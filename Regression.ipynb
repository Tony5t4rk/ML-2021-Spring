{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO4Pl07ugUkuq/wdOqRtTdB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tony5t4rk/ML-2021-Spring/blob/main/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDhyTP7-Q-jv"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmSCozQ8RBRZ"
      },
      "source": [
        "Author: Yang Liu\n",
        "\n",
        "Study notes：[機器學習2021 学习笔记-Introduction](https://www.wolai.com/tony5t4rk/9d8ktj9cGJb8BUafLhWPZ9)\n",
        "\n",
        "This program is modified based on [Sample Code](https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb#scrollTo=ZeZnPAiwDRWG)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFZ7yy4VRBTY"
      },
      "source": [
        "# Mount into Google Drive & Show GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvZtyA9JR4jf",
        "outputId": "02cfed7e-1832-4cf2-d1b8-9a3e1ae21dcf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/Colab/ML 2021 Spring/HW01'\n",
        "!nvidia-smi"
      ],
      "execution_count": 1143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab/ML 2021 Spring/HW01\n",
            "Tue May 11 13:10:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    38W / 300W |   1339MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK91n5G_RBVl"
      },
      "source": [
        "# Download Data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcdst0UdR7u4"
      },
      "source": [
        "# !gdown --id '1jpx8a0aXhz1RPirdCtX5rZGVtaDdNSkx' --output covid.train.csv\n",
        "# !gdown --id '1Itr_zqKBNbK75LAUTkUo00L9J1aVfe6C' --output covid.test.csv\n",
        "\n",
        "train_file = 'covid.train.csv'\n",
        "test_file = 'covid.test.csv'"
      ],
      "execution_count": 1144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZoYxeDSRBXs"
      },
      "source": [
        "# Import Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu5O3c5uSACo"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# set a random seed for reproducibility\n",
        "my_seed = 42096\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(my_seed)\n",
        "torch.manual_seed(my_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(my_seed)"
      ],
      "execution_count": 1145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7_VeXgIRBZ8"
      },
      "source": [
        "# Plot Utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyi2D7QMSAiW"
      },
      "source": [
        "def plot_learning_curve(loss_record, title=''):\n",
        "    n_epochs = len(loss_record['train'])\n",
        "    x_1 = range(n_epochs)\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_1, loss_record['val'], c='tab:cyan', label='val')\n",
        "    plt.ylim(0.0, 10.)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.savefig('Learning curve of {}.svg'.format(title))\n",
        "    plt.show()"
      ],
      "execution_count": 1146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoA4Aml9RBcT"
      },
      "source": [
        "# Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFk-WjbQSA1Z",
        "outputId": "37e36f20-b0a2-43aa-fc96-c2defb832742"
      },
      "source": [
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "config = {\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'target_only': False,\n",
        "    'val_ratio': 0.1,\n",
        "    'reg_decay': 0.01,\n",
        "    'n_epochs': 10000,\n",
        "    'batch_size': 270,\n",
        "    'optim_hparams': {\n",
        "        'lr': 0.001,\n",
        "        'momentum': 0.9\n",
        "    },\n",
        "    'early_stop': True,\n",
        "    'early_stop_epochs': 200,\n",
        "    'model_path': 'models/model.pth',\n",
        "    'pred_file': 'covid-19.pred.csv'\n",
        "}\n",
        "\n",
        "print(f'device: {config[\"device\"]}')"
      ],
      "execution_count": 1147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udnMBQOrRBeb"
      },
      "source": [
        "# Data Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EjqwQTJURdi"
      },
      "source": [
        "## Pre-Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58hylAZ6URJe"
      },
      "source": [
        "with open(train_file, 'r') as fp:\n",
        "    train_x = list(csv.reader(fp))\n",
        "    train_x = np.array(train_x[1:])[:, 1:].astype(float)\n",
        "with open(test_file, 'r') as fp:\n",
        "    test_x = list(csv.reader(fp))\n",
        "    test_x = np.array(test_x[1:])[:, 1:].astype(float)\n",
        "\n",
        "feature_indices = (list(range(40)) + [57, 75]) if config['target_only'] else list(range(40)) + [40, 41, 42, 43, 57, 58, 59, 60, 61, 75, 76, 77, 78, 79]\n",
        "\n",
        "train_x, train_y = train_x[:, feature_indices], train_x[:, -1]\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=config['val_ratio'], random_state=my_seed)\n",
        "test_x = test_x[:, feature_indices]"
      ],
      "execution_count": 1148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBXacuhOSjvK"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5tVRGH3SBJV",
        "outputId": "5c31041d-0b84-40f8-b33b-f9a818cb5ee6"
      },
      "source": [
        "class COVID19_Dataset(Dataset):\n",
        "    def __init__(self, x, y=None, mean=None, std=None):\n",
        "        self.data = torch.from_numpy(x).float()\n",
        "        if mean is None and std is None:\n",
        "            self.mean = self.data[:, 40:].mean(dim=0, keepdim=True)\n",
        "            self.std = self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "        else:\n",
        "            self.mean = mean\n",
        "            self.std = std\n",
        "        self.data[:, 40:] = (self.data[:, 40:] - self.mean) / self.std\n",
        "        if y is not None:\n",
        "            self.label = torch.from_numpy(y).float()\n",
        "        else:\n",
        "            self.label = None\n",
        "        self.dim = self.data.shape[1]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if self.label is not None:\n",
        "            return self.data[index], self.label[index]\n",
        "        else:\n",
        "            return self.data[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "train_dataset = COVID19_Dataset(train_x, train_y)\n",
        "val_dataset = COVID19_Dataset(val_x, val_y, train_dataset.mean, train_dataset.std)\n",
        "test_dataset = COVID19_Dataset(test_x, None, train_dataset.mean, train_dataset.std)\n",
        "\n",
        "print(f'Train Dataset: {len(train_dataset)} samples')\n",
        "print(f'Valid Dataset: {len(val_dataset)} samples')\n",
        "print(f'Test Dataset: {len(test_dataset)} samples')"
      ],
      "execution_count": 1149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Dataset: 2430 samples\n",
            "Valid Dataset: 270 samples\n",
            "Test Dataset: 893 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPf6jI4dSkma"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fu1XrL4SmMa"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)"
      ],
      "execution_count": 1150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pur5XsuWRv6F"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f94vp0OSBi2"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 74),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(74, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "model = Net(train_dataset.dim).to(config['device'])"
      ],
      "execution_count": 1151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3CtfTJ6Rv8B"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZtEn2yA1iyP"
      },
      "source": [
        "criterion = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=config['optim_hparams']['lr'], momentum=config['optim_hparams']['momentum'])"
      ],
      "execution_count": 1152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM-3h6vO1kBe"
      },
      "source": [
        "# L1 > L2 > None\n",
        "def calc_regularization(model, p=1):\n",
        "    reg_loss = 0\n",
        "    if p == 1:\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                reg_loss += config['reg_decay'] * torch.sum(torch.abs(param))\n",
        "    elif p == 2:\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                reg_loss += config['reg_decay'] * torch.norm(param, p=2)\n",
        "    else:\n",
        "        pass\n",
        "    return reg_loss\n",
        "\n",
        "def calc_loss(model, criterion, pred, label, p=1, eps=1e-6):\n",
        "    # RMSE + Regularization\n",
        "    return torch.sqrt(criterion(pred, y) + eps) + calc_regularization(model, p=p)"
      ],
      "execution_count": 1153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBpOwhcKSB1z",
        "outputId": "0e4bc67b-cadc-4ac6-859d-d9de1cfd681e"
      },
      "source": [
        "loss_record = {'train': [], 'val': []}\n",
        "\n",
        "if config['early_stop']:\n",
        "    min_val_loss = float('inf')\n",
        "    early_stop_cnt = 0\n",
        "\n",
        "epoch = 0\n",
        "while epoch < config['n_epochs']:\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    for x, y in train_dataloader:\n",
        "        x, y = x.to(config['device']), y.to(config['device'])\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss = calc_loss(model, criterion, pred, y, p=1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.item())\n",
        "    train_loss = sum(train_loss) / len(train_loss)\n",
        "    loss_record['train'].append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    for x, y in val_dataloader:\n",
        "        x, y = x.to(config['device']), y.to(config['device'])\n",
        "        with torch.no_grad():\n",
        "            pred = model(x)\n",
        "        loss = calc_loss(model, criterion, pred, y, p=1)\n",
        "        val_loss.append(loss.item())\n",
        "    val_loss = sum(val_loss) / len(val_loss)\n",
        "    loss_record['val'].append(val_loss)\n",
        "\n",
        "    print(f'[ Epoch {epoch + 1:03d}/{config[\"n_epochs\"]:03d} ] Train Loss: {train_loss:.5f}   Valid Loss: {val_loss:.5f}')\n",
        "\n",
        "    if config['early_stop']:\n",
        "        if val_loss < min_val_loss:\n",
        "            min_val_loss = val_loss\n",
        "            torch.save(model, config['model_path'])\n",
        "            print(f'Early Stop Saving Model on Epoch {epoch + 1:03d}/{config[\"n_epochs\"]:03d}')\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "    else:\n",
        "        torch.save(model, config['model_path'])\n",
        "    \n",
        "    epoch += 1\n",
        "\n",
        "    if config['early_stop'] and early_stop_cnt > config['early_stop_epochs']:\n",
        "        break\n",
        "\n",
        "print(f'Finish Train After {epoch} Epochs')"
      ],
      "execution_count": 1154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "[ Epoch 1009/10000 ] Train Loss: 1.15522   Valid Loss: 1.09135\n",
            "[ Epoch 1010/10000 ] Train Loss: 1.15863   Valid Loss: 1.09756\n",
            "[ Epoch 1011/10000 ] Train Loss: 1.15833   Valid Loss: 1.09308\n",
            "[ Epoch 1012/10000 ] Train Loss: 1.15740   Valid Loss: 1.09061\n",
            "[ Epoch 1013/10000 ] Train Loss: 1.15716   Valid Loss: 1.09361\n",
            "[ Epoch 1014/10000 ] Train Loss: 1.15579   Valid Loss: 1.09452\n",
            "[ Epoch 1015/10000 ] Train Loss: 1.15848   Valid Loss: 1.09228\n",
            "[ Epoch 1016/10000 ] Train Loss: 1.15636   Valid Loss: 1.09060\n",
            "[ Epoch 1017/10000 ] Train Loss: 1.15584   Valid Loss: 1.08946\n",
            "Early Stop Saving Model on Epoch 1017/10000\n",
            "[ Epoch 1018/10000 ] Train Loss: 1.15525   Valid Loss: 1.09219\n",
            "[ Epoch 1019/10000 ] Train Loss: 1.15429   Valid Loss: 1.09013\n",
            "[ Epoch 1020/10000 ] Train Loss: 1.15594   Valid Loss: 1.09064\n",
            "[ Epoch 1021/10000 ] Train Loss: 1.15535   Valid Loss: 1.09138\n",
            "[ Epoch 1022/10000 ] Train Loss: 1.15612   Valid Loss: 1.08899\n",
            "Early Stop Saving Model on Epoch 1022/10000\n",
            "[ Epoch 1023/10000 ] Train Loss: 1.15386   Valid Loss: 1.08982\n",
            "[ Epoch 1024/10000 ] Train Loss: 1.15693   Valid Loss: 1.09034\n",
            "[ Epoch 1025/10000 ] Train Loss: 1.15587   Valid Loss: 1.09006\n",
            "[ Epoch 1026/10000 ] Train Loss: 1.15389   Valid Loss: 1.08931\n",
            "[ Epoch 1027/10000 ] Train Loss: 1.15325   Valid Loss: 1.08883\n",
            "Early Stop Saving Model on Epoch 1027/10000\n",
            "[ Epoch 1028/10000 ] Train Loss: 1.15439   Valid Loss: 1.08864\n",
            "Early Stop Saving Model on Epoch 1028/10000\n",
            "[ Epoch 1029/10000 ] Train Loss: 1.15444   Valid Loss: 1.08929\n",
            "[ Epoch 1030/10000 ] Train Loss: 1.15374   Valid Loss: 1.08901\n",
            "[ Epoch 1031/10000 ] Train Loss: 1.15411   Valid Loss: 1.08862\n",
            "Early Stop Saving Model on Epoch 1031/10000\n",
            "[ Epoch 1032/10000 ] Train Loss: 1.15320   Valid Loss: 1.08820\n",
            "Early Stop Saving Model on Epoch 1032/10000\n",
            "[ Epoch 1033/10000 ] Train Loss: 1.15212   Valid Loss: 1.08827\n",
            "[ Epoch 1034/10000 ] Train Loss: 1.15416   Valid Loss: 1.08833\n",
            "[ Epoch 1035/10000 ] Train Loss: 1.15795   Valid Loss: 1.09955\n",
            "[ Epoch 1036/10000 ] Train Loss: 1.16431   Valid Loss: 1.10080\n",
            "[ Epoch 1037/10000 ] Train Loss: 1.15245   Valid Loss: 1.09296\n",
            "[ Epoch 1038/10000 ] Train Loss: 1.15640   Valid Loss: 1.08809\n",
            "Early Stop Saving Model on Epoch 1038/10000\n",
            "[ Epoch 1039/10000 ] Train Loss: 1.15344   Valid Loss: 1.08755\n",
            "Early Stop Saving Model on Epoch 1039/10000\n",
            "[ Epoch 1040/10000 ] Train Loss: 1.15492   Valid Loss: 1.08829\n",
            "[ Epoch 1041/10000 ] Train Loss: 1.15442   Valid Loss: 1.08748\n",
            "Early Stop Saving Model on Epoch 1041/10000\n",
            "[ Epoch 1042/10000 ] Train Loss: 1.15182   Valid Loss: 1.08843\n",
            "[ Epoch 1043/10000 ] Train Loss: 1.15095   Valid Loss: 1.08830\n",
            "[ Epoch 1044/10000 ] Train Loss: 1.15257   Valid Loss: 1.08592\n",
            "Early Stop Saving Model on Epoch 1044/10000\n",
            "[ Epoch 1045/10000 ] Train Loss: 1.15246   Valid Loss: 1.08630\n",
            "[ Epoch 1046/10000 ] Train Loss: 1.15372   Valid Loss: 1.08784\n",
            "[ Epoch 1047/10000 ] Train Loss: 1.15232   Valid Loss: 1.08649\n",
            "[ Epoch 1048/10000 ] Train Loss: 1.15450   Valid Loss: 1.08752\n",
            "[ Epoch 1049/10000 ] Train Loss: 1.15411   Valid Loss: 1.08670\n",
            "[ Epoch 1050/10000 ] Train Loss: 1.15256   Valid Loss: 1.08910\n",
            "[ Epoch 1051/10000 ] Train Loss: 1.15265   Valid Loss: 1.08617\n",
            "[ Epoch 1052/10000 ] Train Loss: 1.15166   Valid Loss: 1.08540\n",
            "Early Stop Saving Model on Epoch 1052/10000\n",
            "[ Epoch 1053/10000 ] Train Loss: 1.15098   Valid Loss: 1.08720\n",
            "[ Epoch 1054/10000 ] Train Loss: 1.15361   Valid Loss: 1.09359\n",
            "[ Epoch 1055/10000 ] Train Loss: 1.15413   Valid Loss: 1.09203\n",
            "[ Epoch 1056/10000 ] Train Loss: 1.15366   Valid Loss: 1.08570\n",
            "[ Epoch 1057/10000 ] Train Loss: 1.15218   Valid Loss: 1.08615\n",
            "[ Epoch 1058/10000 ] Train Loss: 1.15155   Valid Loss: 1.08757\n",
            "[ Epoch 1059/10000 ] Train Loss: 1.15206   Valid Loss: 1.08403\n",
            "Early Stop Saving Model on Epoch 1059/10000\n",
            "[ Epoch 1060/10000 ] Train Loss: 1.15099   Valid Loss: 1.08571\n",
            "[ Epoch 1061/10000 ] Train Loss: 1.15065   Valid Loss: 1.08652\n",
            "[ Epoch 1062/10000 ] Train Loss: 1.15600   Valid Loss: 1.09133\n",
            "[ Epoch 1063/10000 ] Train Loss: 1.15151   Valid Loss: 1.08611\n",
            "[ Epoch 1064/10000 ] Train Loss: 1.14923   Valid Loss: 1.08777\n",
            "[ Epoch 1065/10000 ] Train Loss: 1.15291   Valid Loss: 1.08671\n",
            "[ Epoch 1066/10000 ] Train Loss: 1.15101   Valid Loss: 1.08405\n",
            "[ Epoch 1067/10000 ] Train Loss: 1.15109   Valid Loss: 1.08769\n",
            "[ Epoch 1068/10000 ] Train Loss: 1.15082   Valid Loss: 1.08426\n",
            "[ Epoch 1069/10000 ] Train Loss: 1.14780   Valid Loss: 1.08588\n",
            "[ Epoch 1070/10000 ] Train Loss: 1.15649   Valid Loss: 1.08496\n",
            "[ Epoch 1071/10000 ] Train Loss: 1.15161   Valid Loss: 1.08621\n",
            "[ Epoch 1072/10000 ] Train Loss: 1.15201   Valid Loss: 1.08562\n",
            "[ Epoch 1073/10000 ] Train Loss: 1.15098   Valid Loss: 1.08411\n",
            "[ Epoch 1074/10000 ] Train Loss: 1.14931   Valid Loss: 1.08780\n",
            "[ Epoch 1075/10000 ] Train Loss: 1.15049   Valid Loss: 1.08471\n",
            "[ Epoch 1076/10000 ] Train Loss: 1.14829   Valid Loss: 1.08384\n",
            "Early Stop Saving Model on Epoch 1076/10000\n",
            "[ Epoch 1077/10000 ] Train Loss: 1.14775   Valid Loss: 1.08365\n",
            "Early Stop Saving Model on Epoch 1077/10000\n",
            "[ Epoch 1078/10000 ] Train Loss: 1.14826   Valid Loss: 1.08246\n",
            "Early Stop Saving Model on Epoch 1078/10000\n",
            "[ Epoch 1079/10000 ] Train Loss: 1.14727   Valid Loss: 1.08281\n",
            "[ Epoch 1080/10000 ] Train Loss: 1.14736   Valid Loss: 1.08344\n",
            "[ Epoch 1081/10000 ] Train Loss: 1.14831   Valid Loss: 1.08337\n",
            "[ Epoch 1082/10000 ] Train Loss: 1.14797   Valid Loss: 1.08185\n",
            "Early Stop Saving Model on Epoch 1082/10000\n",
            "[ Epoch 1083/10000 ] Train Loss: 1.14723   Valid Loss: 1.08365\n",
            "[ Epoch 1084/10000 ] Train Loss: 1.14835   Valid Loss: 1.08403\n",
            "[ Epoch 1085/10000 ] Train Loss: 1.15084   Valid Loss: 1.08207\n",
            "[ Epoch 1086/10000 ] Train Loss: 1.14659   Valid Loss: 1.08241\n",
            "[ Epoch 1087/10000 ] Train Loss: 1.14687   Valid Loss: 1.08299\n",
            "[ Epoch 1088/10000 ] Train Loss: 1.14696   Valid Loss: 1.08300\n",
            "[ Epoch 1089/10000 ] Train Loss: 1.14911   Valid Loss: 1.08444\n",
            "[ Epoch 1090/10000 ] Train Loss: 1.14799   Valid Loss: 1.08234\n",
            "[ Epoch 1091/10000 ] Train Loss: 1.14793   Valid Loss: 1.08553\n",
            "[ Epoch 1092/10000 ] Train Loss: 1.14916   Valid Loss: 1.08298\n",
            "[ Epoch 1093/10000 ] Train Loss: 1.14720   Valid Loss: 1.08147\n",
            "Early Stop Saving Model on Epoch 1093/10000\n",
            "[ Epoch 1094/10000 ] Train Loss: 1.14804   Valid Loss: 1.08421\n",
            "[ Epoch 1095/10000 ] Train Loss: 1.14961   Valid Loss: 1.08933\n",
            "[ Epoch 1096/10000 ] Train Loss: 1.15189   Valid Loss: 1.08628\n",
            "[ Epoch 1097/10000 ] Train Loss: 1.14984   Valid Loss: 1.08120\n",
            "Early Stop Saving Model on Epoch 1097/10000\n",
            "[ Epoch 1098/10000 ] Train Loss: 1.14758   Valid Loss: 1.08243\n",
            "[ Epoch 1099/10000 ] Train Loss: 1.14748   Valid Loss: 1.08118\n",
            "Early Stop Saving Model on Epoch 1099/10000\n",
            "[ Epoch 1100/10000 ] Train Loss: 1.14870   Valid Loss: 1.08417\n",
            "[ Epoch 1101/10000 ] Train Loss: 1.14759   Valid Loss: 1.08420\n",
            "[ Epoch 1102/10000 ] Train Loss: 1.14605   Valid Loss: 1.08008\n",
            "Early Stop Saving Model on Epoch 1102/10000\n",
            "[ Epoch 1103/10000 ] Train Loss: 1.14614   Valid Loss: 1.08050\n",
            "[ Epoch 1104/10000 ] Train Loss: 1.14574   Valid Loss: 1.08070\n",
            "[ Epoch 1105/10000 ] Train Loss: 1.14698   Valid Loss: 1.08222\n",
            "[ Epoch 1106/10000 ] Train Loss: 1.14596   Valid Loss: 1.08085\n",
            "[ Epoch 1107/10000 ] Train Loss: 1.14498   Valid Loss: 1.07988\n",
            "Early Stop Saving Model on Epoch 1107/10000\n",
            "[ Epoch 1108/10000 ] Train Loss: 1.14624   Valid Loss: 1.08101\n",
            "[ Epoch 1109/10000 ] Train Loss: 1.14555   Valid Loss: 1.08019\n",
            "[ Epoch 1110/10000 ] Train Loss: 1.14583   Valid Loss: 1.08214\n",
            "[ Epoch 1111/10000 ] Train Loss: 1.14594   Valid Loss: 1.08253\n",
            "[ Epoch 1112/10000 ] Train Loss: 1.14754   Valid Loss: 1.08128\n",
            "[ Epoch 1113/10000 ] Train Loss: 1.14543   Valid Loss: 1.08322\n",
            "[ Epoch 1114/10000 ] Train Loss: 1.14508   Valid Loss: 1.08046\n",
            "[ Epoch 1115/10000 ] Train Loss: 1.14522   Valid Loss: 1.07953\n",
            "Early Stop Saving Model on Epoch 1115/10000\n",
            "[ Epoch 1116/10000 ] Train Loss: 1.14389   Valid Loss: 1.07925\n",
            "Early Stop Saving Model on Epoch 1116/10000\n",
            "[ Epoch 1117/10000 ] Train Loss: 1.14740   Valid Loss: 1.08071\n",
            "[ Epoch 1118/10000 ] Train Loss: 1.14547   Valid Loss: 1.07979\n",
            "[ Epoch 1119/10000 ] Train Loss: 1.14571   Valid Loss: 1.07990\n",
            "[ Epoch 1120/10000 ] Train Loss: 1.14449   Valid Loss: 1.07904\n",
            "Early Stop Saving Model on Epoch 1120/10000\n",
            "[ Epoch 1121/10000 ] Train Loss: 1.14427   Valid Loss: 1.07983\n",
            "[ Epoch 1122/10000 ] Train Loss: 1.14357   Valid Loss: 1.07898\n",
            "Early Stop Saving Model on Epoch 1122/10000\n",
            "[ Epoch 1123/10000 ] Train Loss: 1.14361   Valid Loss: 1.07859\n",
            "Early Stop Saving Model on Epoch 1123/10000\n",
            "[ Epoch 1124/10000 ] Train Loss: 1.14442   Valid Loss: 1.07845\n",
            "Early Stop Saving Model on Epoch 1124/10000\n",
            "[ Epoch 1125/10000 ] Train Loss: 1.14428   Valid Loss: 1.08080\n",
            "[ Epoch 1126/10000 ] Train Loss: 1.14460   Valid Loss: 1.07919\n",
            "[ Epoch 1127/10000 ] Train Loss: 1.14377   Valid Loss: 1.07806\n",
            "Early Stop Saving Model on Epoch 1127/10000\n",
            "[ Epoch 1128/10000 ] Train Loss: 1.14402   Valid Loss: 1.07869\n",
            "[ Epoch 1129/10000 ] Train Loss: 1.14339   Valid Loss: 1.07981\n",
            "[ Epoch 1130/10000 ] Train Loss: 1.14366   Valid Loss: 1.07892\n",
            "[ Epoch 1131/10000 ] Train Loss: 1.14575   Valid Loss: 1.08010\n",
            "[ Epoch 1132/10000 ] Train Loss: 1.14602   Valid Loss: 1.07827\n",
            "[ Epoch 1133/10000 ] Train Loss: 1.14452   Valid Loss: 1.07910\n",
            "[ Epoch 1134/10000 ] Train Loss: 1.14318   Valid Loss: 1.07932\n",
            "[ Epoch 1135/10000 ] Train Loss: 1.14390   Valid Loss: 1.07896\n",
            "[ Epoch 1136/10000 ] Train Loss: 1.14183   Valid Loss: 1.08022\n",
            "[ Epoch 1137/10000 ] Train Loss: 1.14499   Valid Loss: 1.07876\n",
            "[ Epoch 1138/10000 ] Train Loss: 1.14282   Valid Loss: 1.08093\n",
            "[ Epoch 1139/10000 ] Train Loss: 1.14303   Valid Loss: 1.07647\n",
            "Early Stop Saving Model on Epoch 1139/10000\n",
            "[ Epoch 1140/10000 ] Train Loss: 1.14289   Valid Loss: 1.07735\n",
            "[ Epoch 1141/10000 ] Train Loss: 1.14329   Valid Loss: 1.07763\n",
            "[ Epoch 1142/10000 ] Train Loss: 1.14540   Valid Loss: 1.08160\n",
            "[ Epoch 1143/10000 ] Train Loss: 1.14593   Valid Loss: 1.07886\n",
            "[ Epoch 1144/10000 ] Train Loss: 1.14259   Valid Loss: 1.07664\n",
            "[ Epoch 1145/10000 ] Train Loss: 1.14159   Valid Loss: 1.07737\n",
            "[ Epoch 1146/10000 ] Train Loss: 1.14183   Valid Loss: 1.07716\n",
            "[ Epoch 1147/10000 ] Train Loss: 1.14434   Valid Loss: 1.07740\n",
            "[ Epoch 1148/10000 ] Train Loss: 1.14327   Valid Loss: 1.07705\n",
            "[ Epoch 1149/10000 ] Train Loss: 1.14445   Valid Loss: 1.07870\n",
            "[ Epoch 1150/10000 ] Train Loss: 1.14397   Valid Loss: 1.07746\n",
            "[ Epoch 1151/10000 ] Train Loss: 1.14246   Valid Loss: 1.07828\n",
            "[ Epoch 1152/10000 ] Train Loss: 1.14490   Valid Loss: 1.07873\n",
            "[ Epoch 1153/10000 ] Train Loss: 1.14490   Valid Loss: 1.07617\n",
            "Early Stop Saving Model on Epoch 1153/10000\n",
            "[ Epoch 1154/10000 ] Train Loss: 1.14552   Valid Loss: 1.07869\n",
            "[ Epoch 1155/10000 ] Train Loss: 1.14742   Valid Loss: 1.07577\n",
            "Early Stop Saving Model on Epoch 1155/10000\n",
            "[ Epoch 1156/10000 ] Train Loss: 1.14455   Valid Loss: 1.08122\n",
            "[ Epoch 1157/10000 ] Train Loss: 1.14347   Valid Loss: 1.08043\n",
            "[ Epoch 1158/10000 ] Train Loss: 1.14596   Valid Loss: 1.07840\n",
            "[ Epoch 1159/10000 ] Train Loss: 1.14248   Valid Loss: 1.07628\n",
            "[ Epoch 1160/10000 ] Train Loss: 1.14132   Valid Loss: 1.07632\n",
            "[ Epoch 1161/10000 ] Train Loss: 1.14105   Valid Loss: 1.07554\n",
            "Early Stop Saving Model on Epoch 1161/10000\n",
            "[ Epoch 1162/10000 ] Train Loss: 1.14138   Valid Loss: 1.07639\n",
            "[ Epoch 1163/10000 ] Train Loss: 1.14176   Valid Loss: 1.07684\n",
            "[ Epoch 1164/10000 ] Train Loss: 1.14020   Valid Loss: 1.07560\n",
            "[ Epoch 1165/10000 ] Train Loss: 1.14025   Valid Loss: 1.07544\n",
            "Early Stop Saving Model on Epoch 1165/10000\n",
            "[ Epoch 1166/10000 ] Train Loss: 1.14047   Valid Loss: 1.07488\n",
            "Early Stop Saving Model on Epoch 1166/10000\n",
            "[ Epoch 1167/10000 ] Train Loss: 1.14045   Valid Loss: 1.07920\n",
            "[ Epoch 1168/10000 ] Train Loss: 1.14456   Valid Loss: 1.07578\n",
            "[ Epoch 1169/10000 ] Train Loss: 1.13981   Valid Loss: 1.07466\n",
            "Early Stop Saving Model on Epoch 1169/10000\n",
            "[ Epoch 1170/10000 ] Train Loss: 1.13987   Valid Loss: 1.07470\n",
            "[ Epoch 1171/10000 ] Train Loss: 1.14102   Valid Loss: 1.07578\n",
            "[ Epoch 1172/10000 ] Train Loss: 1.14090   Valid Loss: 1.07677\n",
            "[ Epoch 1173/10000 ] Train Loss: 1.14073   Valid Loss: 1.07503\n",
            "[ Epoch 1174/10000 ] Train Loss: 1.14233   Valid Loss: 1.07438\n",
            "Early Stop Saving Model on Epoch 1174/10000\n",
            "[ Epoch 1175/10000 ] Train Loss: 1.14052   Valid Loss: 1.07487\n",
            "[ Epoch 1176/10000 ] Train Loss: 1.14097   Valid Loss: 1.07599\n",
            "[ Epoch 1177/10000 ] Train Loss: 1.14064   Valid Loss: 1.07663\n",
            "[ Epoch 1178/10000 ] Train Loss: 1.14112   Valid Loss: 1.07430\n",
            "Early Stop Saving Model on Epoch 1178/10000\n",
            "[ Epoch 1179/10000 ] Train Loss: 1.13802   Valid Loss: 1.07385\n",
            "Early Stop Saving Model on Epoch 1179/10000\n",
            "[ Epoch 1180/10000 ] Train Loss: 1.14011   Valid Loss: 1.07479\n",
            "[ Epoch 1181/10000 ] Train Loss: 1.13977   Valid Loss: 1.07508\n",
            "[ Epoch 1182/10000 ] Train Loss: 1.13886   Valid Loss: 1.07480\n",
            "[ Epoch 1183/10000 ] Train Loss: 1.13915   Valid Loss: 1.07345\n",
            "Early Stop Saving Model on Epoch 1183/10000\n",
            "[ Epoch 1184/10000 ] Train Loss: 1.13792   Valid Loss: 1.07370\n",
            "[ Epoch 1185/10000 ] Train Loss: 1.13960   Valid Loss: 1.07348\n",
            "[ Epoch 1186/10000 ] Train Loss: 1.13959   Valid Loss: 1.07349\n",
            "[ Epoch 1187/10000 ] Train Loss: 1.14028   Valid Loss: 1.07572\n",
            "[ Epoch 1188/10000 ] Train Loss: 1.14062   Valid Loss: 1.07309\n",
            "Early Stop Saving Model on Epoch 1188/10000\n",
            "[ Epoch 1189/10000 ] Train Loss: 1.13786   Valid Loss: 1.07395\n",
            "[ Epoch 1190/10000 ] Train Loss: 1.13861   Valid Loss: 1.07344\n",
            "[ Epoch 1191/10000 ] Train Loss: 1.14052   Valid Loss: 1.07565\n",
            "[ Epoch 1192/10000 ] Train Loss: 1.13967   Valid Loss: 1.07480\n",
            "[ Epoch 1193/10000 ] Train Loss: 1.14373   Valid Loss: 1.07548\n",
            "[ Epoch 1194/10000 ] Train Loss: 1.13939   Valid Loss: 1.07405\n",
            "[ Epoch 1195/10000 ] Train Loss: 1.13907   Valid Loss: 1.07449\n",
            "[ Epoch 1196/10000 ] Train Loss: 1.13799   Valid Loss: 1.07273\n",
            "Early Stop Saving Model on Epoch 1196/10000\n",
            "[ Epoch 1197/10000 ] Train Loss: 1.13844   Valid Loss: 1.07505\n",
            "[ Epoch 1198/10000 ] Train Loss: 1.13914   Valid Loss: 1.07369\n",
            "[ Epoch 1199/10000 ] Train Loss: 1.13939   Valid Loss: 1.07484\n",
            "[ Epoch 1200/10000 ] Train Loss: 1.13777   Valid Loss: 1.07221\n",
            "Early Stop Saving Model on Epoch 1200/10000\n",
            "[ Epoch 1201/10000 ] Train Loss: 1.13880   Valid Loss: 1.07298\n",
            "[ Epoch 1202/10000 ] Train Loss: 1.13699   Valid Loss: 1.07360\n",
            "[ Epoch 1203/10000 ] Train Loss: 1.13798   Valid Loss: 1.07382\n",
            "[ Epoch 1204/10000 ] Train Loss: 1.13681   Valid Loss: 1.07392\n",
            "[ Epoch 1205/10000 ] Train Loss: 1.13838   Valid Loss: 1.07251\n",
            "[ Epoch 1206/10000 ] Train Loss: 1.13550   Valid Loss: 1.07211\n",
            "Early Stop Saving Model on Epoch 1206/10000\n",
            "[ Epoch 1207/10000 ] Train Loss: 1.13856   Valid Loss: 1.07474\n",
            "[ Epoch 1208/10000 ] Train Loss: 1.13824   Valid Loss: 1.07143\n",
            "Early Stop Saving Model on Epoch 1208/10000\n",
            "[ Epoch 1209/10000 ] Train Loss: 1.13769   Valid Loss: 1.07399\n",
            "[ Epoch 1210/10000 ] Train Loss: 1.13868   Valid Loss: 1.07129\n",
            "Early Stop Saving Model on Epoch 1210/10000\n",
            "[ Epoch 1211/10000 ] Train Loss: 1.14047   Valid Loss: 1.07467\n",
            "[ Epoch 1212/10000 ] Train Loss: 1.13860   Valid Loss: 1.07090\n",
            "Early Stop Saving Model on Epoch 1212/10000\n",
            "[ Epoch 1213/10000 ] Train Loss: 1.13704   Valid Loss: 1.07283\n",
            "[ Epoch 1214/10000 ] Train Loss: 1.13700   Valid Loss: 1.07204\n",
            "[ Epoch 1215/10000 ] Train Loss: 1.13729   Valid Loss: 1.07085\n",
            "Early Stop Saving Model on Epoch 1215/10000\n",
            "[ Epoch 1216/10000 ] Train Loss: 1.13676   Valid Loss: 1.07173\n",
            "[ Epoch 1217/10000 ] Train Loss: 1.13599   Valid Loss: 1.07298\n",
            "[ Epoch 1218/10000 ] Train Loss: 1.13721   Valid Loss: 1.07281\n",
            "[ Epoch 1219/10000 ] Train Loss: 1.13805   Valid Loss: 1.07046\n",
            "Early Stop Saving Model on Epoch 1219/10000\n",
            "[ Epoch 1220/10000 ] Train Loss: 1.13771   Valid Loss: 1.07096\n",
            "[ Epoch 1221/10000 ] Train Loss: 1.13595   Valid Loss: 1.07199\n",
            "[ Epoch 1222/10000 ] Train Loss: 1.13651   Valid Loss: 1.07205\n",
            "[ Epoch 1223/10000 ] Train Loss: 1.13698   Valid Loss: 1.07021\n",
            "Early Stop Saving Model on Epoch 1223/10000\n",
            "[ Epoch 1224/10000 ] Train Loss: 1.13723   Valid Loss: 1.07180\n",
            "[ Epoch 1225/10000 ] Train Loss: 1.13867   Valid Loss: 1.07207\n",
            "[ Epoch 1226/10000 ] Train Loss: 1.13775   Valid Loss: 1.07254\n",
            "[ Epoch 1227/10000 ] Train Loss: 1.13792   Valid Loss: 1.07024\n",
            "[ Epoch 1228/10000 ] Train Loss: 1.13787   Valid Loss: 1.07329\n",
            "[ Epoch 1229/10000 ] Train Loss: 1.13601   Valid Loss: 1.07385\n",
            "[ Epoch 1230/10000 ] Train Loss: 1.13800   Valid Loss: 1.07221\n",
            "[ Epoch 1231/10000 ] Train Loss: 1.13733   Valid Loss: 1.07147\n",
            "[ Epoch 1232/10000 ] Train Loss: 1.13766   Valid Loss: 1.07363\n",
            "[ Epoch 1233/10000 ] Train Loss: 1.13704   Valid Loss: 1.06895\n",
            "Early Stop Saving Model on Epoch 1233/10000\n",
            "[ Epoch 1234/10000 ] Train Loss: 1.13663   Valid Loss: 1.06979\n",
            "[ Epoch 1235/10000 ] Train Loss: 1.13589   Valid Loss: 1.06982\n",
            "[ Epoch 1236/10000 ] Train Loss: 1.13466   Valid Loss: 1.07040\n",
            "[ Epoch 1237/10000 ] Train Loss: 1.13525   Valid Loss: 1.07117\n",
            "[ Epoch 1238/10000 ] Train Loss: 1.13580   Valid Loss: 1.06957\n",
            "[ Epoch 1239/10000 ] Train Loss: 1.13486   Valid Loss: 1.06956\n",
            "[ Epoch 1240/10000 ] Train Loss: 1.13484   Valid Loss: 1.07044\n",
            "[ Epoch 1241/10000 ] Train Loss: 1.13599   Valid Loss: 1.06977\n",
            "[ Epoch 1242/10000 ] Train Loss: 1.13875   Valid Loss: 1.07090\n",
            "[ Epoch 1243/10000 ] Train Loss: 1.13663   Valid Loss: 1.06956\n",
            "[ Epoch 1244/10000 ] Train Loss: 1.13597   Valid Loss: 1.07174\n",
            "[ Epoch 1245/10000 ] Train Loss: 1.13401   Valid Loss: 1.06988\n",
            "[ Epoch 1246/10000 ] Train Loss: 1.13573   Valid Loss: 1.06875\n",
            "Early Stop Saving Model on Epoch 1246/10000\n",
            "[ Epoch 1247/10000 ] Train Loss: 1.13565   Valid Loss: 1.07185\n",
            "[ Epoch 1248/10000 ] Train Loss: 1.13799   Valid Loss: 1.07096\n",
            "[ Epoch 1249/10000 ] Train Loss: 1.13316   Valid Loss: 1.07024\n",
            "[ Epoch 1250/10000 ] Train Loss: 1.13537   Valid Loss: 1.07011\n",
            "[ Epoch 1251/10000 ] Train Loss: 1.13279   Valid Loss: 1.06877\n",
            "[ Epoch 1252/10000 ] Train Loss: 1.13534   Valid Loss: 1.06974\n",
            "[ Epoch 1253/10000 ] Train Loss: 1.13325   Valid Loss: 1.06797\n",
            "Early Stop Saving Model on Epoch 1253/10000\n",
            "[ Epoch 1254/10000 ] Train Loss: 1.13362   Valid Loss: 1.07126\n",
            "[ Epoch 1255/10000 ] Train Loss: 1.13513   Valid Loss: 1.07235\n",
            "[ Epoch 1256/10000 ] Train Loss: 1.13569   Valid Loss: 1.06993\n",
            "[ Epoch 1257/10000 ] Train Loss: 1.13524   Valid Loss: 1.06795\n",
            "Early Stop Saving Model on Epoch 1257/10000\n",
            "[ Epoch 1258/10000 ] Train Loss: 1.13392   Valid Loss: 1.07105\n",
            "[ Epoch 1259/10000 ] Train Loss: 1.13448   Valid Loss: 1.06958\n",
            "[ Epoch 1260/10000 ] Train Loss: 1.13255   Valid Loss: 1.06881\n",
            "[ Epoch 1261/10000 ] Train Loss: 1.13561   Valid Loss: 1.06690\n",
            "Early Stop Saving Model on Epoch 1261/10000\n",
            "[ Epoch 1262/10000 ] Train Loss: 1.13471   Valid Loss: 1.06692\n",
            "[ Epoch 1263/10000 ] Train Loss: 1.13370   Valid Loss: 1.06913\n",
            "[ Epoch 1264/10000 ] Train Loss: 1.13310   Valid Loss: 1.06866\n",
            "[ Epoch 1265/10000 ] Train Loss: 1.13327   Valid Loss: 1.06699\n",
            "[ Epoch 1266/10000 ] Train Loss: 1.13128   Valid Loss: 1.06760\n",
            "[ Epoch 1267/10000 ] Train Loss: 1.13223   Valid Loss: 1.06737\n",
            "[ Epoch 1268/10000 ] Train Loss: 1.13221   Valid Loss: 1.06749\n",
            "[ Epoch 1269/10000 ] Train Loss: 1.13290   Valid Loss: 1.06742\n",
            "[ Epoch 1270/10000 ] Train Loss: 1.13272   Valid Loss: 1.06768\n",
            "[ Epoch 1271/10000 ] Train Loss: 1.13275   Valid Loss: 1.06700\n",
            "[ Epoch 1272/10000 ] Train Loss: 1.13319   Valid Loss: 1.06674\n",
            "Early Stop Saving Model on Epoch 1272/10000\n",
            "[ Epoch 1273/10000 ] Train Loss: 1.13150   Valid Loss: 1.06781\n",
            "[ Epoch 1274/10000 ] Train Loss: 1.13102   Valid Loss: 1.06650\n",
            "Early Stop Saving Model on Epoch 1274/10000\n",
            "[ Epoch 1275/10000 ] Train Loss: 1.13347   Valid Loss: 1.06622\n",
            "Early Stop Saving Model on Epoch 1275/10000\n",
            "[ Epoch 1276/10000 ] Train Loss: 1.13429   Valid Loss: 1.06880\n",
            "[ Epoch 1277/10000 ] Train Loss: 1.13244   Valid Loss: 1.06849\n",
            "[ Epoch 1278/10000 ] Train Loss: 1.13222   Valid Loss: 1.06824\n",
            "[ Epoch 1279/10000 ] Train Loss: 1.13207   Valid Loss: 1.06842\n",
            "[ Epoch 1280/10000 ] Train Loss: 1.13280   Valid Loss: 1.06618\n",
            "Early Stop Saving Model on Epoch 1280/10000\n",
            "[ Epoch 1281/10000 ] Train Loss: 1.13363   Valid Loss: 1.07065\n",
            "[ Epoch 1282/10000 ] Train Loss: 1.13337   Valid Loss: 1.06947\n",
            "[ Epoch 1283/10000 ] Train Loss: 1.13217   Valid Loss: 1.06691\n",
            "[ Epoch 1284/10000 ] Train Loss: 1.13134   Valid Loss: 1.06701\n",
            "[ Epoch 1285/10000 ] Train Loss: 1.13052   Valid Loss: 1.06512\n",
            "Early Stop Saving Model on Epoch 1285/10000\n",
            "[ Epoch 1286/10000 ] Train Loss: 1.13120   Valid Loss: 1.06647\n",
            "[ Epoch 1287/10000 ] Train Loss: 1.13296   Valid Loss: 1.06705\n",
            "[ Epoch 1288/10000 ] Train Loss: 1.13028   Valid Loss: 1.06871\n",
            "[ Epoch 1289/10000 ] Train Loss: 1.13095   Valid Loss: 1.06800\n",
            "[ Epoch 1290/10000 ] Train Loss: 1.13102   Valid Loss: 1.06967\n",
            "[ Epoch 1291/10000 ] Train Loss: 1.13044   Valid Loss: 1.06489\n",
            "Early Stop Saving Model on Epoch 1291/10000\n",
            "[ Epoch 1292/10000 ] Train Loss: 1.13165   Valid Loss: 1.06513\n",
            "[ Epoch 1293/10000 ] Train Loss: 1.13123   Valid Loss: 1.06679\n",
            "[ Epoch 1294/10000 ] Train Loss: 1.13005   Valid Loss: 1.06572\n",
            "[ Epoch 1295/10000 ] Train Loss: 1.13073   Valid Loss: 1.06565\n",
            "[ Epoch 1296/10000 ] Train Loss: 1.13113   Valid Loss: 1.06545\n",
            "[ Epoch 1297/10000 ] Train Loss: 1.13060   Valid Loss: 1.06584\n",
            "[ Epoch 1298/10000 ] Train Loss: 1.13163   Valid Loss: 1.06504\n",
            "[ Epoch 1299/10000 ] Train Loss: 1.13214   Valid Loss: 1.06720\n",
            "[ Epoch 1300/10000 ] Train Loss: 1.13232   Valid Loss: 1.06532\n",
            "[ Epoch 1301/10000 ] Train Loss: 1.13055   Valid Loss: 1.06350\n",
            "Early Stop Saving Model on Epoch 1301/10000\n",
            "[ Epoch 1302/10000 ] Train Loss: 1.12946   Valid Loss: 1.06440\n",
            "[ Epoch 1303/10000 ] Train Loss: 1.13570   Valid Loss: 1.07113\n",
            "[ Epoch 1304/10000 ] Train Loss: 1.13508   Valid Loss: 1.06574\n",
            "[ Epoch 1305/10000 ] Train Loss: 1.13146   Valid Loss: 1.06432\n",
            "[ Epoch 1306/10000 ] Train Loss: 1.13121   Valid Loss: 1.06445\n",
            "[ Epoch 1307/10000 ] Train Loss: 1.13040   Valid Loss: 1.06465\n",
            "[ Epoch 1308/10000 ] Train Loss: 1.12942   Valid Loss: 1.06290\n",
            "Early Stop Saving Model on Epoch 1308/10000\n",
            "[ Epoch 1309/10000 ] Train Loss: 1.13031   Valid Loss: 1.06409\n",
            "[ Epoch 1310/10000 ] Train Loss: 1.13038   Valid Loss: 1.06477\n",
            "[ Epoch 1311/10000 ] Train Loss: 1.13012   Valid Loss: 1.06380\n",
            "[ Epoch 1312/10000 ] Train Loss: 1.12845   Valid Loss: 1.06231\n",
            "Early Stop Saving Model on Epoch 1312/10000\n",
            "[ Epoch 1313/10000 ] Train Loss: 1.12997   Valid Loss: 1.06398\n",
            "[ Epoch 1314/10000 ] Train Loss: 1.12900   Valid Loss: 1.06417\n",
            "[ Epoch 1315/10000 ] Train Loss: 1.13015   Valid Loss: 1.06663\n",
            "[ Epoch 1316/10000 ] Train Loss: 1.13094   Valid Loss: 1.06737\n",
            "[ Epoch 1317/10000 ] Train Loss: 1.12897   Valid Loss: 1.06251\n",
            "[ Epoch 1318/10000 ] Train Loss: 1.13062   Valid Loss: 1.06387\n",
            "[ Epoch 1319/10000 ] Train Loss: 1.12823   Valid Loss: 1.06483\n",
            "[ Epoch 1320/10000 ] Train Loss: 1.12875   Valid Loss: 1.06305\n",
            "[ Epoch 1321/10000 ] Train Loss: 1.12924   Valid Loss: 1.06301\n",
            "[ Epoch 1322/10000 ] Train Loss: 1.12961   Valid Loss: 1.06492\n",
            "[ Epoch 1323/10000 ] Train Loss: 1.12867   Valid Loss: 1.06347\n",
            "[ Epoch 1324/10000 ] Train Loss: 1.12811   Valid Loss: 1.06151\n",
            "Early Stop Saving Model on Epoch 1324/10000\n",
            "[ Epoch 1325/10000 ] Train Loss: 1.12751   Valid Loss: 1.06226\n",
            "[ Epoch 1326/10000 ] Train Loss: 1.12716   Valid Loss: 1.06169\n",
            "[ Epoch 1327/10000 ] Train Loss: 1.12807   Valid Loss: 1.06197\n",
            "[ Epoch 1328/10000 ] Train Loss: 1.12805   Valid Loss: 1.06300\n",
            "[ Epoch 1329/10000 ] Train Loss: 1.12744   Valid Loss: 1.06309\n",
            "[ Epoch 1330/10000 ] Train Loss: 1.12785   Valid Loss: 1.06135\n",
            "Early Stop Saving Model on Epoch 1330/10000\n",
            "[ Epoch 1331/10000 ] Train Loss: 1.12672   Valid Loss: 1.06281\n",
            "[ Epoch 1332/10000 ] Train Loss: 1.12740   Valid Loss: 1.06116\n",
            "Early Stop Saving Model on Epoch 1332/10000\n",
            "[ Epoch 1333/10000 ] Train Loss: 1.13045   Valid Loss: 1.06382\n",
            "[ Epoch 1334/10000 ] Train Loss: 1.12730   Valid Loss: 1.06035\n",
            "Early Stop Saving Model on Epoch 1334/10000\n",
            "[ Epoch 1335/10000 ] Train Loss: 1.12812   Valid Loss: 1.06313\n",
            "[ Epoch 1336/10000 ] Train Loss: 1.12707   Valid Loss: 1.06398\n",
            "[ Epoch 1337/10000 ] Train Loss: 1.13000   Valid Loss: 1.06337\n",
            "[ Epoch 1338/10000 ] Train Loss: 1.12785   Valid Loss: 1.06504\n",
            "[ Epoch 1339/10000 ] Train Loss: 1.12715   Valid Loss: 1.06353\n",
            "[ Epoch 1340/10000 ] Train Loss: 1.13255   Valid Loss: 1.06237\n",
            "[ Epoch 1341/10000 ] Train Loss: 1.12785   Valid Loss: 1.06097\n",
            "[ Epoch 1342/10000 ] Train Loss: 1.12734   Valid Loss: 1.06096\n",
            "[ Epoch 1343/10000 ] Train Loss: 1.12581   Valid Loss: 1.06107\n",
            "[ Epoch 1344/10000 ] Train Loss: 1.12625   Valid Loss: 1.05993\n",
            "Early Stop Saving Model on Epoch 1344/10000\n",
            "[ Epoch 1345/10000 ] Train Loss: 1.12639   Valid Loss: 1.06325\n",
            "[ Epoch 1346/10000 ] Train Loss: 1.12890   Valid Loss: 1.06367\n",
            "[ Epoch 1347/10000 ] Train Loss: 1.12556   Valid Loss: 1.06181\n",
            "[ Epoch 1348/10000 ] Train Loss: 1.12607   Valid Loss: 1.06229\n",
            "[ Epoch 1349/10000 ] Train Loss: 1.12678   Valid Loss: 1.05932\n",
            "Early Stop Saving Model on Epoch 1349/10000\n",
            "[ Epoch 1350/10000 ] Train Loss: 1.12727   Valid Loss: 1.06272\n",
            "[ Epoch 1351/10000 ] Train Loss: 1.12643   Valid Loss: 1.06174\n",
            "[ Epoch 1352/10000 ] Train Loss: 1.12646   Valid Loss: 1.06059\n",
            "[ Epoch 1353/10000 ] Train Loss: 1.12662   Valid Loss: 1.06297\n",
            "[ Epoch 1354/10000 ] Train Loss: 1.12923   Valid Loss: 1.06393\n",
            "[ Epoch 1355/10000 ] Train Loss: 1.12959   Valid Loss: 1.06059\n",
            "[ Epoch 1356/10000 ] Train Loss: 1.13289   Valid Loss: 1.06969\n",
            "[ Epoch 1357/10000 ] Train Loss: 1.13387   Valid Loss: 1.05952\n",
            "[ Epoch 1358/10000 ] Train Loss: 1.12496   Valid Loss: 1.05970\n",
            "[ Epoch 1359/10000 ] Train Loss: 1.12372   Valid Loss: 1.06056\n",
            "[ Epoch 1360/10000 ] Train Loss: 1.12638   Valid Loss: 1.06095\n",
            "[ Epoch 1361/10000 ] Train Loss: 1.12562   Valid Loss: 1.05930\n",
            "Early Stop Saving Model on Epoch 1361/10000\n",
            "[ Epoch 1362/10000 ] Train Loss: 1.12328   Valid Loss: 1.05867\n",
            "Early Stop Saving Model on Epoch 1362/10000\n",
            "[ Epoch 1363/10000 ] Train Loss: 1.12442   Valid Loss: 1.06027\n",
            "[ Epoch 1364/10000 ] Train Loss: 1.12387   Valid Loss: 1.05966\n",
            "[ Epoch 1365/10000 ] Train Loss: 1.12508   Valid Loss: 1.05809\n",
            "Early Stop Saving Model on Epoch 1365/10000\n",
            "[ Epoch 1366/10000 ] Train Loss: 1.12601   Valid Loss: 1.05894\n",
            "[ Epoch 1367/10000 ] Train Loss: 1.12656   Valid Loss: 1.06071\n",
            "[ Epoch 1368/10000 ] Train Loss: 1.12629   Valid Loss: 1.06036\n",
            "[ Epoch 1369/10000 ] Train Loss: 1.12535   Valid Loss: 1.06013\n",
            "[ Epoch 1370/10000 ] Train Loss: 1.12314   Valid Loss: 1.06090\n",
            "[ Epoch 1371/10000 ] Train Loss: 1.12409   Valid Loss: 1.05834\n",
            "[ Epoch 1372/10000 ] Train Loss: 1.12507   Valid Loss: 1.06114\n",
            "[ Epoch 1373/10000 ] Train Loss: 1.12520   Valid Loss: 1.06072\n",
            "[ Epoch 1374/10000 ] Train Loss: 1.12409   Valid Loss: 1.05844\n",
            "[ Epoch 1375/10000 ] Train Loss: 1.12525   Valid Loss: 1.05815\n",
            "[ Epoch 1376/10000 ] Train Loss: 1.12524   Valid Loss: 1.05878\n",
            "[ Epoch 1377/10000 ] Train Loss: 1.12602   Valid Loss: 1.06171\n",
            "[ Epoch 1378/10000 ] Train Loss: 1.12290   Valid Loss: 1.06451\n",
            "[ Epoch 1379/10000 ] Train Loss: 1.12495   Valid Loss: 1.05732\n",
            "Early Stop Saving Model on Epoch 1379/10000\n",
            "[ Epoch 1380/10000 ] Train Loss: 1.12412   Valid Loss: 1.05865\n",
            "[ Epoch 1381/10000 ] Train Loss: 1.12484   Valid Loss: 1.05737\n",
            "[ Epoch 1382/10000 ] Train Loss: 1.12410   Valid Loss: 1.05775\n",
            "[ Epoch 1383/10000 ] Train Loss: 1.12393   Valid Loss: 1.05817\n",
            "[ Epoch 1384/10000 ] Train Loss: 1.12409   Valid Loss: 1.05770\n",
            "[ Epoch 1385/10000 ] Train Loss: 1.12448   Valid Loss: 1.05846\n",
            "[ Epoch 1386/10000 ] Train Loss: 1.12275   Valid Loss: 1.05707\n",
            "Early Stop Saving Model on Epoch 1386/10000\n",
            "[ Epoch 1387/10000 ] Train Loss: 1.12324   Valid Loss: 1.05641\n",
            "Early Stop Saving Model on Epoch 1387/10000\n",
            "[ Epoch 1388/10000 ] Train Loss: 1.12242   Valid Loss: 1.05695\n",
            "[ Epoch 1389/10000 ] Train Loss: 1.12270   Valid Loss: 1.05764\n",
            "[ Epoch 1390/10000 ] Train Loss: 1.12550   Valid Loss: 1.05868\n",
            "[ Epoch 1391/10000 ] Train Loss: 1.12661   Valid Loss: 1.05909\n",
            "[ Epoch 1392/10000 ] Train Loss: 1.12334   Valid Loss: 1.05623\n",
            "Early Stop Saving Model on Epoch 1392/10000\n",
            "[ Epoch 1393/10000 ] Train Loss: 1.12348   Valid Loss: 1.05722\n",
            "[ Epoch 1394/10000 ] Train Loss: 1.12211   Valid Loss: 1.06035\n",
            "[ Epoch 1395/10000 ] Train Loss: 1.12295   Valid Loss: 1.05904\n",
            "[ Epoch 1396/10000 ] Train Loss: 1.12502   Valid Loss: 1.05580\n",
            "Early Stop Saving Model on Epoch 1396/10000\n",
            "[ Epoch 1397/10000 ] Train Loss: 1.12210   Valid Loss: 1.05618\n",
            "[ Epoch 1398/10000 ] Train Loss: 1.12246   Valid Loss: 1.05665\n",
            "[ Epoch 1399/10000 ] Train Loss: 1.12085   Valid Loss: 1.05564\n",
            "Early Stop Saving Model on Epoch 1399/10000\n",
            "[ Epoch 1400/10000 ] Train Loss: 1.12188   Valid Loss: 1.05614\n",
            "[ Epoch 1401/10000 ] Train Loss: 1.12288   Valid Loss: 1.05584\n",
            "[ Epoch 1402/10000 ] Train Loss: 1.11883   Valid Loss: 1.05661\n",
            "[ Epoch 1403/10000 ] Train Loss: 1.12153   Valid Loss: 1.05613\n",
            "[ Epoch 1404/10000 ] Train Loss: 1.12185   Valid Loss: 1.05641\n",
            "[ Epoch 1405/10000 ] Train Loss: 1.12405   Valid Loss: 1.05833\n",
            "[ Epoch 1406/10000 ] Train Loss: 1.12323   Valid Loss: 1.05523\n",
            "Early Stop Saving Model on Epoch 1406/10000\n",
            "[ Epoch 1407/10000 ] Train Loss: 1.12046   Valid Loss: 1.05568\n",
            "[ Epoch 1408/10000 ] Train Loss: 1.11997   Valid Loss: 1.05515\n",
            "Early Stop Saving Model on Epoch 1408/10000\n",
            "[ Epoch 1409/10000 ] Train Loss: 1.12033   Valid Loss: 1.05577\n",
            "[ Epoch 1410/10000 ] Train Loss: 1.12196   Valid Loss: 1.05580\n",
            "[ Epoch 1411/10000 ] Train Loss: 1.12248   Valid Loss: 1.05554\n",
            "[ Epoch 1412/10000 ] Train Loss: 1.12231   Valid Loss: 1.05590\n",
            "[ Epoch 1413/10000 ] Train Loss: 1.12010   Valid Loss: 1.05633\n",
            "[ Epoch 1414/10000 ] Train Loss: 1.12198   Valid Loss: 1.05642\n",
            "[ Epoch 1415/10000 ] Train Loss: 1.12316   Valid Loss: 1.05491\n",
            "Early Stop Saving Model on Epoch 1415/10000\n",
            "[ Epoch 1416/10000 ] Train Loss: 1.12001   Valid Loss: 1.05578\n",
            "[ Epoch 1417/10000 ] Train Loss: 1.12274   Valid Loss: 1.05535\n",
            "[ Epoch 1418/10000 ] Train Loss: 1.12293   Valid Loss: 1.05695\n",
            "[ Epoch 1419/10000 ] Train Loss: 1.12049   Valid Loss: 1.05585\n",
            "[ Epoch 1420/10000 ] Train Loss: 1.12175   Valid Loss: 1.05392\n",
            "Early Stop Saving Model on Epoch 1420/10000\n",
            "[ Epoch 1421/10000 ] Train Loss: 1.12049   Valid Loss: 1.05438\n",
            "[ Epoch 1422/10000 ] Train Loss: 1.12073   Valid Loss: 1.05406\n",
            "[ Epoch 1423/10000 ] Train Loss: 1.11887   Valid Loss: 1.05383\n",
            "Early Stop Saving Model on Epoch 1423/10000\n",
            "[ Epoch 1424/10000 ] Train Loss: 1.12001   Valid Loss: 1.05356\n",
            "Early Stop Saving Model on Epoch 1424/10000\n",
            "[ Epoch 1425/10000 ] Train Loss: 1.11891   Valid Loss: 1.05540\n",
            "[ Epoch 1426/10000 ] Train Loss: 1.11911   Valid Loss: 1.05345\n",
            "Early Stop Saving Model on Epoch 1426/10000\n",
            "[ Epoch 1427/10000 ] Train Loss: 1.11941   Valid Loss: 1.05443\n",
            "[ Epoch 1428/10000 ] Train Loss: 1.11972   Valid Loss: 1.05349\n",
            "[ Epoch 1429/10000 ] Train Loss: 1.11951   Valid Loss: 1.05357\n",
            "[ Epoch 1430/10000 ] Train Loss: 1.11972   Valid Loss: 1.05313\n",
            "Early Stop Saving Model on Epoch 1430/10000\n",
            "[ Epoch 1431/10000 ] Train Loss: 1.11834   Valid Loss: 1.05417\n",
            "[ Epoch 1432/10000 ] Train Loss: 1.11840   Valid Loss: 1.05551\n",
            "[ Epoch 1433/10000 ] Train Loss: 1.11944   Valid Loss: 1.05611\n",
            "[ Epoch 1434/10000 ] Train Loss: 1.12307   Valid Loss: 1.05397\n",
            "[ Epoch 1435/10000 ] Train Loss: 1.12306   Valid Loss: 1.05466\n",
            "[ Epoch 1436/10000 ] Train Loss: 1.12238   Valid Loss: 1.05464\n",
            "[ Epoch 1437/10000 ] Train Loss: 1.11933   Valid Loss: 1.05508\n",
            "[ Epoch 1438/10000 ] Train Loss: 1.11855   Valid Loss: 1.05438\n",
            "[ Epoch 1439/10000 ] Train Loss: 1.11890   Valid Loss: 1.05209\n",
            "Early Stop Saving Model on Epoch 1439/10000\n",
            "[ Epoch 1440/10000 ] Train Loss: 1.11886   Valid Loss: 1.05281\n",
            "[ Epoch 1441/10000 ] Train Loss: 1.11810   Valid Loss: 1.05280\n",
            "[ Epoch 1442/10000 ] Train Loss: 1.11664   Valid Loss: 1.05254\n",
            "[ Epoch 1443/10000 ] Train Loss: 1.11752   Valid Loss: 1.05462\n",
            "[ Epoch 1444/10000 ] Train Loss: 1.12276   Valid Loss: 1.05551\n",
            "[ Epoch 1445/10000 ] Train Loss: 1.12233   Valid Loss: 1.05235\n",
            "[ Epoch 1446/10000 ] Train Loss: 1.11846   Valid Loss: 1.05457\n",
            "[ Epoch 1447/10000 ] Train Loss: 1.11860   Valid Loss: 1.05447\n",
            "[ Epoch 1448/10000 ] Train Loss: 1.11770   Valid Loss: 1.05309\n",
            "[ Epoch 1449/10000 ] Train Loss: 1.11806   Valid Loss: 1.05067\n",
            "Early Stop Saving Model on Epoch 1449/10000\n",
            "[ Epoch 1450/10000 ] Train Loss: 1.11733   Valid Loss: 1.05203\n",
            "[ Epoch 1451/10000 ] Train Loss: 1.11802   Valid Loss: 1.05354\n",
            "[ Epoch 1452/10000 ] Train Loss: 1.12024   Valid Loss: 1.05084\n",
            "[ Epoch 1453/10000 ] Train Loss: 1.12020   Valid Loss: 1.05253\n",
            "[ Epoch 1454/10000 ] Train Loss: 1.11869   Valid Loss: 1.05009\n",
            "Early Stop Saving Model on Epoch 1454/10000\n",
            "[ Epoch 1455/10000 ] Train Loss: 1.11598   Valid Loss: 1.05041\n",
            "[ Epoch 1456/10000 ] Train Loss: 1.11551   Valid Loss: 1.05150\n",
            "[ Epoch 1457/10000 ] Train Loss: 1.11888   Valid Loss: 1.05143\n",
            "[ Epoch 1458/10000 ] Train Loss: 1.11740   Valid Loss: 1.05030\n",
            "[ Epoch 1459/10000 ] Train Loss: 1.11620   Valid Loss: 1.05057\n",
            "[ Epoch 1460/10000 ] Train Loss: 1.11652   Valid Loss: 1.05249\n",
            "[ Epoch 1461/10000 ] Train Loss: 1.11793   Valid Loss: 1.05156\n",
            "[ Epoch 1462/10000 ] Train Loss: 1.11624   Valid Loss: 1.05100\n",
            "[ Epoch 1463/10000 ] Train Loss: 1.11674   Valid Loss: 1.05193\n",
            "[ Epoch 1464/10000 ] Train Loss: 1.11582   Valid Loss: 1.05296\n",
            "[ Epoch 1465/10000 ] Train Loss: 1.11555   Valid Loss: 1.04938\n",
            "Early Stop Saving Model on Epoch 1465/10000\n",
            "[ Epoch 1466/10000 ] Train Loss: 1.11670   Valid Loss: 1.05063\n",
            "[ Epoch 1467/10000 ] Train Loss: 1.11549   Valid Loss: 1.04961\n",
            "[ Epoch 1468/10000 ] Train Loss: 1.11617   Valid Loss: 1.04983\n",
            "[ Epoch 1469/10000 ] Train Loss: 1.11464   Valid Loss: 1.04982\n",
            "[ Epoch 1470/10000 ] Train Loss: 1.11651   Valid Loss: 1.04951\n",
            "[ Epoch 1471/10000 ] Train Loss: 1.11513   Valid Loss: 1.04960\n",
            "[ Epoch 1472/10000 ] Train Loss: 1.11587   Valid Loss: 1.04878\n",
            "Early Stop Saving Model on Epoch 1472/10000\n",
            "[ Epoch 1473/10000 ] Train Loss: 1.11701   Valid Loss: 1.05103\n",
            "[ Epoch 1474/10000 ] Train Loss: 1.11558   Valid Loss: 1.04870\n",
            "Early Stop Saving Model on Epoch 1474/10000\n",
            "[ Epoch 1475/10000 ] Train Loss: 1.11452   Valid Loss: 1.05019\n",
            "[ Epoch 1476/10000 ] Train Loss: 1.11663   Valid Loss: 1.05110\n",
            "[ Epoch 1477/10000 ] Train Loss: 1.11694   Valid Loss: 1.04917\n",
            "[ Epoch 1478/10000 ] Train Loss: 1.11520   Valid Loss: 1.04926\n",
            "[ Epoch 1479/10000 ] Train Loss: 1.11273   Valid Loss: 1.04887\n",
            "[ Epoch 1480/10000 ] Train Loss: 1.11589   Valid Loss: 1.05011\n",
            "[ Epoch 1481/10000 ] Train Loss: 1.11595   Valid Loss: 1.04785\n",
            "Early Stop Saving Model on Epoch 1481/10000\n",
            "[ Epoch 1482/10000 ] Train Loss: 1.11454   Valid Loss: 1.04939\n",
            "[ Epoch 1483/10000 ] Train Loss: 1.11419   Valid Loss: 1.04776\n",
            "Early Stop Saving Model on Epoch 1483/10000\n",
            "[ Epoch 1484/10000 ] Train Loss: 1.11415   Valid Loss: 1.04825\n",
            "[ Epoch 1485/10000 ] Train Loss: 1.11468   Valid Loss: 1.05221\n",
            "[ Epoch 1486/10000 ] Train Loss: 1.11614   Valid Loss: 1.04715\n",
            "Early Stop Saving Model on Epoch 1486/10000\n",
            "[ Epoch 1487/10000 ] Train Loss: 1.11364   Valid Loss: 1.04805\n",
            "[ Epoch 1488/10000 ] Train Loss: 1.11415   Valid Loss: 1.04947\n",
            "[ Epoch 1489/10000 ] Train Loss: 1.11478   Valid Loss: 1.04709\n",
            "Early Stop Saving Model on Epoch 1489/10000\n",
            "[ Epoch 1490/10000 ] Train Loss: 1.11262   Valid Loss: 1.04889\n",
            "[ Epoch 1491/10000 ] Train Loss: 1.11329   Valid Loss: 1.04779\n",
            "[ Epoch 1492/10000 ] Train Loss: 1.11209   Valid Loss: 1.04877\n",
            "[ Epoch 1493/10000 ] Train Loss: 1.11325   Valid Loss: 1.04986\n",
            "[ Epoch 1494/10000 ] Train Loss: 1.11772   Valid Loss: 1.04884\n",
            "[ Epoch 1495/10000 ] Train Loss: 1.11406   Valid Loss: 1.04667\n",
            "Early Stop Saving Model on Epoch 1495/10000\n",
            "[ Epoch 1496/10000 ] Train Loss: 1.11420   Valid Loss: 1.05112\n",
            "[ Epoch 1497/10000 ] Train Loss: 1.11298   Valid Loss: 1.04813\n",
            "[ Epoch 1498/10000 ] Train Loss: 1.11248   Valid Loss: 1.04825\n",
            "[ Epoch 1499/10000 ] Train Loss: 1.11148   Valid Loss: 1.04821\n",
            "[ Epoch 1500/10000 ] Train Loss: 1.11398   Valid Loss: 1.04896\n",
            "[ Epoch 1501/10000 ] Train Loss: 1.11407   Valid Loss: 1.04913\n",
            "[ Epoch 1502/10000 ] Train Loss: 1.11710   Valid Loss: 1.04572\n",
            "Early Stop Saving Model on Epoch 1502/10000\n",
            "[ Epoch 1503/10000 ] Train Loss: 1.11432   Valid Loss: 1.04854\n",
            "[ Epoch 1504/10000 ] Train Loss: 1.11398   Valid Loss: 1.05006\n",
            "[ Epoch 1505/10000 ] Train Loss: 1.11455   Valid Loss: 1.04989\n",
            "[ Epoch 1506/10000 ] Train Loss: 1.11341   Valid Loss: 1.04699\n",
            "[ Epoch 1507/10000 ] Train Loss: 1.11133   Valid Loss: 1.04803\n",
            "[ Epoch 1508/10000 ] Train Loss: 1.11090   Valid Loss: 1.04645\n",
            "[ Epoch 1509/10000 ] Train Loss: 1.11299   Valid Loss: 1.04504\n",
            "Early Stop Saving Model on Epoch 1509/10000\n",
            "[ Epoch 1510/10000 ] Train Loss: 1.11448   Valid Loss: 1.04962\n",
            "[ Epoch 1511/10000 ] Train Loss: 1.11089   Valid Loss: 1.04626\n",
            "[ Epoch 1512/10000 ] Train Loss: 1.11365   Valid Loss: 1.04551\n",
            "[ Epoch 1513/10000 ] Train Loss: 1.11186   Valid Loss: 1.04611\n",
            "[ Epoch 1514/10000 ] Train Loss: 1.11155   Valid Loss: 1.04719\n",
            "[ Epoch 1515/10000 ] Train Loss: 1.11077   Valid Loss: 1.04540\n",
            "[ Epoch 1516/10000 ] Train Loss: 1.11233   Valid Loss: 1.04582\n",
            "[ Epoch 1517/10000 ] Train Loss: 1.11096   Valid Loss: 1.04582\n",
            "[ Epoch 1518/10000 ] Train Loss: 1.11274   Valid Loss: 1.04549\n",
            "[ Epoch 1519/10000 ] Train Loss: 1.11114   Valid Loss: 1.04572\n",
            "[ Epoch 1520/10000 ] Train Loss: 1.11176   Valid Loss: 1.05197\n",
            "[ Epoch 1521/10000 ] Train Loss: 1.11457   Valid Loss: 1.04874\n",
            "[ Epoch 1522/10000 ] Train Loss: 1.11239   Valid Loss: 1.04505\n",
            "[ Epoch 1523/10000 ] Train Loss: 1.11143   Valid Loss: 1.04709\n",
            "[ Epoch 1524/10000 ] Train Loss: 1.11058   Valid Loss: 1.04563\n",
            "[ Epoch 1525/10000 ] Train Loss: 1.10931   Valid Loss: 1.04496\n",
            "Early Stop Saving Model on Epoch 1525/10000\n",
            "[ Epoch 1526/10000 ] Train Loss: 1.10978   Valid Loss: 1.04547\n",
            "[ Epoch 1527/10000 ] Train Loss: 1.11223   Valid Loss: 1.04792\n",
            "[ Epoch 1528/10000 ] Train Loss: 1.11713   Valid Loss: 1.04654\n",
            "[ Epoch 1529/10000 ] Train Loss: 1.11394   Valid Loss: 1.04472\n",
            "Early Stop Saving Model on Epoch 1529/10000\n",
            "[ Epoch 1530/10000 ] Train Loss: 1.11297   Valid Loss: 1.04766\n",
            "[ Epoch 1531/10000 ] Train Loss: 1.11445   Valid Loss: 1.04547\n",
            "[ Epoch 1532/10000 ] Train Loss: 1.11007   Valid Loss: 1.04355\n",
            "Early Stop Saving Model on Epoch 1532/10000\n",
            "[ Epoch 1533/10000 ] Train Loss: 1.11157   Valid Loss: 1.04474\n",
            "[ Epoch 1534/10000 ] Train Loss: 1.11279   Valid Loss: 1.05011\n",
            "[ Epoch 1535/10000 ] Train Loss: 1.11220   Valid Loss: 1.04899\n",
            "[ Epoch 1536/10000 ] Train Loss: 1.10989   Valid Loss: 1.04851\n",
            "[ Epoch 1537/10000 ] Train Loss: 1.11270   Valid Loss: 1.04917\n",
            "[ Epoch 1538/10000 ] Train Loss: 1.11013   Valid Loss: 1.04495\n",
            "[ Epoch 1539/10000 ] Train Loss: 1.11194   Valid Loss: 1.04477\n",
            "[ Epoch 1540/10000 ] Train Loss: 1.11071   Valid Loss: 1.04507\n",
            "[ Epoch 1541/10000 ] Train Loss: 1.10949   Valid Loss: 1.04237\n",
            "Early Stop Saving Model on Epoch 1541/10000\n",
            "[ Epoch 1542/10000 ] Train Loss: 1.10872   Valid Loss: 1.04427\n",
            "[ Epoch 1543/10000 ] Train Loss: 1.11133   Valid Loss: 1.04418\n",
            "[ Epoch 1544/10000 ] Train Loss: 1.10873   Valid Loss: 1.04278\n",
            "[ Epoch 1545/10000 ] Train Loss: 1.10918   Valid Loss: 1.04516\n",
            "[ Epoch 1546/10000 ] Train Loss: 1.10959   Valid Loss: 1.04387\n",
            "[ Epoch 1547/10000 ] Train Loss: 1.10956   Valid Loss: 1.04313\n",
            "[ Epoch 1548/10000 ] Train Loss: 1.11130   Valid Loss: 1.04381\n",
            "[ Epoch 1549/10000 ] Train Loss: 1.11254   Valid Loss: 1.04458\n",
            "[ Epoch 1550/10000 ] Train Loss: 1.10929   Valid Loss: 1.04507\n",
            "[ Epoch 1551/10000 ] Train Loss: 1.10859   Valid Loss: 1.04406\n",
            "[ Epoch 1552/10000 ] Train Loss: 1.10977   Valid Loss: 1.04259\n",
            "[ Epoch 1553/10000 ] Train Loss: 1.11147   Valid Loss: 1.04896\n",
            "[ Epoch 1554/10000 ] Train Loss: 1.11015   Valid Loss: 1.04190\n",
            "Early Stop Saving Model on Epoch 1554/10000\n",
            "[ Epoch 1555/10000 ] Train Loss: 1.10787   Valid Loss: 1.04188\n",
            "Early Stop Saving Model on Epoch 1555/10000\n",
            "[ Epoch 1556/10000 ] Train Loss: 1.10877   Valid Loss: 1.04295\n",
            "[ Epoch 1557/10000 ] Train Loss: 1.10856   Valid Loss: 1.04201\n",
            "[ Epoch 1558/10000 ] Train Loss: 1.10766   Valid Loss: 1.04228\n",
            "[ Epoch 1559/10000 ] Train Loss: 1.10723   Valid Loss: 1.04248\n",
            "[ Epoch 1560/10000 ] Train Loss: 1.10688   Valid Loss: 1.04194\n",
            "[ Epoch 1561/10000 ] Train Loss: 1.10937   Valid Loss: 1.04443\n",
            "[ Epoch 1562/10000 ] Train Loss: 1.11038   Valid Loss: 1.04171\n",
            "Early Stop Saving Model on Epoch 1562/10000\n",
            "[ Epoch 1563/10000 ] Train Loss: 1.11185   Valid Loss: 1.04810\n",
            "[ Epoch 1564/10000 ] Train Loss: 1.10970   Valid Loss: 1.04364\n",
            "[ Epoch 1565/10000 ] Train Loss: 1.11127   Valid Loss: 1.04173\n",
            "[ Epoch 1566/10000 ] Train Loss: 1.10808   Valid Loss: 1.04280\n",
            "[ Epoch 1567/10000 ] Train Loss: 1.10725   Valid Loss: 1.04357\n",
            "[ Epoch 1568/10000 ] Train Loss: 1.10754   Valid Loss: 1.04138\n",
            "Early Stop Saving Model on Epoch 1568/10000\n",
            "[ Epoch 1569/10000 ] Train Loss: 1.10796   Valid Loss: 1.04149\n",
            "[ Epoch 1570/10000 ] Train Loss: 1.10671   Valid Loss: 1.04018\n",
            "Early Stop Saving Model on Epoch 1570/10000\n",
            "[ Epoch 1571/10000 ] Train Loss: 1.10825   Valid Loss: 1.04134\n",
            "[ Epoch 1572/10000 ] Train Loss: 1.10706   Valid Loss: 1.04102\n",
            "[ Epoch 1573/10000 ] Train Loss: 1.10900   Valid Loss: 1.04117\n",
            "[ Epoch 1574/10000 ] Train Loss: 1.10508   Valid Loss: 1.04210\n",
            "[ Epoch 1575/10000 ] Train Loss: 1.10726   Valid Loss: 1.04067\n",
            "[ Epoch 1576/10000 ] Train Loss: 1.10547   Valid Loss: 1.04047\n",
            "[ Epoch 1577/10000 ] Train Loss: 1.10809   Valid Loss: 1.04219\n",
            "[ Epoch 1578/10000 ] Train Loss: 1.10859   Valid Loss: 1.04398\n",
            "[ Epoch 1579/10000 ] Train Loss: 1.10997   Valid Loss: 1.03978\n",
            "Early Stop Saving Model on Epoch 1579/10000\n",
            "[ Epoch 1580/10000 ] Train Loss: 1.10945   Valid Loss: 1.04238\n",
            "[ Epoch 1581/10000 ] Train Loss: 1.10799   Valid Loss: 1.04352\n",
            "[ Epoch 1582/10000 ] Train Loss: 1.10738   Valid Loss: 1.04088\n",
            "[ Epoch 1583/10000 ] Train Loss: 1.10780   Valid Loss: 1.03977\n",
            "Early Stop Saving Model on Epoch 1583/10000\n",
            "[ Epoch 1584/10000 ] Train Loss: 1.10601   Valid Loss: 1.04235\n",
            "[ Epoch 1585/10000 ] Train Loss: 1.10723   Valid Loss: 1.04144\n",
            "[ Epoch 1586/10000 ] Train Loss: 1.10637   Valid Loss: 1.04105\n",
            "[ Epoch 1587/10000 ] Train Loss: 1.10856   Valid Loss: 1.04155\n",
            "[ Epoch 1588/10000 ] Train Loss: 1.10751   Valid Loss: 1.04266\n",
            "[ Epoch 1589/10000 ] Train Loss: 1.11049   Valid Loss: 1.04095\n",
            "[ Epoch 1590/10000 ] Train Loss: 1.10816   Valid Loss: 1.04062\n",
            "[ Epoch 1591/10000 ] Train Loss: 1.10705   Valid Loss: 1.03965\n",
            "Early Stop Saving Model on Epoch 1591/10000\n",
            "[ Epoch 1592/10000 ] Train Loss: 1.10635   Valid Loss: 1.03915\n",
            "Early Stop Saving Model on Epoch 1592/10000\n",
            "[ Epoch 1593/10000 ] Train Loss: 1.10514   Valid Loss: 1.03996\n",
            "[ Epoch 1594/10000 ] Train Loss: 1.10514   Valid Loss: 1.04010\n",
            "[ Epoch 1595/10000 ] Train Loss: 1.10621   Valid Loss: 1.04194\n",
            "[ Epoch 1596/10000 ] Train Loss: 1.10534   Valid Loss: 1.04143\n",
            "[ Epoch 1597/10000 ] Train Loss: 1.10891   Valid Loss: 1.04029\n",
            "[ Epoch 1598/10000 ] Train Loss: 1.10482   Valid Loss: 1.04142\n",
            "[ Epoch 1599/10000 ] Train Loss: 1.10394   Valid Loss: 1.03994\n",
            "[ Epoch 1600/10000 ] Train Loss: 1.10462   Valid Loss: 1.03995\n",
            "[ Epoch 1601/10000 ] Train Loss: 1.10490   Valid Loss: 1.03904\n",
            "Early Stop Saving Model on Epoch 1601/10000\n",
            "[ Epoch 1602/10000 ] Train Loss: 1.10521   Valid Loss: 1.04093\n",
            "[ Epoch 1603/10000 ] Train Loss: 1.10411   Valid Loss: 1.03981\n",
            "[ Epoch 1604/10000 ] Train Loss: 1.10706   Valid Loss: 1.03901\n",
            "Early Stop Saving Model on Epoch 1604/10000\n",
            "[ Epoch 1605/10000 ] Train Loss: 1.10596   Valid Loss: 1.04192\n",
            "[ Epoch 1606/10000 ] Train Loss: 1.10811   Valid Loss: 1.03960\n",
            "[ Epoch 1607/10000 ] Train Loss: 1.10631   Valid Loss: 1.04019\n",
            "[ Epoch 1608/10000 ] Train Loss: 1.10561   Valid Loss: 1.03904\n",
            "[ Epoch 1609/10000 ] Train Loss: 1.10616   Valid Loss: 1.03803\n",
            "Early Stop Saving Model on Epoch 1609/10000\n",
            "[ Epoch 1610/10000 ] Train Loss: 1.10500   Valid Loss: 1.03907\n",
            "[ Epoch 1611/10000 ] Train Loss: 1.10505   Valid Loss: 1.03862\n",
            "[ Epoch 1612/10000 ] Train Loss: 1.10408   Valid Loss: 1.03872\n",
            "[ Epoch 1613/10000 ] Train Loss: 1.10357   Valid Loss: 1.03780\n",
            "Early Stop Saving Model on Epoch 1613/10000\n",
            "[ Epoch 1614/10000 ] Train Loss: 1.10398   Valid Loss: 1.03866\n",
            "[ Epoch 1615/10000 ] Train Loss: 1.10529   Valid Loss: 1.04068\n",
            "[ Epoch 1616/10000 ] Train Loss: 1.10349   Valid Loss: 1.04315\n",
            "[ Epoch 1617/10000 ] Train Loss: 1.10941   Valid Loss: 1.03845\n",
            "[ Epoch 1618/10000 ] Train Loss: 1.10504   Valid Loss: 1.03915\n",
            "[ Epoch 1619/10000 ] Train Loss: 1.10490   Valid Loss: 1.04145\n",
            "[ Epoch 1620/10000 ] Train Loss: 1.10546   Valid Loss: 1.03780\n",
            "[ Epoch 1621/10000 ] Train Loss: 1.10413   Valid Loss: 1.03761\n",
            "Early Stop Saving Model on Epoch 1621/10000\n",
            "[ Epoch 1622/10000 ] Train Loss: 1.10307   Valid Loss: 1.03829\n",
            "[ Epoch 1623/10000 ] Train Loss: 1.10432   Valid Loss: 1.03965\n",
            "[ Epoch 1624/10000 ] Train Loss: 1.10475   Valid Loss: 1.03697\n",
            "Early Stop Saving Model on Epoch 1624/10000\n",
            "[ Epoch 1625/10000 ] Train Loss: 1.10345   Valid Loss: 1.03837\n",
            "[ Epoch 1626/10000 ] Train Loss: 1.10505   Valid Loss: 1.03916\n",
            "[ Epoch 1627/10000 ] Train Loss: 1.10590   Valid Loss: 1.03811\n",
            "[ Epoch 1628/10000 ] Train Loss: 1.10412   Valid Loss: 1.03834\n",
            "[ Epoch 1629/10000 ] Train Loss: 1.10443   Valid Loss: 1.03761\n",
            "[ Epoch 1630/10000 ] Train Loss: 1.10489   Valid Loss: 1.03953\n",
            "[ Epoch 1631/10000 ] Train Loss: 1.10343   Valid Loss: 1.03888\n",
            "[ Epoch 1632/10000 ] Train Loss: 1.10345   Valid Loss: 1.03668\n",
            "Early Stop Saving Model on Epoch 1632/10000\n",
            "[ Epoch 1633/10000 ] Train Loss: 1.10301   Valid Loss: 1.03661\n",
            "Early Stop Saving Model on Epoch 1633/10000\n",
            "[ Epoch 1634/10000 ] Train Loss: 1.10510   Valid Loss: 1.03946\n",
            "[ Epoch 1635/10000 ] Train Loss: 1.10703   Valid Loss: 1.04106\n",
            "[ Epoch 1636/10000 ] Train Loss: 1.10295   Valid Loss: 1.03737\n",
            "[ Epoch 1637/10000 ] Train Loss: 1.10274   Valid Loss: 1.03797\n",
            "[ Epoch 1638/10000 ] Train Loss: 1.10407   Valid Loss: 1.03956\n",
            "[ Epoch 1639/10000 ] Train Loss: 1.10437   Valid Loss: 1.03775\n",
            "[ Epoch 1640/10000 ] Train Loss: 1.10289   Valid Loss: 1.03652\n",
            "Early Stop Saving Model on Epoch 1640/10000\n",
            "[ Epoch 1641/10000 ] Train Loss: 1.10367   Valid Loss: 1.03809\n",
            "[ Epoch 1642/10000 ] Train Loss: 1.10561   Valid Loss: 1.03652\n",
            "[ Epoch 1643/10000 ] Train Loss: 1.10361   Valid Loss: 1.03773\n",
            "[ Epoch 1644/10000 ] Train Loss: 1.10201   Valid Loss: 1.03688\n",
            "[ Epoch 1645/10000 ] Train Loss: 1.10152   Valid Loss: 1.03662\n",
            "[ Epoch 1646/10000 ] Train Loss: 1.10162   Valid Loss: 1.03626\n",
            "Early Stop Saving Model on Epoch 1646/10000\n",
            "[ Epoch 1647/10000 ] Train Loss: 1.10194   Valid Loss: 1.03637\n",
            "[ Epoch 1648/10000 ] Train Loss: 1.10257   Valid Loss: 1.03616\n",
            "Early Stop Saving Model on Epoch 1648/10000\n",
            "[ Epoch 1649/10000 ] Train Loss: 1.10327   Valid Loss: 1.03863\n",
            "[ Epoch 1650/10000 ] Train Loss: 1.10168   Valid Loss: 1.04062\n",
            "[ Epoch 1651/10000 ] Train Loss: 1.10526   Valid Loss: 1.03743\n",
            "[ Epoch 1652/10000 ] Train Loss: 1.10124   Valid Loss: 1.04096\n",
            "[ Epoch 1653/10000 ] Train Loss: 1.10561   Valid Loss: 1.03667\n",
            "[ Epoch 1654/10000 ] Train Loss: 1.10283   Valid Loss: 1.03814\n",
            "[ Epoch 1655/10000 ] Train Loss: 1.10494   Valid Loss: 1.03710\n",
            "[ Epoch 1656/10000 ] Train Loss: 1.10288   Valid Loss: 1.03640\n",
            "[ Epoch 1657/10000 ] Train Loss: 1.10181   Valid Loss: 1.03545\n",
            "Early Stop Saving Model on Epoch 1657/10000\n",
            "[ Epoch 1658/10000 ] Train Loss: 1.10418   Valid Loss: 1.04092\n",
            "[ Epoch 1659/10000 ] Train Loss: 1.10412   Valid Loss: 1.04115\n",
            "[ Epoch 1660/10000 ] Train Loss: 1.10408   Valid Loss: 1.03643\n",
            "[ Epoch 1661/10000 ] Train Loss: 1.10161   Valid Loss: 1.03551\n",
            "[ Epoch 1662/10000 ] Train Loss: 1.10139   Valid Loss: 1.03589\n",
            "[ Epoch 1663/10000 ] Train Loss: 1.10218   Valid Loss: 1.03624\n",
            "[ Epoch 1664/10000 ] Train Loss: 1.10109   Valid Loss: 1.03969\n",
            "[ Epoch 1665/10000 ] Train Loss: 1.10293   Valid Loss: 1.03584\n",
            "[ Epoch 1666/10000 ] Train Loss: 1.10299   Valid Loss: 1.03653\n",
            "[ Epoch 1667/10000 ] Train Loss: 1.10356   Valid Loss: 1.03557\n",
            "[ Epoch 1668/10000 ] Train Loss: 1.10144   Valid Loss: 1.03478\n",
            "Early Stop Saving Model on Epoch 1668/10000\n",
            "[ Epoch 1669/10000 ] Train Loss: 1.10210   Valid Loss: 1.03867\n",
            "[ Epoch 1670/10000 ] Train Loss: 1.10073   Valid Loss: 1.03787\n",
            "[ Epoch 1671/10000 ] Train Loss: 1.10273   Valid Loss: 1.03559\n",
            "[ Epoch 1672/10000 ] Train Loss: 1.10123   Valid Loss: 1.03541\n",
            "[ Epoch 1673/10000 ] Train Loss: 1.09988   Valid Loss: 1.03659\n",
            "[ Epoch 1674/10000 ] Train Loss: 1.10038   Valid Loss: 1.03509\n",
            "[ Epoch 1675/10000 ] Train Loss: 1.10115   Valid Loss: 1.03522\n",
            "[ Epoch 1676/10000 ] Train Loss: 1.10070   Valid Loss: 1.03688\n",
            "[ Epoch 1677/10000 ] Train Loss: 1.10320   Valid Loss: 1.03724\n",
            "[ Epoch 1678/10000 ] Train Loss: 1.10231   Valid Loss: 1.03436\n",
            "Early Stop Saving Model on Epoch 1678/10000\n",
            "[ Epoch 1679/10000 ] Train Loss: 1.09954   Valid Loss: 1.03490\n",
            "[ Epoch 1680/10000 ] Train Loss: 1.10216   Valid Loss: 1.03607\n",
            "[ Epoch 1681/10000 ] Train Loss: 1.10315   Valid Loss: 1.04008\n",
            "[ Epoch 1682/10000 ] Train Loss: 1.10069   Valid Loss: 1.03495\n",
            "[ Epoch 1683/10000 ] Train Loss: 1.10118   Valid Loss: 1.03959\n",
            "[ Epoch 1684/10000 ] Train Loss: 1.10313   Valid Loss: 1.03563\n",
            "[ Epoch 1685/10000 ] Train Loss: 1.09997   Valid Loss: 1.03433\n",
            "Early Stop Saving Model on Epoch 1685/10000\n",
            "[ Epoch 1686/10000 ] Train Loss: 1.10087   Valid Loss: 1.03659\n",
            "[ Epoch 1687/10000 ] Train Loss: 1.10208   Valid Loss: 1.03469\n",
            "[ Epoch 1688/10000 ] Train Loss: 1.10152   Valid Loss: 1.03470\n",
            "[ Epoch 1689/10000 ] Train Loss: 1.10039   Valid Loss: 1.03434\n",
            "[ Epoch 1690/10000 ] Train Loss: 1.09885   Valid Loss: 1.03398\n",
            "Early Stop Saving Model on Epoch 1690/10000\n",
            "[ Epoch 1691/10000 ] Train Loss: 1.09891   Valid Loss: 1.03535\n",
            "[ Epoch 1692/10000 ] Train Loss: 1.10428   Valid Loss: 1.03746\n",
            "[ Epoch 1693/10000 ] Train Loss: 1.10215   Valid Loss: 1.03452\n",
            "[ Epoch 1694/10000 ] Train Loss: 1.10297   Valid Loss: 1.03952\n",
            "[ Epoch 1695/10000 ] Train Loss: 1.10403   Valid Loss: 1.03434\n",
            "[ Epoch 1696/10000 ] Train Loss: 1.09859   Valid Loss: 1.03356\n",
            "Early Stop Saving Model on Epoch 1696/10000\n",
            "[ Epoch 1697/10000 ] Train Loss: 1.10098   Valid Loss: 1.03395\n",
            "[ Epoch 1698/10000 ] Train Loss: 1.10367   Valid Loss: 1.03858\n",
            "[ Epoch 1699/10000 ] Train Loss: 1.09997   Valid Loss: 1.03970\n",
            "[ Epoch 1700/10000 ] Train Loss: 1.10172   Valid Loss: 1.03726\n",
            "[ Epoch 1701/10000 ] Train Loss: 1.10241   Valid Loss: 1.03388\n",
            "[ Epoch 1702/10000 ] Train Loss: 1.09969   Valid Loss: 1.03552\n",
            "[ Epoch 1703/10000 ] Train Loss: 1.10035   Valid Loss: 1.03538\n",
            "[ Epoch 1704/10000 ] Train Loss: 1.09917   Valid Loss: 1.03406\n",
            "[ Epoch 1705/10000 ] Train Loss: 1.09841   Valid Loss: 1.03622\n",
            "[ Epoch 1706/10000 ] Train Loss: 1.09998   Valid Loss: 1.03365\n",
            "[ Epoch 1707/10000 ] Train Loss: 1.10033   Valid Loss: 1.03312\n",
            "Early Stop Saving Model on Epoch 1707/10000\n",
            "[ Epoch 1708/10000 ] Train Loss: 1.10276   Valid Loss: 1.03698\n",
            "[ Epoch 1709/10000 ] Train Loss: 1.10143   Valid Loss: 1.03392\n",
            "[ Epoch 1710/10000 ] Train Loss: 1.09813   Valid Loss: 1.03491\n",
            "[ Epoch 1711/10000 ] Train Loss: 1.10129   Valid Loss: 1.03282\n",
            "Early Stop Saving Model on Epoch 1711/10000\n",
            "[ Epoch 1712/10000 ] Train Loss: 1.09772   Valid Loss: 1.03347\n",
            "[ Epoch 1713/10000 ] Train Loss: 1.10011   Valid Loss: 1.03425\n",
            "[ Epoch 1714/10000 ] Train Loss: 1.10111   Valid Loss: 1.03603\n",
            "[ Epoch 1715/10000 ] Train Loss: 1.10203   Valid Loss: 1.03609\n",
            "[ Epoch 1716/10000 ] Train Loss: 1.10034   Valid Loss: 1.03550\n",
            "[ Epoch 1717/10000 ] Train Loss: 1.10028   Valid Loss: 1.03314\n",
            "[ Epoch 1718/10000 ] Train Loss: 1.09905   Valid Loss: 1.03412\n",
            "[ Epoch 1719/10000 ] Train Loss: 1.10046   Valid Loss: 1.03327\n",
            "[ Epoch 1720/10000 ] Train Loss: 1.09884   Valid Loss: 1.03326\n",
            "[ Epoch 1721/10000 ] Train Loss: 1.09915   Valid Loss: 1.03369\n",
            "[ Epoch 1722/10000 ] Train Loss: 1.09921   Valid Loss: 1.03381\n",
            "[ Epoch 1723/10000 ] Train Loss: 1.09962   Valid Loss: 1.03285\n",
            "[ Epoch 1724/10000 ] Train Loss: 1.09836   Valid Loss: 1.03248\n",
            "Early Stop Saving Model on Epoch 1724/10000\n",
            "[ Epoch 1725/10000 ] Train Loss: 1.09816   Valid Loss: 1.03348\n",
            "[ Epoch 1726/10000 ] Train Loss: 1.10090   Valid Loss: 1.03193\n",
            "Early Stop Saving Model on Epoch 1726/10000\n",
            "[ Epoch 1727/10000 ] Train Loss: 1.10348   Valid Loss: 1.03923\n",
            "[ Epoch 1728/10000 ] Train Loss: 1.10470   Valid Loss: 1.03986\n",
            "[ Epoch 1729/10000 ] Train Loss: 1.10228   Valid Loss: 1.03257\n",
            "[ Epoch 1730/10000 ] Train Loss: 1.09829   Valid Loss: 1.03218\n",
            "[ Epoch 1731/10000 ] Train Loss: 1.09802   Valid Loss: 1.03236\n",
            "[ Epoch 1732/10000 ] Train Loss: 1.09750   Valid Loss: 1.03427\n",
            "[ Epoch 1733/10000 ] Train Loss: 1.09870   Valid Loss: 1.03802\n",
            "[ Epoch 1734/10000 ] Train Loss: 1.10066   Valid Loss: 1.03285\n",
            "[ Epoch 1735/10000 ] Train Loss: 1.10075   Valid Loss: 1.03189\n",
            "Early Stop Saving Model on Epoch 1735/10000\n",
            "[ Epoch 1736/10000 ] Train Loss: 1.10281   Valid Loss: 1.03972\n",
            "[ Epoch 1737/10000 ] Train Loss: 1.10451   Valid Loss: 1.03376\n",
            "[ Epoch 1738/10000 ] Train Loss: 1.09865   Valid Loss: 1.03402\n",
            "[ Epoch 1739/10000 ] Train Loss: 1.09957   Valid Loss: 1.03340\n",
            "[ Epoch 1740/10000 ] Train Loss: 1.09917   Valid Loss: 1.03419\n",
            "[ Epoch 1741/10000 ] Train Loss: 1.10086   Valid Loss: 1.03380\n",
            "[ Epoch 1742/10000 ] Train Loss: 1.09806   Valid Loss: 1.03252\n",
            "[ Epoch 1743/10000 ] Train Loss: 1.09710   Valid Loss: 1.03181\n",
            "Early Stop Saving Model on Epoch 1743/10000\n",
            "[ Epoch 1744/10000 ] Train Loss: 1.09818   Valid Loss: 1.03307\n",
            "[ Epoch 1745/10000 ] Train Loss: 1.09923   Valid Loss: 1.03309\n",
            "[ Epoch 1746/10000 ] Train Loss: 1.09971   Valid Loss: 1.03508\n",
            "[ Epoch 1747/10000 ] Train Loss: 1.09899   Valid Loss: 1.03108\n",
            "Early Stop Saving Model on Epoch 1747/10000\n",
            "[ Epoch 1748/10000 ] Train Loss: 1.09569   Valid Loss: 1.03207\n",
            "[ Epoch 1749/10000 ] Train Loss: 1.09481   Valid Loss: 1.03275\n",
            "[ Epoch 1750/10000 ] Train Loss: 1.09689   Valid Loss: 1.03206\n",
            "[ Epoch 1751/10000 ] Train Loss: 1.09734   Valid Loss: 1.03144\n",
            "[ Epoch 1752/10000 ] Train Loss: 1.09677   Valid Loss: 1.03199\n",
            "[ Epoch 1753/10000 ] Train Loss: 1.09822   Valid Loss: 1.03150\n",
            "[ Epoch 1754/10000 ] Train Loss: 1.09788   Valid Loss: 1.03134\n",
            "[ Epoch 1755/10000 ] Train Loss: 1.09793   Valid Loss: 1.03281\n",
            "[ Epoch 1756/10000 ] Train Loss: 1.09594   Valid Loss: 1.03183\n",
            "[ Epoch 1757/10000 ] Train Loss: 1.09745   Valid Loss: 1.03320\n",
            "[ Epoch 1758/10000 ] Train Loss: 1.10192   Valid Loss: 1.03718\n",
            "[ Epoch 1759/10000 ] Train Loss: 1.09753   Valid Loss: 1.03073\n",
            "Early Stop Saving Model on Epoch 1759/10000\n",
            "[ Epoch 1760/10000 ] Train Loss: 1.09809   Valid Loss: 1.03125\n",
            "[ Epoch 1761/10000 ] Train Loss: 1.09798   Valid Loss: 1.03203\n",
            "[ Epoch 1762/10000 ] Train Loss: 1.09793   Valid Loss: 1.03217\n",
            "[ Epoch 1763/10000 ] Train Loss: 1.09692   Valid Loss: 1.03162\n",
            "[ Epoch 1764/10000 ] Train Loss: 1.09781   Valid Loss: 1.03105\n",
            "[ Epoch 1765/10000 ] Train Loss: 1.09590   Valid Loss: 1.03359\n",
            "[ Epoch 1766/10000 ] Train Loss: 1.09754   Valid Loss: 1.03238\n",
            "[ Epoch 1767/10000 ] Train Loss: 1.09801   Valid Loss: 1.03189\n",
            "[ Epoch 1768/10000 ] Train Loss: 1.09966   Valid Loss: 1.03195\n",
            "[ Epoch 1769/10000 ] Train Loss: 1.09516   Valid Loss: 1.03447\n",
            "[ Epoch 1770/10000 ] Train Loss: 1.09681   Valid Loss: 1.03210\n",
            "[ Epoch 1771/10000 ] Train Loss: 1.09668   Valid Loss: 1.03147\n",
            "[ Epoch 1772/10000 ] Train Loss: 1.09626   Valid Loss: 1.03084\n",
            "[ Epoch 1773/10000 ] Train Loss: 1.09734   Valid Loss: 1.03093\n",
            "[ Epoch 1774/10000 ] Train Loss: 1.09723   Valid Loss: 1.03171\n",
            "[ Epoch 1775/10000 ] Train Loss: 1.09754   Valid Loss: 1.03134\n",
            "[ Epoch 1776/10000 ] Train Loss: 1.09625   Valid Loss: 1.03013\n",
            "Early Stop Saving Model on Epoch 1776/10000\n",
            "[ Epoch 1777/10000 ] Train Loss: 1.09751   Valid Loss: 1.03214\n",
            "[ Epoch 1778/10000 ] Train Loss: 1.09775   Valid Loss: 1.03115\n",
            "[ Epoch 1779/10000 ] Train Loss: 1.09740   Valid Loss: 1.03429\n",
            "[ Epoch 1780/10000 ] Train Loss: 1.09603   Valid Loss: 1.03287\n",
            "[ Epoch 1781/10000 ] Train Loss: 1.09709   Valid Loss: 1.03062\n",
            "[ Epoch 1782/10000 ] Train Loss: 1.09731   Valid Loss: 1.02960\n",
            "Early Stop Saving Model on Epoch 1782/10000\n",
            "[ Epoch 1783/10000 ] Train Loss: 1.09534   Valid Loss: 1.03090\n",
            "[ Epoch 1784/10000 ] Train Loss: 1.09613   Valid Loss: 1.03087\n",
            "[ Epoch 1785/10000 ] Train Loss: 1.09530   Valid Loss: 1.03023\n",
            "[ Epoch 1786/10000 ] Train Loss: 1.09475   Valid Loss: 1.03037\n",
            "[ Epoch 1787/10000 ] Train Loss: 1.09604   Valid Loss: 1.03223\n",
            "[ Epoch 1788/10000 ] Train Loss: 1.09575   Valid Loss: 1.03274\n",
            "[ Epoch 1789/10000 ] Train Loss: 1.09687   Valid Loss: 1.03326\n",
            "[ Epoch 1790/10000 ] Train Loss: 1.09892   Valid Loss: 1.03062\n",
            "[ Epoch 1791/10000 ] Train Loss: 1.09640   Valid Loss: 1.03047\n",
            "[ Epoch 1792/10000 ] Train Loss: 1.09619   Valid Loss: 1.03226\n",
            "[ Epoch 1793/10000 ] Train Loss: 1.09530   Valid Loss: 1.03067\n",
            "[ Epoch 1794/10000 ] Train Loss: 1.09560   Valid Loss: 1.02949\n",
            "Early Stop Saving Model on Epoch 1794/10000\n",
            "[ Epoch 1795/10000 ] Train Loss: 1.09503   Valid Loss: 1.03101\n",
            "[ Epoch 1796/10000 ] Train Loss: 1.09648   Valid Loss: 1.03039\n",
            "[ Epoch 1797/10000 ] Train Loss: 1.09621   Valid Loss: 1.03149\n",
            "[ Epoch 1798/10000 ] Train Loss: 1.09635   Valid Loss: 1.02918\n",
            "Early Stop Saving Model on Epoch 1798/10000\n",
            "[ Epoch 1799/10000 ] Train Loss: 1.09494   Valid Loss: 1.02988\n",
            "[ Epoch 1800/10000 ] Train Loss: 1.09574   Valid Loss: 1.03223\n",
            "[ Epoch 1801/10000 ] Train Loss: 1.09627   Valid Loss: 1.03089\n",
            "[ Epoch 1802/10000 ] Train Loss: 1.09712   Valid Loss: 1.03105\n",
            "[ Epoch 1803/10000 ] Train Loss: 1.09672   Valid Loss: 1.03028\n",
            "[ Epoch 1804/10000 ] Train Loss: 1.09627   Valid Loss: 1.03029\n",
            "[ Epoch 1805/10000 ] Train Loss: 1.09676   Valid Loss: 1.03474\n",
            "[ Epoch 1806/10000 ] Train Loss: 1.09627   Valid Loss: 1.03251\n",
            "[ Epoch 1807/10000 ] Train Loss: 1.09553   Valid Loss: 1.02866\n",
            "Early Stop Saving Model on Epoch 1807/10000\n",
            "[ Epoch 1808/10000 ] Train Loss: 1.09765   Valid Loss: 1.03197\n",
            "[ Epoch 1809/10000 ] Train Loss: 1.09513   Valid Loss: 1.03033\n",
            "[ Epoch 1810/10000 ] Train Loss: 1.09673   Valid Loss: 1.02928\n",
            "[ Epoch 1811/10000 ] Train Loss: 1.09731   Valid Loss: 1.03396\n",
            "[ Epoch 1812/10000 ] Train Loss: 1.09718   Valid Loss: 1.03053\n",
            "[ Epoch 1813/10000 ] Train Loss: 1.09684   Valid Loss: 1.03011\n",
            "[ Epoch 1814/10000 ] Train Loss: 1.09585   Valid Loss: 1.03096\n",
            "[ Epoch 1815/10000 ] Train Loss: 1.09489   Valid Loss: 1.02968\n",
            "[ Epoch 1816/10000 ] Train Loss: 1.09606   Valid Loss: 1.02953\n",
            "[ Epoch 1817/10000 ] Train Loss: 1.09476   Valid Loss: 1.03043\n",
            "[ Epoch 1818/10000 ] Train Loss: 1.09643   Valid Loss: 1.03543\n",
            "[ Epoch 1819/10000 ] Train Loss: 1.10127   Valid Loss: 1.02919\n",
            "[ Epoch 1820/10000 ] Train Loss: 1.09683   Valid Loss: 1.03206\n",
            "[ Epoch 1821/10000 ] Train Loss: 1.09544   Valid Loss: 1.02838\n",
            "Early Stop Saving Model on Epoch 1821/10000\n",
            "[ Epoch 1822/10000 ] Train Loss: 1.09590   Valid Loss: 1.02967\n",
            "[ Epoch 1823/10000 ] Train Loss: 1.09534   Valid Loss: 1.03016\n",
            "[ Epoch 1824/10000 ] Train Loss: 1.09539   Valid Loss: 1.03113\n",
            "[ Epoch 1825/10000 ] Train Loss: 1.09570   Valid Loss: 1.03123\n",
            "[ Epoch 1826/10000 ] Train Loss: 1.09514   Valid Loss: 1.03001\n",
            "[ Epoch 1827/10000 ] Train Loss: 1.09536   Valid Loss: 1.03202\n",
            "[ Epoch 1828/10000 ] Train Loss: 1.09362   Valid Loss: 1.03531\n",
            "[ Epoch 1829/10000 ] Train Loss: 1.09711   Valid Loss: 1.03221\n",
            "[ Epoch 1830/10000 ] Train Loss: 1.09534   Valid Loss: 1.02926\n",
            "[ Epoch 1831/10000 ] Train Loss: 1.09522   Valid Loss: 1.02791\n",
            "Early Stop Saving Model on Epoch 1831/10000\n",
            "[ Epoch 1832/10000 ] Train Loss: 1.09530   Valid Loss: 1.02911\n",
            "[ Epoch 1833/10000 ] Train Loss: 1.09522   Valid Loss: 1.03050\n",
            "[ Epoch 1834/10000 ] Train Loss: 1.09552   Valid Loss: 1.02788\n",
            "Early Stop Saving Model on Epoch 1834/10000\n",
            "[ Epoch 1835/10000 ] Train Loss: 1.09514   Valid Loss: 1.02906\n",
            "[ Epoch 1836/10000 ] Train Loss: 1.09474   Valid Loss: 1.02829\n",
            "[ Epoch 1837/10000 ] Train Loss: 1.09537   Valid Loss: 1.03545\n",
            "[ Epoch 1838/10000 ] Train Loss: 1.09697   Valid Loss: 1.03059\n",
            "[ Epoch 1839/10000 ] Train Loss: 1.09472   Valid Loss: 1.02759\n",
            "Early Stop Saving Model on Epoch 1839/10000\n",
            "[ Epoch 1840/10000 ] Train Loss: 1.09540   Valid Loss: 1.02934\n",
            "[ Epoch 1841/10000 ] Train Loss: 1.09549   Valid Loss: 1.02979\n",
            "[ Epoch 1842/10000 ] Train Loss: 1.09571   Valid Loss: 1.02826\n",
            "[ Epoch 1843/10000 ] Train Loss: 1.09761   Valid Loss: 1.02969\n",
            "[ Epoch 1844/10000 ] Train Loss: 1.09499   Valid Loss: 1.02871\n",
            "[ Epoch 1845/10000 ] Train Loss: 1.09698   Valid Loss: 1.03009\n",
            "[ Epoch 1846/10000 ] Train Loss: 1.09596   Valid Loss: 1.02777\n",
            "[ Epoch 1847/10000 ] Train Loss: 1.09456   Valid Loss: 1.03160\n",
            "[ Epoch 1848/10000 ] Train Loss: 1.09520   Valid Loss: 1.03071\n",
            "[ Epoch 1849/10000 ] Train Loss: 1.09392   Valid Loss: 1.02855\n",
            "[ Epoch 1850/10000 ] Train Loss: 1.09524   Valid Loss: 1.02827\n",
            "[ Epoch 1851/10000 ] Train Loss: 1.09374   Valid Loss: 1.03042\n",
            "[ Epoch 1852/10000 ] Train Loss: 1.09301   Valid Loss: 1.02840\n",
            "[ Epoch 1853/10000 ] Train Loss: 1.09188   Valid Loss: 1.02818\n",
            "[ Epoch 1854/10000 ] Train Loss: 1.09416   Valid Loss: 1.02804\n",
            "[ Epoch 1855/10000 ] Train Loss: 1.09441   Valid Loss: 1.02911\n",
            "[ Epoch 1856/10000 ] Train Loss: 1.09461   Valid Loss: 1.02848\n",
            "[ Epoch 1857/10000 ] Train Loss: 1.09391   Valid Loss: 1.03022\n",
            "[ Epoch 1858/10000 ] Train Loss: 1.09650   Valid Loss: 1.02802\n",
            "[ Epoch 1859/10000 ] Train Loss: 1.09345   Valid Loss: 1.03022\n",
            "[ Epoch 1860/10000 ] Train Loss: 1.09178   Valid Loss: 1.02918\n",
            "[ Epoch 1861/10000 ] Train Loss: 1.09358   Valid Loss: 1.02876\n",
            "[ Epoch 1862/10000 ] Train Loss: 1.09314   Valid Loss: 1.02793\n",
            "[ Epoch 1863/10000 ] Train Loss: 1.09550   Valid Loss: 1.02829\n",
            "[ Epoch 1864/10000 ] Train Loss: 1.09460   Valid Loss: 1.02847\n",
            "[ Epoch 1865/10000 ] Train Loss: 1.09429   Valid Loss: 1.02816\n",
            "[ Epoch 1866/10000 ] Train Loss: 1.09366   Valid Loss: 1.02762\n",
            "[ Epoch 1867/10000 ] Train Loss: 1.09414   Valid Loss: 1.02768\n",
            "[ Epoch 1868/10000 ] Train Loss: 1.09382   Valid Loss: 1.02858\n",
            "[ Epoch 1869/10000 ] Train Loss: 1.09719   Valid Loss: 1.03080\n",
            "[ Epoch 1870/10000 ] Train Loss: 1.09374   Valid Loss: 1.02827\n",
            "[ Epoch 1871/10000 ] Train Loss: 1.09260   Valid Loss: 1.02811\n",
            "[ Epoch 1872/10000 ] Train Loss: 1.09317   Valid Loss: 1.02836\n",
            "[ Epoch 1873/10000 ] Train Loss: 1.09370   Valid Loss: 1.02773\n",
            "[ Epoch 1874/10000 ] Train Loss: 1.09305   Valid Loss: 1.02769\n",
            "[ Epoch 1875/10000 ] Train Loss: 1.09286   Valid Loss: 1.02889\n",
            "[ Epoch 1876/10000 ] Train Loss: 1.09459   Valid Loss: 1.02819\n",
            "[ Epoch 1877/10000 ] Train Loss: 1.09302   Valid Loss: 1.02710\n",
            "Early Stop Saving Model on Epoch 1877/10000\n",
            "[ Epoch 1878/10000 ] Train Loss: 1.09562   Valid Loss: 1.02734\n",
            "[ Epoch 1879/10000 ] Train Loss: 1.09463   Valid Loss: 1.02823\n",
            "[ Epoch 1880/10000 ] Train Loss: 1.09575   Valid Loss: 1.02726\n",
            "[ Epoch 1881/10000 ] Train Loss: 1.09421   Valid Loss: 1.03318\n",
            "[ Epoch 1882/10000 ] Train Loss: 1.09734   Valid Loss: 1.02737\n",
            "[ Epoch 1883/10000 ] Train Loss: 1.09382   Valid Loss: 1.02736\n",
            "[ Epoch 1884/10000 ] Train Loss: 1.09231   Valid Loss: 1.02702\n",
            "Early Stop Saving Model on Epoch 1884/10000\n",
            "[ Epoch 1885/10000 ] Train Loss: 1.09312   Valid Loss: 1.02915\n",
            "[ Epoch 1886/10000 ] Train Loss: 1.09348   Valid Loss: 1.02981\n",
            "[ Epoch 1887/10000 ] Train Loss: 1.09334   Valid Loss: 1.02671\n",
            "Early Stop Saving Model on Epoch 1887/10000\n",
            "[ Epoch 1888/10000 ] Train Loss: 1.08994   Valid Loss: 1.02782\n",
            "[ Epoch 1889/10000 ] Train Loss: 1.09217   Valid Loss: 1.02710\n",
            "[ Epoch 1890/10000 ] Train Loss: 1.09366   Valid Loss: 1.02717\n",
            "[ Epoch 1891/10000 ] Train Loss: 1.09261   Valid Loss: 1.02706\n",
            "[ Epoch 1892/10000 ] Train Loss: 1.09379   Valid Loss: 1.02692\n",
            "[ Epoch 1893/10000 ] Train Loss: 1.09125   Valid Loss: 1.02734\n",
            "[ Epoch 1894/10000 ] Train Loss: 1.09174   Valid Loss: 1.02659\n",
            "Early Stop Saving Model on Epoch 1894/10000\n",
            "[ Epoch 1895/10000 ] Train Loss: 1.09405   Valid Loss: 1.02709\n",
            "[ Epoch 1896/10000 ] Train Loss: 1.09225   Valid Loss: 1.02759\n",
            "[ Epoch 1897/10000 ] Train Loss: 1.09267   Valid Loss: 1.02745\n",
            "[ Epoch 1898/10000 ] Train Loss: 1.09498   Valid Loss: 1.02881\n",
            "[ Epoch 1899/10000 ] Train Loss: 1.09338   Valid Loss: 1.02734\n",
            "[ Epoch 1900/10000 ] Train Loss: 1.09283   Valid Loss: 1.02580\n",
            "Early Stop Saving Model on Epoch 1900/10000\n",
            "[ Epoch 1901/10000 ] Train Loss: 1.09220   Valid Loss: 1.02706\n",
            "[ Epoch 1902/10000 ] Train Loss: 1.09199   Valid Loss: 1.02784\n",
            "[ Epoch 1903/10000 ] Train Loss: 1.09211   Valid Loss: 1.02709\n",
            "[ Epoch 1904/10000 ] Train Loss: 1.09189   Valid Loss: 1.02686\n",
            "[ Epoch 1905/10000 ] Train Loss: 1.09312   Valid Loss: 1.02734\n",
            "[ Epoch 1906/10000 ] Train Loss: 1.09309   Valid Loss: 1.03147\n",
            "[ Epoch 1907/10000 ] Train Loss: 1.09734   Valid Loss: 1.03360\n",
            "[ Epoch 1908/10000 ] Train Loss: 1.09233   Valid Loss: 1.02987\n",
            "[ Epoch 1909/10000 ] Train Loss: 1.09574   Valid Loss: 1.02900\n",
            "[ Epoch 1910/10000 ] Train Loss: 1.09310   Valid Loss: 1.02744\n",
            "[ Epoch 1911/10000 ] Train Loss: 1.09289   Valid Loss: 1.02848\n",
            "[ Epoch 1912/10000 ] Train Loss: 1.09194   Valid Loss: 1.02624\n",
            "[ Epoch 1913/10000 ] Train Loss: 1.09200   Valid Loss: 1.02659\n",
            "[ Epoch 1914/10000 ] Train Loss: 1.09632   Valid Loss: 1.02926\n",
            "[ Epoch 1915/10000 ] Train Loss: 1.09150   Valid Loss: 1.02641\n",
            "[ Epoch 1916/10000 ] Train Loss: 1.09261   Valid Loss: 1.02721\n",
            "[ Epoch 1917/10000 ] Train Loss: 1.09188   Valid Loss: 1.02608\n",
            "[ Epoch 1918/10000 ] Train Loss: 1.09284   Valid Loss: 1.02677\n",
            "[ Epoch 1919/10000 ] Train Loss: 1.09118   Valid Loss: 1.02697\n",
            "[ Epoch 1920/10000 ] Train Loss: 1.09182   Valid Loss: 1.02762\n",
            "[ Epoch 1921/10000 ] Train Loss: 1.09340   Valid Loss: 1.03419\n",
            "[ Epoch 1922/10000 ] Train Loss: 1.09720   Valid Loss: 1.02668\n",
            "[ Epoch 1923/10000 ] Train Loss: 1.09227   Valid Loss: 1.02755\n",
            "[ Epoch 1924/10000 ] Train Loss: 1.09165   Valid Loss: 1.02660\n",
            "[ Epoch 1925/10000 ] Train Loss: 1.09124   Valid Loss: 1.02579\n",
            "Early Stop Saving Model on Epoch 1925/10000\n",
            "[ Epoch 1926/10000 ] Train Loss: 1.09281   Valid Loss: 1.02585\n",
            "[ Epoch 1927/10000 ] Train Loss: 1.09240   Valid Loss: 1.02666\n",
            "[ Epoch 1928/10000 ] Train Loss: 1.09210   Valid Loss: 1.02626\n",
            "[ Epoch 1929/10000 ] Train Loss: 1.09205   Valid Loss: 1.02779\n",
            "[ Epoch 1930/10000 ] Train Loss: 1.09185   Valid Loss: 1.02628\n",
            "[ Epoch 1931/10000 ] Train Loss: 1.09107   Valid Loss: 1.02709\n",
            "[ Epoch 1932/10000 ] Train Loss: 1.09222   Valid Loss: 1.02602\n",
            "[ Epoch 1933/10000 ] Train Loss: 1.09086   Valid Loss: 1.02540\n",
            "Early Stop Saving Model on Epoch 1933/10000\n",
            "[ Epoch 1934/10000 ] Train Loss: 1.09178   Valid Loss: 1.02514\n",
            "Early Stop Saving Model on Epoch 1934/10000\n",
            "[ Epoch 1935/10000 ] Train Loss: 1.09191   Valid Loss: 1.02711\n",
            "[ Epoch 1936/10000 ] Train Loss: 1.09211   Valid Loss: 1.02645\n",
            "[ Epoch 1937/10000 ] Train Loss: 1.09201   Valid Loss: 1.02966\n",
            "[ Epoch 1938/10000 ] Train Loss: 1.09207   Valid Loss: 1.02627\n",
            "[ Epoch 1939/10000 ] Train Loss: 1.09008   Valid Loss: 1.02481\n",
            "Early Stop Saving Model on Epoch 1939/10000\n",
            "[ Epoch 1940/10000 ] Train Loss: 1.09148   Valid Loss: 1.02563\n",
            "[ Epoch 1941/10000 ] Train Loss: 1.09446   Valid Loss: 1.02534\n",
            "[ Epoch 1942/10000 ] Train Loss: 1.09050   Valid Loss: 1.02609\n",
            "[ Epoch 1943/10000 ] Train Loss: 1.09167   Valid Loss: 1.02582\n",
            "[ Epoch 1944/10000 ] Train Loss: 1.09214   Valid Loss: 1.02631\n",
            "[ Epoch 1945/10000 ] Train Loss: 1.09340   Valid Loss: 1.02645\n",
            "[ Epoch 1946/10000 ] Train Loss: 1.09317   Valid Loss: 1.02517\n",
            "[ Epoch 1947/10000 ] Train Loss: 1.09204   Valid Loss: 1.02640\n",
            "[ Epoch 1948/10000 ] Train Loss: 1.09484   Valid Loss: 1.03113\n",
            "[ Epoch 1949/10000 ] Train Loss: 1.09254   Valid Loss: 1.02622\n",
            "[ Epoch 1950/10000 ] Train Loss: 1.09315   Valid Loss: 1.02723\n",
            "[ Epoch 1951/10000 ] Train Loss: 1.09433   Valid Loss: 1.02693\n",
            "[ Epoch 1952/10000 ] Train Loss: 1.09085   Valid Loss: 1.02533\n",
            "[ Epoch 1953/10000 ] Train Loss: 1.09107   Valid Loss: 1.02552\n",
            "[ Epoch 1954/10000 ] Train Loss: 1.09034   Valid Loss: 1.02549\n",
            "[ Epoch 1955/10000 ] Train Loss: 1.09009   Valid Loss: 1.02746\n",
            "[ Epoch 1956/10000 ] Train Loss: 1.09147   Valid Loss: 1.02564\n",
            "[ Epoch 1957/10000 ] Train Loss: 1.09105   Valid Loss: 1.02717\n",
            "[ Epoch 1958/10000 ] Train Loss: 1.09087   Valid Loss: 1.02750\n",
            "[ Epoch 1959/10000 ] Train Loss: 1.09140   Valid Loss: 1.02453\n",
            "Early Stop Saving Model on Epoch 1959/10000\n",
            "[ Epoch 1960/10000 ] Train Loss: 1.09321   Valid Loss: 1.02648\n",
            "[ Epoch 1961/10000 ] Train Loss: 1.09397   Valid Loss: 1.03036\n",
            "[ Epoch 1962/10000 ] Train Loss: 1.09308   Valid Loss: 1.02604\n",
            "[ Epoch 1963/10000 ] Train Loss: 1.09122   Valid Loss: 1.02507\n",
            "[ Epoch 1964/10000 ] Train Loss: 1.09257   Valid Loss: 1.02573\n",
            "[ Epoch 1965/10000 ] Train Loss: 1.09007   Valid Loss: 1.02502\n",
            "[ Epoch 1966/10000 ] Train Loss: 1.09231   Valid Loss: 1.02457\n",
            "[ Epoch 1967/10000 ] Train Loss: 1.09056   Valid Loss: 1.02596\n",
            "[ Epoch 1968/10000 ] Train Loss: 1.09059   Valid Loss: 1.02496\n",
            "[ Epoch 1969/10000 ] Train Loss: 1.09018   Valid Loss: 1.02439\n",
            "Early Stop Saving Model on Epoch 1969/10000\n",
            "[ Epoch 1970/10000 ] Train Loss: 1.09104   Valid Loss: 1.02908\n",
            "[ Epoch 1971/10000 ] Train Loss: 1.09315   Valid Loss: 1.02439\n",
            "[ Epoch 1972/10000 ] Train Loss: 1.09156   Valid Loss: 1.02716\n",
            "[ Epoch 1973/10000 ] Train Loss: 1.09266   Valid Loss: 1.02636\n",
            "[ Epoch 1974/10000 ] Train Loss: 1.09096   Valid Loss: 1.02437\n",
            "Early Stop Saving Model on Epoch 1974/10000\n",
            "[ Epoch 1975/10000 ] Train Loss: 1.09082   Valid Loss: 1.02531\n",
            "[ Epoch 1976/10000 ] Train Loss: 1.09093   Valid Loss: 1.02403\n",
            "Early Stop Saving Model on Epoch 1976/10000\n",
            "[ Epoch 1977/10000 ] Train Loss: 1.09047   Valid Loss: 1.02640\n",
            "[ Epoch 1978/10000 ] Train Loss: 1.08938   Valid Loss: 1.02381\n",
            "Early Stop Saving Model on Epoch 1978/10000\n",
            "[ Epoch 1979/10000 ] Train Loss: 1.09024   Valid Loss: 1.02504\n",
            "[ Epoch 1980/10000 ] Train Loss: 1.08949   Valid Loss: 1.02406\n",
            "[ Epoch 1981/10000 ] Train Loss: 1.08801   Valid Loss: 1.02399\n",
            "[ Epoch 1982/10000 ] Train Loss: 1.09222   Valid Loss: 1.02745\n",
            "[ Epoch 1983/10000 ] Train Loss: 1.08992   Valid Loss: 1.02719\n",
            "[ Epoch 1984/10000 ] Train Loss: 1.09115   Valid Loss: 1.02404\n",
            "[ Epoch 1985/10000 ] Train Loss: 1.09195   Valid Loss: 1.02699\n",
            "[ Epoch 1986/10000 ] Train Loss: 1.09187   Valid Loss: 1.02389\n",
            "[ Epoch 1987/10000 ] Train Loss: 1.08987   Valid Loss: 1.02547\n",
            "[ Epoch 1988/10000 ] Train Loss: 1.09149   Valid Loss: 1.02815\n",
            "[ Epoch 1989/10000 ] Train Loss: 1.09520   Valid Loss: 1.02609\n",
            "[ Epoch 1990/10000 ] Train Loss: 1.09232   Valid Loss: 1.02861\n",
            "[ Epoch 1991/10000 ] Train Loss: 1.09184   Valid Loss: 1.02385\n",
            "[ Epoch 1992/10000 ] Train Loss: 1.09245   Valid Loss: 1.02686\n",
            "[ Epoch 1993/10000 ] Train Loss: 1.09196   Valid Loss: 1.02907\n",
            "[ Epoch 1994/10000 ] Train Loss: 1.09533   Valid Loss: 1.02532\n",
            "[ Epoch 1995/10000 ] Train Loss: 1.09507   Valid Loss: 1.02624\n",
            "[ Epoch 1996/10000 ] Train Loss: 1.09047   Valid Loss: 1.02436\n",
            "[ Epoch 1997/10000 ] Train Loss: 1.09195   Valid Loss: 1.02749\n",
            "[ Epoch 1998/10000 ] Train Loss: 1.09234   Valid Loss: 1.02374\n",
            "Early Stop Saving Model on Epoch 1998/10000\n",
            "[ Epoch 1999/10000 ] Train Loss: 1.09173   Valid Loss: 1.02841\n",
            "[ Epoch 2000/10000 ] Train Loss: 1.09113   Valid Loss: 1.02430\n",
            "[ Epoch 2001/10000 ] Train Loss: 1.09333   Valid Loss: 1.02890\n",
            "[ Epoch 2002/10000 ] Train Loss: 1.09111   Valid Loss: 1.02774\n",
            "[ Epoch 2003/10000 ] Train Loss: 1.09220   Valid Loss: 1.02320\n",
            "Early Stop Saving Model on Epoch 2003/10000\n",
            "[ Epoch 2004/10000 ] Train Loss: 1.09214   Valid Loss: 1.02658\n",
            "[ Epoch 2005/10000 ] Train Loss: 1.09240   Valid Loss: 1.02647\n",
            "[ Epoch 2006/10000 ] Train Loss: 1.08844   Valid Loss: 1.02346\n",
            "[ Epoch 2007/10000 ] Train Loss: 1.08819   Valid Loss: 1.02573\n",
            "[ Epoch 2008/10000 ] Train Loss: 1.08941   Valid Loss: 1.02469\n",
            "[ Epoch 2009/10000 ] Train Loss: 1.08969   Valid Loss: 1.02262\n",
            "Early Stop Saving Model on Epoch 2009/10000\n",
            "[ Epoch 2010/10000 ] Train Loss: 1.09123   Valid Loss: 1.02451\n",
            "[ Epoch 2011/10000 ] Train Loss: 1.09409   Valid Loss: 1.02889\n",
            "[ Epoch 2012/10000 ] Train Loss: 1.09254   Valid Loss: 1.02306\n",
            "[ Epoch 2013/10000 ] Train Loss: 1.09392   Valid Loss: 1.02704\n",
            "[ Epoch 2014/10000 ] Train Loss: 1.09616   Valid Loss: 1.03181\n",
            "[ Epoch 2015/10000 ] Train Loss: 1.09036   Valid Loss: 1.02360\n",
            "[ Epoch 2016/10000 ] Train Loss: 1.08989   Valid Loss: 1.02345\n",
            "[ Epoch 2017/10000 ] Train Loss: 1.08856   Valid Loss: 1.02328\n",
            "[ Epoch 2018/10000 ] Train Loss: 1.08855   Valid Loss: 1.02293\n",
            "[ Epoch 2019/10000 ] Train Loss: 1.08856   Valid Loss: 1.02471\n",
            "[ Epoch 2020/10000 ] Train Loss: 1.08903   Valid Loss: 1.02330\n",
            "[ Epoch 2021/10000 ] Train Loss: 1.08995   Valid Loss: 1.02273\n",
            "[ Epoch 2022/10000 ] Train Loss: 1.08896   Valid Loss: 1.02391\n",
            "[ Epoch 2023/10000 ] Train Loss: 1.09025   Valid Loss: 1.02519\n",
            "[ Epoch 2024/10000 ] Train Loss: 1.08916   Valid Loss: 1.02362\n",
            "[ Epoch 2025/10000 ] Train Loss: 1.08921   Valid Loss: 1.02285\n",
            "[ Epoch 2026/10000 ] Train Loss: 1.08949   Valid Loss: 1.02382\n",
            "[ Epoch 2027/10000 ] Train Loss: 1.08882   Valid Loss: 1.02261\n",
            "Early Stop Saving Model on Epoch 2027/10000\n",
            "[ Epoch 2028/10000 ] Train Loss: 1.08914   Valid Loss: 1.02259\n",
            "Early Stop Saving Model on Epoch 2028/10000\n",
            "[ Epoch 2029/10000 ] Train Loss: 1.08846   Valid Loss: 1.02305\n",
            "[ Epoch 2030/10000 ] Train Loss: 1.08961   Valid Loss: 1.02380\n",
            "[ Epoch 2031/10000 ] Train Loss: 1.08905   Valid Loss: 1.02283\n",
            "[ Epoch 2032/10000 ] Train Loss: 1.08864   Valid Loss: 1.02387\n",
            "[ Epoch 2033/10000 ] Train Loss: 1.08935   Valid Loss: 1.02428\n",
            "[ Epoch 2034/10000 ] Train Loss: 1.08993   Valid Loss: 1.02166\n",
            "Early Stop Saving Model on Epoch 2034/10000\n",
            "[ Epoch 2035/10000 ] Train Loss: 1.08911   Valid Loss: 1.02363\n",
            "[ Epoch 2036/10000 ] Train Loss: 1.09073   Valid Loss: 1.02545\n",
            "[ Epoch 2037/10000 ] Train Loss: 1.08746   Valid Loss: 1.02332\n",
            "[ Epoch 2038/10000 ] Train Loss: 1.08849   Valid Loss: 1.02245\n",
            "[ Epoch 2039/10000 ] Train Loss: 1.08963   Valid Loss: 1.02458\n",
            "[ Epoch 2040/10000 ] Train Loss: 1.09084   Valid Loss: 1.02843\n",
            "[ Epoch 2041/10000 ] Train Loss: 1.09189   Valid Loss: 1.02521\n",
            "[ Epoch 2042/10000 ] Train Loss: 1.08894   Valid Loss: 1.02332\n",
            "[ Epoch 2043/10000 ] Train Loss: 1.08888   Valid Loss: 1.02311\n",
            "[ Epoch 2044/10000 ] Train Loss: 1.08954   Valid Loss: 1.02449\n",
            "[ Epoch 2045/10000 ] Train Loss: 1.09211   Valid Loss: 1.02180\n",
            "[ Epoch 2046/10000 ] Train Loss: 1.08886   Valid Loss: 1.02261\n",
            "[ Epoch 2047/10000 ] Train Loss: 1.08863   Valid Loss: 1.02372\n",
            "[ Epoch 2048/10000 ] Train Loss: 1.08925   Valid Loss: 1.02156\n",
            "Early Stop Saving Model on Epoch 2048/10000\n",
            "[ Epoch 2049/10000 ] Train Loss: 1.08949   Valid Loss: 1.02445\n",
            "[ Epoch 2050/10000 ] Train Loss: 1.08903   Valid Loss: 1.02328\n",
            "[ Epoch 2051/10000 ] Train Loss: 1.08629   Valid Loss: 1.02296\n",
            "[ Epoch 2052/10000 ] Train Loss: 1.08783   Valid Loss: 1.02421\n",
            "[ Epoch 2053/10000 ] Train Loss: 1.08970   Valid Loss: 1.02326\n",
            "[ Epoch 2054/10000 ] Train Loss: 1.08901   Valid Loss: 1.02287\n",
            "[ Epoch 2055/10000 ] Train Loss: 1.08855   Valid Loss: 1.02313\n",
            "[ Epoch 2056/10000 ] Train Loss: 1.08787   Valid Loss: 1.02421\n",
            "[ Epoch 2057/10000 ] Train Loss: 1.08749   Valid Loss: 1.02464\n",
            "[ Epoch 2058/10000 ] Train Loss: 1.09167   Valid Loss: 1.02873\n",
            "[ Epoch 2059/10000 ] Train Loss: 1.09032   Valid Loss: 1.02298\n",
            "[ Epoch 2060/10000 ] Train Loss: 1.09095   Valid Loss: 1.02266\n",
            "[ Epoch 2061/10000 ] Train Loss: 1.09068   Valid Loss: 1.02564\n",
            "[ Epoch 2062/10000 ] Train Loss: 1.09017   Valid Loss: 1.02344\n",
            "[ Epoch 2063/10000 ] Train Loss: 1.08980   Valid Loss: 1.02239\n",
            "[ Epoch 2064/10000 ] Train Loss: 1.08950   Valid Loss: 1.02460\n",
            "[ Epoch 2065/10000 ] Train Loss: 1.09303   Valid Loss: 1.02631\n",
            "[ Epoch 2066/10000 ] Train Loss: 1.08993   Valid Loss: 1.02298\n",
            "[ Epoch 2067/10000 ] Train Loss: 1.08805   Valid Loss: 1.02491\n",
            "[ Epoch 2068/10000 ] Train Loss: 1.08734   Valid Loss: 1.02382\n",
            "[ Epoch 2069/10000 ] Train Loss: 1.08963   Valid Loss: 1.02509\n",
            "[ Epoch 2070/10000 ] Train Loss: 1.08718   Valid Loss: 1.02357\n",
            "[ Epoch 2071/10000 ] Train Loss: 1.08880   Valid Loss: 1.02195\n",
            "[ Epoch 2072/10000 ] Train Loss: 1.08851   Valid Loss: 1.02467\n",
            "[ Epoch 2073/10000 ] Train Loss: 1.08981   Valid Loss: 1.02450\n",
            "[ Epoch 2074/10000 ] Train Loss: 1.08784   Valid Loss: 1.02124\n",
            "Early Stop Saving Model on Epoch 2074/10000\n",
            "[ Epoch 2075/10000 ] Train Loss: 1.08854   Valid Loss: 1.02333\n",
            "[ Epoch 2076/10000 ] Train Loss: 1.08908   Valid Loss: 1.02142\n",
            "[ Epoch 2077/10000 ] Train Loss: 1.08806   Valid Loss: 1.02262\n",
            "[ Epoch 2078/10000 ] Train Loss: 1.08973   Valid Loss: 1.02208\n",
            "[ Epoch 2079/10000 ] Train Loss: 1.08910   Valid Loss: 1.02302\n",
            "[ Epoch 2080/10000 ] Train Loss: 1.08834   Valid Loss: 1.02530\n",
            "[ Epoch 2081/10000 ] Train Loss: 1.08926   Valid Loss: 1.02365\n",
            "[ Epoch 2082/10000 ] Train Loss: 1.08813   Valid Loss: 1.02163\n",
            "[ Epoch 2083/10000 ] Train Loss: 1.08992   Valid Loss: 1.02341\n",
            "[ Epoch 2084/10000 ] Train Loss: 1.09091   Valid Loss: 1.02132\n",
            "[ Epoch 2085/10000 ] Train Loss: 1.08794   Valid Loss: 1.02332\n",
            "[ Epoch 2086/10000 ] Train Loss: 1.08887   Valid Loss: 1.02293\n",
            "[ Epoch 2087/10000 ] Train Loss: 1.08886   Valid Loss: 1.02133\n",
            "[ Epoch 2088/10000 ] Train Loss: 1.08924   Valid Loss: 1.02304\n",
            "[ Epoch 2089/10000 ] Train Loss: 1.08978   Valid Loss: 1.02285\n",
            "[ Epoch 2090/10000 ] Train Loss: 1.08724   Valid Loss: 1.02453\n",
            "[ Epoch 2091/10000 ] Train Loss: 1.09065   Valid Loss: 1.02282\n",
            "[ Epoch 2092/10000 ] Train Loss: 1.08643   Valid Loss: 1.02119\n",
            "Early Stop Saving Model on Epoch 2092/10000\n",
            "[ Epoch 2093/10000 ] Train Loss: 1.08730   Valid Loss: 1.02359\n",
            "[ Epoch 2094/10000 ] Train Loss: 1.08790   Valid Loss: 1.02812\n",
            "[ Epoch 2095/10000 ] Train Loss: 1.08812   Valid Loss: 1.02860\n",
            "[ Epoch 2096/10000 ] Train Loss: 1.09128   Valid Loss: 1.02188\n",
            "[ Epoch 2097/10000 ] Train Loss: 1.08843   Valid Loss: 1.02193\n",
            "[ Epoch 2098/10000 ] Train Loss: 1.08615   Valid Loss: 1.02177\n",
            "[ Epoch 2099/10000 ] Train Loss: 1.08727   Valid Loss: 1.02124\n",
            "[ Epoch 2100/10000 ] Train Loss: 1.08708   Valid Loss: 1.02194\n",
            "[ Epoch 2101/10000 ] Train Loss: 1.08653   Valid Loss: 1.02227\n",
            "[ Epoch 2102/10000 ] Train Loss: 1.08761   Valid Loss: 1.02124\n",
            "[ Epoch 2103/10000 ] Train Loss: 1.08722   Valid Loss: 1.02099\n",
            "Early Stop Saving Model on Epoch 2103/10000\n",
            "[ Epoch 2104/10000 ] Train Loss: 1.08949   Valid Loss: 1.02835\n",
            "[ Epoch 2105/10000 ] Train Loss: 1.09178   Valid Loss: 1.02472\n",
            "[ Epoch 2106/10000 ] Train Loss: 1.08846   Valid Loss: 1.02249\n",
            "[ Epoch 2107/10000 ] Train Loss: 1.09027   Valid Loss: 1.02787\n",
            "[ Epoch 2108/10000 ] Train Loss: 1.09298   Valid Loss: 1.02594\n",
            "[ Epoch 2109/10000 ] Train Loss: 1.08863   Valid Loss: 1.02016\n",
            "Early Stop Saving Model on Epoch 2109/10000\n",
            "[ Epoch 2110/10000 ] Train Loss: 1.08805   Valid Loss: 1.02218\n",
            "[ Epoch 2111/10000 ] Train Loss: 1.08580   Valid Loss: 1.02053\n",
            "[ Epoch 2112/10000 ] Train Loss: 1.08545   Valid Loss: 1.02316\n",
            "[ Epoch 2113/10000 ] Train Loss: 1.08755   Valid Loss: 1.02373\n",
            "[ Epoch 2114/10000 ] Train Loss: 1.08778   Valid Loss: 1.02314\n",
            "[ Epoch 2115/10000 ] Train Loss: 1.08644   Valid Loss: 1.02055\n",
            "[ Epoch 2116/10000 ] Train Loss: 1.08699   Valid Loss: 1.02258\n",
            "[ Epoch 2117/10000 ] Train Loss: 1.08723   Valid Loss: 1.02089\n",
            "[ Epoch 2118/10000 ] Train Loss: 1.08591   Valid Loss: 1.02136\n",
            "[ Epoch 2119/10000 ] Train Loss: 1.08637   Valid Loss: 1.01991\n",
            "Early Stop Saving Model on Epoch 2119/10000\n",
            "[ Epoch 2120/10000 ] Train Loss: 1.08740   Valid Loss: 1.02505\n",
            "[ Epoch 2121/10000 ] Train Loss: 1.08956   Valid Loss: 1.02032\n",
            "[ Epoch 2122/10000 ] Train Loss: 1.08603   Valid Loss: 1.02093\n",
            "[ Epoch 2123/10000 ] Train Loss: 1.08731   Valid Loss: 1.02209\n",
            "[ Epoch 2124/10000 ] Train Loss: 1.08960   Valid Loss: 1.02797\n",
            "[ Epoch 2125/10000 ] Train Loss: 1.08761   Valid Loss: 1.02599\n",
            "[ Epoch 2126/10000 ] Train Loss: 1.08809   Valid Loss: 1.02551\n",
            "[ Epoch 2127/10000 ] Train Loss: 1.08802   Valid Loss: 1.02120\n",
            "[ Epoch 2128/10000 ] Train Loss: 1.08650   Valid Loss: 1.01953\n",
            "Early Stop Saving Model on Epoch 2128/10000\n",
            "[ Epoch 2129/10000 ] Train Loss: 1.08495   Valid Loss: 1.02220\n",
            "[ Epoch 2130/10000 ] Train Loss: 1.08596   Valid Loss: 1.02087\n",
            "[ Epoch 2131/10000 ] Train Loss: 1.08799   Valid Loss: 1.02137\n",
            "[ Epoch 2132/10000 ] Train Loss: 1.08643   Valid Loss: 1.02176\n",
            "[ Epoch 2133/10000 ] Train Loss: 1.08511   Valid Loss: 1.02106\n",
            "[ Epoch 2134/10000 ] Train Loss: 1.08642   Valid Loss: 1.02019\n",
            "[ Epoch 2135/10000 ] Train Loss: 1.08678   Valid Loss: 1.02110\n",
            "[ Epoch 2136/10000 ] Train Loss: 1.08715   Valid Loss: 1.02069\n",
            "[ Epoch 2137/10000 ] Train Loss: 1.08665   Valid Loss: 1.02016\n",
            "[ Epoch 2138/10000 ] Train Loss: 1.08630   Valid Loss: 1.02257\n",
            "[ Epoch 2139/10000 ] Train Loss: 1.08690   Valid Loss: 1.02028\n",
            "[ Epoch 2140/10000 ] Train Loss: 1.08599   Valid Loss: 1.02122\n",
            "[ Epoch 2141/10000 ] Train Loss: 1.08686   Valid Loss: 1.02022\n",
            "[ Epoch 2142/10000 ] Train Loss: 1.08669   Valid Loss: 1.02080\n",
            "[ Epoch 2143/10000 ] Train Loss: 1.08683   Valid Loss: 1.02428\n",
            "[ Epoch 2144/10000 ] Train Loss: 1.08992   Valid Loss: 1.02797\n",
            "[ Epoch 2145/10000 ] Train Loss: 1.08784   Valid Loss: 1.02141\n",
            "[ Epoch 2146/10000 ] Train Loss: 1.08681   Valid Loss: 1.02082\n",
            "[ Epoch 2147/10000 ] Train Loss: 1.08531   Valid Loss: 1.02143\n",
            "[ Epoch 2148/10000 ] Train Loss: 1.08617   Valid Loss: 1.02074\n",
            "[ Epoch 2149/10000 ] Train Loss: 1.08563   Valid Loss: 1.02027\n",
            "[ Epoch 2150/10000 ] Train Loss: 1.08840   Valid Loss: 1.02079\n",
            "[ Epoch 2151/10000 ] Train Loss: 1.08715   Valid Loss: 1.02043\n",
            "[ Epoch 2152/10000 ] Train Loss: 1.08600   Valid Loss: 1.02038\n",
            "[ Epoch 2153/10000 ] Train Loss: 1.08538   Valid Loss: 1.01991\n",
            "[ Epoch 2154/10000 ] Train Loss: 1.08799   Valid Loss: 1.02066\n",
            "[ Epoch 2155/10000 ] Train Loss: 1.08671   Valid Loss: 1.02027\n",
            "[ Epoch 2156/10000 ] Train Loss: 1.08616   Valid Loss: 1.02028\n",
            "[ Epoch 2157/10000 ] Train Loss: 1.08447   Valid Loss: 1.01946\n",
            "Early Stop Saving Model on Epoch 2157/10000\n",
            "[ Epoch 2158/10000 ] Train Loss: 1.08561   Valid Loss: 1.01978\n",
            "[ Epoch 2159/10000 ] Train Loss: 1.08760   Valid Loss: 1.02023\n",
            "[ Epoch 2160/10000 ] Train Loss: 1.08833   Valid Loss: 1.02069\n",
            "[ Epoch 2161/10000 ] Train Loss: 1.08350   Valid Loss: 1.01986\n",
            "[ Epoch 2162/10000 ] Train Loss: 1.08569   Valid Loss: 1.01889\n",
            "Early Stop Saving Model on Epoch 2162/10000\n",
            "[ Epoch 2163/10000 ] Train Loss: 1.08573   Valid Loss: 1.01976\n",
            "[ Epoch 2164/10000 ] Train Loss: 1.08660   Valid Loss: 1.02055\n",
            "[ Epoch 2165/10000 ] Train Loss: 1.08484   Valid Loss: 1.01997\n",
            "[ Epoch 2166/10000 ] Train Loss: 1.08447   Valid Loss: 1.01964\n",
            "[ Epoch 2167/10000 ] Train Loss: 1.08508   Valid Loss: 1.01912\n",
            "[ Epoch 2168/10000 ] Train Loss: 1.08564   Valid Loss: 1.02425\n",
            "[ Epoch 2169/10000 ] Train Loss: 1.08875   Valid Loss: 1.01999\n",
            "[ Epoch 2170/10000 ] Train Loss: 1.08513   Valid Loss: 1.01951\n",
            "[ Epoch 2171/10000 ] Train Loss: 1.08611   Valid Loss: 1.02181\n",
            "[ Epoch 2172/10000 ] Train Loss: 1.08668   Valid Loss: 1.01962\n",
            "[ Epoch 2173/10000 ] Train Loss: 1.08426   Valid Loss: 1.02011\n",
            "[ Epoch 2174/10000 ] Train Loss: 1.08708   Valid Loss: 1.02012\n",
            "[ Epoch 2175/10000 ] Train Loss: 1.08734   Valid Loss: 1.02012\n",
            "[ Epoch 2176/10000 ] Train Loss: 1.08407   Valid Loss: 1.02095\n",
            "[ Epoch 2177/10000 ] Train Loss: 1.08676   Valid Loss: 1.02142\n",
            "[ Epoch 2178/10000 ] Train Loss: 1.08727   Valid Loss: 1.02210\n",
            "[ Epoch 2179/10000 ] Train Loss: 1.08464   Valid Loss: 1.02187\n",
            "[ Epoch 2180/10000 ] Train Loss: 1.08694   Valid Loss: 1.02041\n",
            "[ Epoch 2181/10000 ] Train Loss: 1.08527   Valid Loss: 1.02062\n",
            "[ Epoch 2182/10000 ] Train Loss: 1.08647   Valid Loss: 1.01878\n",
            "Early Stop Saving Model on Epoch 2182/10000\n",
            "[ Epoch 2183/10000 ] Train Loss: 1.08653   Valid Loss: 1.02113\n",
            "[ Epoch 2184/10000 ] Train Loss: 1.08474   Valid Loss: 1.02033\n",
            "[ Epoch 2185/10000 ] Train Loss: 1.08707   Valid Loss: 1.01939\n",
            "[ Epoch 2186/10000 ] Train Loss: 1.08630   Valid Loss: 1.02126\n",
            "[ Epoch 2187/10000 ] Train Loss: 1.08466   Valid Loss: 1.02044\n",
            "[ Epoch 2188/10000 ] Train Loss: 1.08688   Valid Loss: 1.01984\n",
            "[ Epoch 2189/10000 ] Train Loss: 1.08545   Valid Loss: 1.01948\n",
            "[ Epoch 2190/10000 ] Train Loss: 1.08637   Valid Loss: 1.01978\n",
            "[ Epoch 2191/10000 ] Train Loss: 1.08513   Valid Loss: 1.01844\n",
            "Early Stop Saving Model on Epoch 2191/10000\n",
            "[ Epoch 2192/10000 ] Train Loss: 1.08368   Valid Loss: 1.01967\n",
            "[ Epoch 2193/10000 ] Train Loss: 1.08521   Valid Loss: 1.01998\n",
            "[ Epoch 2194/10000 ] Train Loss: 1.08541   Valid Loss: 1.01952\n",
            "[ Epoch 2195/10000 ] Train Loss: 1.08526   Valid Loss: 1.02046\n",
            "[ Epoch 2196/10000 ] Train Loss: 1.08574   Valid Loss: 1.02134\n",
            "[ Epoch 2197/10000 ] Train Loss: 1.08920   Valid Loss: 1.01832\n",
            "Early Stop Saving Model on Epoch 2197/10000\n",
            "[ Epoch 2198/10000 ] Train Loss: 1.09019   Valid Loss: 1.02397\n",
            "[ Epoch 2199/10000 ] Train Loss: 1.08657   Valid Loss: 1.02837\n",
            "[ Epoch 2200/10000 ] Train Loss: 1.08982   Valid Loss: 1.01938\n",
            "[ Epoch 2201/10000 ] Train Loss: 1.08518   Valid Loss: 1.02023\n",
            "[ Epoch 2202/10000 ] Train Loss: 1.08531   Valid Loss: 1.02036\n",
            "[ Epoch 2203/10000 ] Train Loss: 1.08500   Valid Loss: 1.01862\n",
            "[ Epoch 2204/10000 ] Train Loss: 1.08494   Valid Loss: 1.02077\n",
            "[ Epoch 2205/10000 ] Train Loss: 1.08650   Valid Loss: 1.02197\n",
            "[ Epoch 2206/10000 ] Train Loss: 1.08536   Valid Loss: 1.02149\n",
            "[ Epoch 2207/10000 ] Train Loss: 1.08620   Valid Loss: 1.01798\n",
            "Early Stop Saving Model on Epoch 2207/10000\n",
            "[ Epoch 2208/10000 ] Train Loss: 1.08576   Valid Loss: 1.01906\n",
            "[ Epoch 2209/10000 ] Train Loss: 1.08579   Valid Loss: 1.02201\n",
            "[ Epoch 2210/10000 ] Train Loss: 1.08431   Valid Loss: 1.01861\n",
            "[ Epoch 2211/10000 ] Train Loss: 1.08457   Valid Loss: 1.01974\n",
            "[ Epoch 2212/10000 ] Train Loss: 1.08680   Valid Loss: 1.01901\n",
            "[ Epoch 2213/10000 ] Train Loss: 1.08790   Valid Loss: 1.02005\n",
            "[ Epoch 2214/10000 ] Train Loss: 1.08556   Valid Loss: 1.02007\n",
            "[ Epoch 2215/10000 ] Train Loss: 1.08473   Valid Loss: 1.01954\n",
            "[ Epoch 2216/10000 ] Train Loss: 1.08502   Valid Loss: 1.01958\n",
            "[ Epoch 2217/10000 ] Train Loss: 1.08391   Valid Loss: 1.01827\n",
            "[ Epoch 2218/10000 ] Train Loss: 1.08438   Valid Loss: 1.01986\n",
            "[ Epoch 2219/10000 ] Train Loss: 1.08432   Valid Loss: 1.02132\n",
            "[ Epoch 2220/10000 ] Train Loss: 1.08473   Valid Loss: 1.01920\n",
            "[ Epoch 2221/10000 ] Train Loss: 1.08509   Valid Loss: 1.01887\n",
            "[ Epoch 2222/10000 ] Train Loss: 1.08438   Valid Loss: 1.02265\n",
            "[ Epoch 2223/10000 ] Train Loss: 1.08406   Valid Loss: 1.02113\n",
            "[ Epoch 2224/10000 ] Train Loss: 1.08615   Valid Loss: 1.02144\n",
            "[ Epoch 2225/10000 ] Train Loss: 1.08592   Valid Loss: 1.01884\n",
            "[ Epoch 2226/10000 ] Train Loss: 1.08600   Valid Loss: 1.01884\n",
            "[ Epoch 2227/10000 ] Train Loss: 1.08335   Valid Loss: 1.01928\n",
            "[ Epoch 2228/10000 ] Train Loss: 1.08409   Valid Loss: 1.01835\n",
            "[ Epoch 2229/10000 ] Train Loss: 1.08408   Valid Loss: 1.01813\n",
            "[ Epoch 2230/10000 ] Train Loss: 1.08355   Valid Loss: 1.01915\n",
            "[ Epoch 2231/10000 ] Train Loss: 1.08333   Valid Loss: 1.01731\n",
            "Early Stop Saving Model on Epoch 2231/10000\n",
            "[ Epoch 2232/10000 ] Train Loss: 1.08419   Valid Loss: 1.01930\n",
            "[ Epoch 2233/10000 ] Train Loss: 1.08401   Valid Loss: 1.01842\n",
            "[ Epoch 2234/10000 ] Train Loss: 1.08476   Valid Loss: 1.01979\n",
            "[ Epoch 2235/10000 ] Train Loss: 1.08468   Valid Loss: 1.01838\n",
            "[ Epoch 2236/10000 ] Train Loss: 1.08431   Valid Loss: 1.01909\n",
            "[ Epoch 2237/10000 ] Train Loss: 1.08336   Valid Loss: 1.01812\n",
            "[ Epoch 2238/10000 ] Train Loss: 1.08645   Valid Loss: 1.01886\n",
            "[ Epoch 2239/10000 ] Train Loss: 1.08393   Valid Loss: 1.01798\n",
            "[ Epoch 2240/10000 ] Train Loss: 1.08563   Valid Loss: 1.02011\n",
            "[ Epoch 2241/10000 ] Train Loss: 1.08456   Valid Loss: 1.02075\n",
            "[ Epoch 2242/10000 ] Train Loss: 1.08568   Valid Loss: 1.01849\n",
            "[ Epoch 2243/10000 ] Train Loss: 1.08383   Valid Loss: 1.01993\n",
            "[ Epoch 2244/10000 ] Train Loss: 1.08683   Valid Loss: 1.02184\n",
            "[ Epoch 2245/10000 ] Train Loss: 1.08473   Valid Loss: 1.01968\n",
            "[ Epoch 2246/10000 ] Train Loss: 1.08702   Valid Loss: 1.01943\n",
            "[ Epoch 2247/10000 ] Train Loss: 1.08400   Valid Loss: 1.01852\n",
            "[ Epoch 2248/10000 ] Train Loss: 1.08462   Valid Loss: 1.01839\n",
            "[ Epoch 2249/10000 ] Train Loss: 1.08299   Valid Loss: 1.01795\n",
            "[ Epoch 2250/10000 ] Train Loss: 1.08398   Valid Loss: 1.01874\n",
            "[ Epoch 2251/10000 ] Train Loss: 1.08307   Valid Loss: 1.01764\n",
            "[ Epoch 2252/10000 ] Train Loss: 1.08534   Valid Loss: 1.01878\n",
            "[ Epoch 2253/10000 ] Train Loss: 1.08552   Valid Loss: 1.01907\n",
            "[ Epoch 2254/10000 ] Train Loss: 1.08620   Valid Loss: 1.01901\n",
            "[ Epoch 2255/10000 ] Train Loss: 1.08339   Valid Loss: 1.01884\n",
            "[ Epoch 2256/10000 ] Train Loss: 1.08484   Valid Loss: 1.01719\n",
            "Early Stop Saving Model on Epoch 2256/10000\n",
            "[ Epoch 2257/10000 ] Train Loss: 1.08598   Valid Loss: 1.02195\n",
            "[ Epoch 2258/10000 ] Train Loss: 1.08682   Valid Loss: 1.02863\n",
            "[ Epoch 2259/10000 ] Train Loss: 1.08789   Valid Loss: 1.01895\n",
            "[ Epoch 2260/10000 ] Train Loss: 1.08636   Valid Loss: 1.01985\n",
            "[ Epoch 2261/10000 ] Train Loss: 1.08495   Valid Loss: 1.02191\n",
            "[ Epoch 2262/10000 ] Train Loss: 1.08741   Valid Loss: 1.01927\n",
            "[ Epoch 2263/10000 ] Train Loss: 1.08415   Valid Loss: 1.01815\n",
            "[ Epoch 2264/10000 ] Train Loss: 1.08415   Valid Loss: 1.01831\n",
            "[ Epoch 2265/10000 ] Train Loss: 1.08345   Valid Loss: 1.01778\n",
            "[ Epoch 2266/10000 ] Train Loss: 1.08454   Valid Loss: 1.01970\n",
            "[ Epoch 2267/10000 ] Train Loss: 1.08451   Valid Loss: 1.02202\n",
            "[ Epoch 2268/10000 ] Train Loss: 1.08276   Valid Loss: 1.01888\n",
            "[ Epoch 2269/10000 ] Train Loss: 1.08454   Valid Loss: 1.01785\n",
            "[ Epoch 2270/10000 ] Train Loss: 1.08419   Valid Loss: 1.01782\n",
            "[ Epoch 2271/10000 ] Train Loss: 1.08264   Valid Loss: 1.01855\n",
            "[ Epoch 2272/10000 ] Train Loss: 1.08412   Valid Loss: 1.02427\n",
            "[ Epoch 2273/10000 ] Train Loss: 1.08792   Valid Loss: 1.02720\n",
            "[ Epoch 2274/10000 ] Train Loss: 1.08584   Valid Loss: 1.02791\n",
            "[ Epoch 2275/10000 ] Train Loss: 1.08530   Valid Loss: 1.01877\n",
            "[ Epoch 2276/10000 ] Train Loss: 1.08556   Valid Loss: 1.01790\n",
            "[ Epoch 2277/10000 ] Train Loss: 1.08405   Valid Loss: 1.02058\n",
            "[ Epoch 2278/10000 ] Train Loss: 1.08505   Valid Loss: 1.01953\n",
            "[ Epoch 2279/10000 ] Train Loss: 1.08755   Valid Loss: 1.02412\n",
            "[ Epoch 2280/10000 ] Train Loss: 1.08585   Valid Loss: 1.01763\n",
            "[ Epoch 2281/10000 ] Train Loss: 1.08316   Valid Loss: 1.01917\n",
            "[ Epoch 2282/10000 ] Train Loss: 1.08293   Valid Loss: 1.01722\n",
            "[ Epoch 2283/10000 ] Train Loss: 1.08535   Valid Loss: 1.01839\n",
            "[ Epoch 2284/10000 ] Train Loss: 1.08370   Valid Loss: 1.01756\n",
            "[ Epoch 2285/10000 ] Train Loss: 1.08138   Valid Loss: 1.01760\n",
            "[ Epoch 2286/10000 ] Train Loss: 1.08235   Valid Loss: 1.01670\n",
            "Early Stop Saving Model on Epoch 2286/10000\n",
            "[ Epoch 2287/10000 ] Train Loss: 1.08335   Valid Loss: 1.01888\n",
            "[ Epoch 2288/10000 ] Train Loss: 1.08404   Valid Loss: 1.01849\n",
            "[ Epoch 2289/10000 ] Train Loss: 1.08382   Valid Loss: 1.01713\n",
            "[ Epoch 2290/10000 ] Train Loss: 1.08253   Valid Loss: 1.01670\n",
            "Early Stop Saving Model on Epoch 2290/10000\n",
            "[ Epoch 2291/10000 ] Train Loss: 1.08469   Valid Loss: 1.02046\n",
            "[ Epoch 2292/10000 ] Train Loss: 1.08469   Valid Loss: 1.01757\n",
            "[ Epoch 2293/10000 ] Train Loss: 1.08403   Valid Loss: 1.01838\n",
            "[ Epoch 2294/10000 ] Train Loss: 1.08364   Valid Loss: 1.01649\n",
            "Early Stop Saving Model on Epoch 2294/10000\n",
            "[ Epoch 2295/10000 ] Train Loss: 1.08306   Valid Loss: 1.01845\n",
            "[ Epoch 2296/10000 ] Train Loss: 1.08352   Valid Loss: 1.01888\n",
            "[ Epoch 2297/10000 ] Train Loss: 1.08384   Valid Loss: 1.01669\n",
            "[ Epoch 2298/10000 ] Train Loss: 1.08182   Valid Loss: 1.01691\n",
            "[ Epoch 2299/10000 ] Train Loss: 1.08459   Valid Loss: 1.01986\n",
            "[ Epoch 2300/10000 ] Train Loss: 1.08786   Valid Loss: 1.02123\n",
            "[ Epoch 2301/10000 ] Train Loss: 1.08532   Valid Loss: 1.02136\n",
            "[ Epoch 2302/10000 ] Train Loss: 1.08659   Valid Loss: 1.01855\n",
            "[ Epoch 2303/10000 ] Train Loss: 1.08431   Valid Loss: 1.01779\n",
            "[ Epoch 2304/10000 ] Train Loss: 1.08147   Valid Loss: 1.01863\n",
            "[ Epoch 2305/10000 ] Train Loss: 1.08464   Valid Loss: 1.01905\n",
            "[ Epoch 2306/10000 ] Train Loss: 1.08283   Valid Loss: 1.01663\n",
            "[ Epoch 2307/10000 ] Train Loss: 1.08307   Valid Loss: 1.01714\n",
            "[ Epoch 2308/10000 ] Train Loss: 1.08375   Valid Loss: 1.01675\n",
            "[ Epoch 2309/10000 ] Train Loss: 1.08249   Valid Loss: 1.01716\n",
            "[ Epoch 2310/10000 ] Train Loss: 1.08298   Valid Loss: 1.01710\n",
            "[ Epoch 2311/10000 ] Train Loss: 1.08331   Valid Loss: 1.01801\n",
            "[ Epoch 2312/10000 ] Train Loss: 1.08174   Valid Loss: 1.01844\n",
            "[ Epoch 2313/10000 ] Train Loss: 1.08464   Valid Loss: 1.02000\n",
            "[ Epoch 2314/10000 ] Train Loss: 1.08256   Valid Loss: 1.01829\n",
            "[ Epoch 2315/10000 ] Train Loss: 1.08404   Valid Loss: 1.01767\n",
            "[ Epoch 2316/10000 ] Train Loss: 1.08260   Valid Loss: 1.01684\n",
            "[ Epoch 2317/10000 ] Train Loss: 1.08188   Valid Loss: 1.01705\n",
            "[ Epoch 2318/10000 ] Train Loss: 1.08137   Valid Loss: 1.01716\n",
            "[ Epoch 2319/10000 ] Train Loss: 1.08262   Valid Loss: 1.01705\n",
            "[ Epoch 2320/10000 ] Train Loss: 1.08305   Valid Loss: 1.01784\n",
            "[ Epoch 2321/10000 ] Train Loss: 1.08445   Valid Loss: 1.01629\n",
            "Early Stop Saving Model on Epoch 2321/10000\n",
            "[ Epoch 2322/10000 ] Train Loss: 1.08177   Valid Loss: 1.01716\n",
            "[ Epoch 2323/10000 ] Train Loss: 1.08271   Valid Loss: 1.01728\n",
            "[ Epoch 2324/10000 ] Train Loss: 1.08351   Valid Loss: 1.01817\n",
            "[ Epoch 2325/10000 ] Train Loss: 1.08259   Valid Loss: 1.01681\n",
            "[ Epoch 2326/10000 ] Train Loss: 1.08269   Valid Loss: 1.01857\n",
            "[ Epoch 2327/10000 ] Train Loss: 1.08407   Valid Loss: 1.01712\n",
            "[ Epoch 2328/10000 ] Train Loss: 1.08571   Valid Loss: 1.01930\n",
            "[ Epoch 2329/10000 ] Train Loss: 1.08158   Valid Loss: 1.01715\n",
            "[ Epoch 2330/10000 ] Train Loss: 1.08328   Valid Loss: 1.01998\n",
            "[ Epoch 2331/10000 ] Train Loss: 1.08483   Valid Loss: 1.01813\n",
            "[ Epoch 2332/10000 ] Train Loss: 1.08338   Valid Loss: 1.01728\n",
            "[ Epoch 2333/10000 ] Train Loss: 1.08511   Valid Loss: 1.02006\n",
            "[ Epoch 2334/10000 ] Train Loss: 1.08511   Valid Loss: 1.02046\n",
            "[ Epoch 2335/10000 ] Train Loss: 1.08369   Valid Loss: 1.01787\n",
            "[ Epoch 2336/10000 ] Train Loss: 1.08294   Valid Loss: 1.02156\n",
            "[ Epoch 2337/10000 ] Train Loss: 1.08480   Valid Loss: 1.01945\n",
            "[ Epoch 2338/10000 ] Train Loss: 1.08292   Valid Loss: 1.02292\n",
            "[ Epoch 2339/10000 ] Train Loss: 1.08474   Valid Loss: 1.02685\n",
            "[ Epoch 2340/10000 ] Train Loss: 1.08607   Valid Loss: 1.01817\n",
            "[ Epoch 2341/10000 ] Train Loss: 1.08233   Valid Loss: 1.01739\n",
            "[ Epoch 2342/10000 ] Train Loss: 1.08633   Valid Loss: 1.01728\n",
            "[ Epoch 2343/10000 ] Train Loss: 1.08240   Valid Loss: 1.01640\n",
            "[ Epoch 2344/10000 ] Train Loss: 1.08283   Valid Loss: 1.01914\n",
            "[ Epoch 2345/10000 ] Train Loss: 1.08276   Valid Loss: 1.01830\n",
            "[ Epoch 2346/10000 ] Train Loss: 1.08173   Valid Loss: 1.01616\n",
            "Early Stop Saving Model on Epoch 2346/10000\n",
            "[ Epoch 2347/10000 ] Train Loss: 1.08287   Valid Loss: 1.01833\n",
            "[ Epoch 2348/10000 ] Train Loss: 1.08176   Valid Loss: 1.01967\n",
            "[ Epoch 2349/10000 ] Train Loss: 1.08399   Valid Loss: 1.01587\n",
            "Early Stop Saving Model on Epoch 2349/10000\n",
            "[ Epoch 2350/10000 ] Train Loss: 1.08318   Valid Loss: 1.01725\n",
            "[ Epoch 2351/10000 ] Train Loss: 1.08303   Valid Loss: 1.01643\n",
            "[ Epoch 2352/10000 ] Train Loss: 1.08200   Valid Loss: 1.01755\n",
            "[ Epoch 2353/10000 ] Train Loss: 1.08233   Valid Loss: 1.01694\n",
            "[ Epoch 2354/10000 ] Train Loss: 1.08010   Valid Loss: 1.01595\n",
            "[ Epoch 2355/10000 ] Train Loss: 1.08308   Valid Loss: 1.01761\n",
            "[ Epoch 2356/10000 ] Train Loss: 1.08419   Valid Loss: 1.01721\n",
            "[ Epoch 2357/10000 ] Train Loss: 1.08418   Valid Loss: 1.01869\n",
            "[ Epoch 2358/10000 ] Train Loss: 1.08439   Valid Loss: 1.01664\n",
            "[ Epoch 2359/10000 ] Train Loss: 1.08264   Valid Loss: 1.01612\n",
            "[ Epoch 2360/10000 ] Train Loss: 1.08153   Valid Loss: 1.01648\n",
            "[ Epoch 2361/10000 ] Train Loss: 1.08066   Valid Loss: 1.01714\n",
            "[ Epoch 2362/10000 ] Train Loss: 1.08296   Valid Loss: 1.01635\n",
            "[ Epoch 2363/10000 ] Train Loss: 1.08289   Valid Loss: 1.01642\n",
            "[ Epoch 2364/10000 ] Train Loss: 1.08228   Valid Loss: 1.01637\n",
            "[ Epoch 2365/10000 ] Train Loss: 1.08138   Valid Loss: 1.01670\n",
            "[ Epoch 2366/10000 ] Train Loss: 1.08273   Valid Loss: 1.01785\n",
            "[ Epoch 2367/10000 ] Train Loss: 1.08245   Valid Loss: 1.01899\n",
            "[ Epoch 2368/10000 ] Train Loss: 1.08174   Valid Loss: 1.01736\n",
            "[ Epoch 2369/10000 ] Train Loss: 1.08149   Valid Loss: 1.01723\n",
            "[ Epoch 2370/10000 ] Train Loss: 1.08159   Valid Loss: 1.01816\n",
            "[ Epoch 2371/10000 ] Train Loss: 1.08241   Valid Loss: 1.01656\n",
            "[ Epoch 2372/10000 ] Train Loss: 1.08271   Valid Loss: 1.01800\n",
            "[ Epoch 2373/10000 ] Train Loss: 1.08241   Valid Loss: 1.01868\n",
            "[ Epoch 2374/10000 ] Train Loss: 1.08209   Valid Loss: 1.01729\n",
            "[ Epoch 2375/10000 ] Train Loss: 1.08407   Valid Loss: 1.01628\n",
            "[ Epoch 2376/10000 ] Train Loss: 1.08684   Valid Loss: 1.01834\n",
            "[ Epoch 2377/10000 ] Train Loss: 1.08167   Valid Loss: 1.01558\n",
            "Early Stop Saving Model on Epoch 2377/10000\n",
            "[ Epoch 2378/10000 ] Train Loss: 1.08375   Valid Loss: 1.01746\n",
            "[ Epoch 2379/10000 ] Train Loss: 1.08332   Valid Loss: 1.01595\n",
            "[ Epoch 2380/10000 ] Train Loss: 1.08329   Valid Loss: 1.01785\n",
            "[ Epoch 2381/10000 ] Train Loss: 1.08339   Valid Loss: 1.02139\n",
            "[ Epoch 2382/10000 ] Train Loss: 1.08518   Valid Loss: 1.01648\n",
            "[ Epoch 2383/10000 ] Train Loss: 1.08285   Valid Loss: 1.01886\n",
            "[ Epoch 2384/10000 ] Train Loss: 1.08345   Valid Loss: 1.01736\n",
            "[ Epoch 2385/10000 ] Train Loss: 1.08247   Valid Loss: 1.01564\n",
            "[ Epoch 2386/10000 ] Train Loss: 1.08168   Valid Loss: 1.01821\n",
            "[ Epoch 2387/10000 ] Train Loss: 1.08306   Valid Loss: 1.01668\n",
            "[ Epoch 2388/10000 ] Train Loss: 1.07962   Valid Loss: 1.01494\n",
            "Early Stop Saving Model on Epoch 2388/10000\n",
            "[ Epoch 2389/10000 ] Train Loss: 1.08260   Valid Loss: 1.01791\n",
            "[ Epoch 2390/10000 ] Train Loss: 1.08218   Valid Loss: 1.01652\n",
            "[ Epoch 2391/10000 ] Train Loss: 1.08198   Valid Loss: 1.01822\n",
            "[ Epoch 2392/10000 ] Train Loss: 1.08181   Valid Loss: 1.01517\n",
            "[ Epoch 2393/10000 ] Train Loss: 1.08210   Valid Loss: 1.01683\n",
            "[ Epoch 2394/10000 ] Train Loss: 1.08328   Valid Loss: 1.01894\n",
            "[ Epoch 2395/10000 ] Train Loss: 1.08201   Valid Loss: 1.01534\n",
            "[ Epoch 2396/10000 ] Train Loss: 1.08225   Valid Loss: 1.01626\n",
            "[ Epoch 2397/10000 ] Train Loss: 1.08248   Valid Loss: 1.01700\n",
            "[ Epoch 2398/10000 ] Train Loss: 1.08316   Valid Loss: 1.01657\n",
            "[ Epoch 2399/10000 ] Train Loss: 1.08686   Valid Loss: 1.01622\n",
            "[ Epoch 2400/10000 ] Train Loss: 1.08243   Valid Loss: 1.01665\n",
            "[ Epoch 2401/10000 ] Train Loss: 1.08061   Valid Loss: 1.01633\n",
            "[ Epoch 2402/10000 ] Train Loss: 1.08236   Valid Loss: 1.01734\n",
            "[ Epoch 2403/10000 ] Train Loss: 1.08178   Valid Loss: 1.01587\n",
            "[ Epoch 2404/10000 ] Train Loss: 1.08129   Valid Loss: 1.01565\n",
            "[ Epoch 2405/10000 ] Train Loss: 1.08106   Valid Loss: 1.01874\n",
            "[ Epoch 2406/10000 ] Train Loss: 1.08330   Valid Loss: 1.01565\n",
            "[ Epoch 2407/10000 ] Train Loss: 1.08218   Valid Loss: 1.01535\n",
            "[ Epoch 2408/10000 ] Train Loss: 1.08278   Valid Loss: 1.01833\n",
            "[ Epoch 2409/10000 ] Train Loss: 1.08203   Valid Loss: 1.01541\n",
            "[ Epoch 2410/10000 ] Train Loss: 1.08135   Valid Loss: 1.01711\n",
            "[ Epoch 2411/10000 ] Train Loss: 1.08257   Valid Loss: 1.01610\n",
            "[ Epoch 2412/10000 ] Train Loss: 1.08254   Valid Loss: 1.01670\n",
            "[ Epoch 2413/10000 ] Train Loss: 1.08301   Valid Loss: 1.01596\n",
            "[ Epoch 2414/10000 ] Train Loss: 1.08049   Valid Loss: 1.01715\n",
            "[ Epoch 2415/10000 ] Train Loss: 1.08507   Valid Loss: 1.01786\n",
            "[ Epoch 2416/10000 ] Train Loss: 1.08300   Valid Loss: 1.01622\n",
            "[ Epoch 2417/10000 ] Train Loss: 1.08076   Valid Loss: 1.01812\n",
            "[ Epoch 2418/10000 ] Train Loss: 1.08092   Valid Loss: 1.01717\n",
            "[ Epoch 2419/10000 ] Train Loss: 1.08248   Valid Loss: 1.01829\n",
            "[ Epoch 2420/10000 ] Train Loss: 1.08067   Valid Loss: 1.01694\n",
            "[ Epoch 2421/10000 ] Train Loss: 1.08116   Valid Loss: 1.01530\n",
            "[ Epoch 2422/10000 ] Train Loss: 1.08148   Valid Loss: 1.01696\n",
            "[ Epoch 2423/10000 ] Train Loss: 1.08195   Valid Loss: 1.01671\n",
            "[ Epoch 2424/10000 ] Train Loss: 1.08454   Valid Loss: 1.01759\n",
            "[ Epoch 2425/10000 ] Train Loss: 1.08281   Valid Loss: 1.01907\n",
            "[ Epoch 2426/10000 ] Train Loss: 1.08367   Valid Loss: 1.01703\n",
            "[ Epoch 2427/10000 ] Train Loss: 1.08110   Valid Loss: 1.01767\n",
            "[ Epoch 2428/10000 ] Train Loss: 1.08237   Valid Loss: 1.01775\n",
            "[ Epoch 2429/10000 ] Train Loss: 1.08064   Valid Loss: 1.01506\n",
            "[ Epoch 2430/10000 ] Train Loss: 1.08338   Valid Loss: 1.01701\n",
            "[ Epoch 2431/10000 ] Train Loss: 1.08128   Valid Loss: 1.01693\n",
            "[ Epoch 2432/10000 ] Train Loss: 1.08185   Valid Loss: 1.01863\n",
            "[ Epoch 2433/10000 ] Train Loss: 1.08317   Valid Loss: 1.01567\n",
            "[ Epoch 2434/10000 ] Train Loss: 1.08325   Valid Loss: 1.01664\n",
            "[ Epoch 2435/10000 ] Train Loss: 1.08037   Valid Loss: 1.01749\n",
            "[ Epoch 2436/10000 ] Train Loss: 1.08128   Valid Loss: 1.01587\n",
            "[ Epoch 2437/10000 ] Train Loss: 1.08250   Valid Loss: 1.01775\n",
            "[ Epoch 2438/10000 ] Train Loss: 1.08178   Valid Loss: 1.01566\n",
            "[ Epoch 2439/10000 ] Train Loss: 1.07930   Valid Loss: 1.01577\n",
            "[ Epoch 2440/10000 ] Train Loss: 1.08345   Valid Loss: 1.02256\n",
            "[ Epoch 2441/10000 ] Train Loss: 1.08355   Valid Loss: 1.01708\n",
            "[ Epoch 2442/10000 ] Train Loss: 1.08136   Valid Loss: 1.01540\n",
            "[ Epoch 2443/10000 ] Train Loss: 1.08250   Valid Loss: 1.02014\n",
            "[ Epoch 2444/10000 ] Train Loss: 1.08277   Valid Loss: 1.01543\n",
            "[ Epoch 2445/10000 ] Train Loss: 1.08103   Valid Loss: 1.01443\n",
            "Early Stop Saving Model on Epoch 2445/10000\n",
            "[ Epoch 2446/10000 ] Train Loss: 1.08091   Valid Loss: 1.01685\n",
            "[ Epoch 2447/10000 ] Train Loss: 1.08053   Valid Loss: 1.01511\n",
            "[ Epoch 2448/10000 ] Train Loss: 1.08116   Valid Loss: 1.01754\n",
            "[ Epoch 2449/10000 ] Train Loss: 1.07997   Valid Loss: 1.01909\n",
            "[ Epoch 2450/10000 ] Train Loss: 1.08196   Valid Loss: 1.01947\n",
            "[ Epoch 2451/10000 ] Train Loss: 1.08255   Valid Loss: 1.01766\n",
            "[ Epoch 2452/10000 ] Train Loss: 1.08313   Valid Loss: 1.01676\n",
            "[ Epoch 2453/10000 ] Train Loss: 1.08258   Valid Loss: 1.01739\n",
            "[ Epoch 2454/10000 ] Train Loss: 1.08641   Valid Loss: 1.01487\n",
            "[ Epoch 2455/10000 ] Train Loss: 1.08397   Valid Loss: 1.01567\n",
            "[ Epoch 2456/10000 ] Train Loss: 1.08173   Valid Loss: 1.01928\n",
            "[ Epoch 2457/10000 ] Train Loss: 1.08113   Valid Loss: 1.01608\n",
            "[ Epoch 2458/10000 ] Train Loss: 1.08113   Valid Loss: 1.01478\n",
            "[ Epoch 2459/10000 ] Train Loss: 1.08139   Valid Loss: 1.01520\n",
            "[ Epoch 2460/10000 ] Train Loss: 1.07982   Valid Loss: 1.01699\n",
            "[ Epoch 2461/10000 ] Train Loss: 1.08308   Valid Loss: 1.01820\n",
            "[ Epoch 2462/10000 ] Train Loss: 1.08132   Valid Loss: 1.01541\n",
            "[ Epoch 2463/10000 ] Train Loss: 1.08043   Valid Loss: 1.01572\n",
            "[ Epoch 2464/10000 ] Train Loss: 1.08146   Valid Loss: 1.01570\n",
            "[ Epoch 2465/10000 ] Train Loss: 1.07973   Valid Loss: 1.01510\n",
            "[ Epoch 2466/10000 ] Train Loss: 1.08119   Valid Loss: 1.01636\n",
            "[ Epoch 2467/10000 ] Train Loss: 1.08205   Valid Loss: 1.01489\n",
            "[ Epoch 2468/10000 ] Train Loss: 1.08013   Valid Loss: 1.01433\n",
            "Early Stop Saving Model on Epoch 2468/10000\n",
            "[ Epoch 2469/10000 ] Train Loss: 1.08098   Valid Loss: 1.01941\n",
            "[ Epoch 2470/10000 ] Train Loss: 1.08455   Valid Loss: 1.01601\n",
            "[ Epoch 2471/10000 ] Train Loss: 1.08450   Valid Loss: 1.02110\n",
            "[ Epoch 2472/10000 ] Train Loss: 1.08441   Valid Loss: 1.01571\n",
            "[ Epoch 2473/10000 ] Train Loss: 1.08212   Valid Loss: 1.01678\n",
            "[ Epoch 2474/10000 ] Train Loss: 1.08267   Valid Loss: 1.01757\n",
            "[ Epoch 2475/10000 ] Train Loss: 1.08144   Valid Loss: 1.01494\n",
            "[ Epoch 2476/10000 ] Train Loss: 1.08091   Valid Loss: 1.01509\n",
            "[ Epoch 2477/10000 ] Train Loss: 1.08334   Valid Loss: 1.01540\n",
            "[ Epoch 2478/10000 ] Train Loss: 1.08235   Valid Loss: 1.01747\n",
            "[ Epoch 2479/10000 ] Train Loss: 1.08054   Valid Loss: 1.01488\n",
            "[ Epoch 2480/10000 ] Train Loss: 1.07814   Valid Loss: 1.01488\n",
            "[ Epoch 2481/10000 ] Train Loss: 1.08076   Valid Loss: 1.01422\n",
            "Early Stop Saving Model on Epoch 2481/10000\n",
            "[ Epoch 2482/10000 ] Train Loss: 1.08210   Valid Loss: 1.01613\n",
            "[ Epoch 2483/10000 ] Train Loss: 1.08232   Valid Loss: 1.01427\n",
            "[ Epoch 2484/10000 ] Train Loss: 1.07973   Valid Loss: 1.01511\n",
            "[ Epoch 2485/10000 ] Train Loss: 1.08091   Valid Loss: 1.01697\n",
            "[ Epoch 2486/10000 ] Train Loss: 1.07986   Valid Loss: 1.01844\n",
            "[ Epoch 2487/10000 ] Train Loss: 1.08191   Valid Loss: 1.01545\n",
            "[ Epoch 2488/10000 ] Train Loss: 1.08290   Valid Loss: 1.01519\n",
            "[ Epoch 2489/10000 ] Train Loss: 1.08199   Valid Loss: 1.01416\n",
            "Early Stop Saving Model on Epoch 2489/10000\n",
            "[ Epoch 2490/10000 ] Train Loss: 1.07954   Valid Loss: 1.01486\n",
            "[ Epoch 2491/10000 ] Train Loss: 1.07924   Valid Loss: 1.01573\n",
            "[ Epoch 2492/10000 ] Train Loss: 1.08044   Valid Loss: 1.01454\n",
            "[ Epoch 2493/10000 ] Train Loss: 1.08224   Valid Loss: 1.01499\n",
            "[ Epoch 2494/10000 ] Train Loss: 1.08094   Valid Loss: 1.01590\n",
            "[ Epoch 2495/10000 ] Train Loss: 1.07986   Valid Loss: 1.01461\n",
            "[ Epoch 2496/10000 ] Train Loss: 1.07980   Valid Loss: 1.01635\n",
            "[ Epoch 2497/10000 ] Train Loss: 1.08124   Valid Loss: 1.01470\n",
            "[ Epoch 2498/10000 ] Train Loss: 1.08099   Valid Loss: 1.01615\n",
            "[ Epoch 2499/10000 ] Train Loss: 1.08158   Valid Loss: 1.01601\n",
            "[ Epoch 2500/10000 ] Train Loss: 1.08063   Valid Loss: 1.01541\n",
            "[ Epoch 2501/10000 ] Train Loss: 1.07950   Valid Loss: 1.01438\n",
            "[ Epoch 2502/10000 ] Train Loss: 1.08154   Valid Loss: 1.01771\n",
            "[ Epoch 2503/10000 ] Train Loss: 1.08217   Valid Loss: 1.01566\n",
            "[ Epoch 2504/10000 ] Train Loss: 1.07996   Valid Loss: 1.01480\n",
            "[ Epoch 2505/10000 ] Train Loss: 1.08131   Valid Loss: 1.01425\n",
            "[ Epoch 2506/10000 ] Train Loss: 1.07914   Valid Loss: 1.01451\n",
            "[ Epoch 2507/10000 ] Train Loss: 1.07902   Valid Loss: 1.01440\n",
            "[ Epoch 2508/10000 ] Train Loss: 1.07912   Valid Loss: 1.01431\n",
            "[ Epoch 2509/10000 ] Train Loss: 1.08078   Valid Loss: 1.01650\n",
            "[ Epoch 2510/10000 ] Train Loss: 1.08013   Valid Loss: 1.01671\n",
            "[ Epoch 2511/10000 ] Train Loss: 1.08001   Valid Loss: 1.01708\n",
            "[ Epoch 2512/10000 ] Train Loss: 1.07968   Valid Loss: 1.01550\n",
            "[ Epoch 2513/10000 ] Train Loss: 1.07877   Valid Loss: 1.01504\n",
            "[ Epoch 2514/10000 ] Train Loss: 1.08133   Valid Loss: 1.01653\n",
            "[ Epoch 2515/10000 ] Train Loss: 1.07955   Valid Loss: 1.01489\n",
            "[ Epoch 2516/10000 ] Train Loss: 1.08023   Valid Loss: 1.01378\n",
            "Early Stop Saving Model on Epoch 2516/10000\n",
            "[ Epoch 2517/10000 ] Train Loss: 1.08007   Valid Loss: 1.01467\n",
            "[ Epoch 2518/10000 ] Train Loss: 1.07954   Valid Loss: 1.01647\n",
            "[ Epoch 2519/10000 ] Train Loss: 1.08238   Valid Loss: 1.01559\n",
            "[ Epoch 2520/10000 ] Train Loss: 1.07999   Valid Loss: 1.01441\n",
            "[ Epoch 2521/10000 ] Train Loss: 1.08002   Valid Loss: 1.01537\n",
            "[ Epoch 2522/10000 ] Train Loss: 1.08057   Valid Loss: 1.01536\n",
            "[ Epoch 2523/10000 ] Train Loss: 1.08011   Valid Loss: 1.01482\n",
            "[ Epoch 2524/10000 ] Train Loss: 1.08019   Valid Loss: 1.01421\n",
            "[ Epoch 2525/10000 ] Train Loss: 1.08162   Valid Loss: 1.01639\n",
            "[ Epoch 2526/10000 ] Train Loss: 1.07947   Valid Loss: 1.01463\n",
            "[ Epoch 2527/10000 ] Train Loss: 1.08009   Valid Loss: 1.01464\n",
            "[ Epoch 2528/10000 ] Train Loss: 1.07955   Valid Loss: 1.01638\n",
            "[ Epoch 2529/10000 ] Train Loss: 1.08007   Valid Loss: 1.01465\n",
            "[ Epoch 2530/10000 ] Train Loss: 1.08063   Valid Loss: 1.01509\n",
            "[ Epoch 2531/10000 ] Train Loss: 1.08040   Valid Loss: 1.01408\n",
            "[ Epoch 2532/10000 ] Train Loss: 1.07954   Valid Loss: 1.01440\n",
            "[ Epoch 2533/10000 ] Train Loss: 1.07905   Valid Loss: 1.01506\n",
            "[ Epoch 2534/10000 ] Train Loss: 1.08301   Valid Loss: 1.01715\n",
            "[ Epoch 2535/10000 ] Train Loss: 1.08383   Valid Loss: 1.01544\n",
            "[ Epoch 2536/10000 ] Train Loss: 1.08047   Valid Loss: 1.01340\n",
            "Early Stop Saving Model on Epoch 2536/10000\n",
            "[ Epoch 2537/10000 ] Train Loss: 1.08140   Valid Loss: 1.01449\n",
            "[ Epoch 2538/10000 ] Train Loss: 1.07879   Valid Loss: 1.01400\n",
            "[ Epoch 2539/10000 ] Train Loss: 1.08219   Valid Loss: 1.01882\n",
            "[ Epoch 2540/10000 ] Train Loss: 1.08139   Valid Loss: 1.01621\n",
            "[ Epoch 2541/10000 ] Train Loss: 1.08229   Valid Loss: 1.01427\n",
            "[ Epoch 2542/10000 ] Train Loss: 1.08086   Valid Loss: 1.01465\n",
            "[ Epoch 2543/10000 ] Train Loss: 1.08111   Valid Loss: 1.01395\n",
            "[ Epoch 2544/10000 ] Train Loss: 1.07932   Valid Loss: 1.01454\n",
            "[ Epoch 2545/10000 ] Train Loss: 1.07846   Valid Loss: 1.01391\n",
            "[ Epoch 2546/10000 ] Train Loss: 1.07869   Valid Loss: 1.01495\n",
            "[ Epoch 2547/10000 ] Train Loss: 1.08052   Valid Loss: 1.01377\n",
            "[ Epoch 2548/10000 ] Train Loss: 1.08049   Valid Loss: 1.01433\n",
            "[ Epoch 2549/10000 ] Train Loss: 1.07954   Valid Loss: 1.01492\n",
            "[ Epoch 2550/10000 ] Train Loss: 1.08057   Valid Loss: 1.01483\n",
            "[ Epoch 2551/10000 ] Train Loss: 1.08017   Valid Loss: 1.01593\n",
            "[ Epoch 2552/10000 ] Train Loss: 1.08013   Valid Loss: 1.01503\n",
            "[ Epoch 2553/10000 ] Train Loss: 1.07918   Valid Loss: 1.01642\n",
            "[ Epoch 2554/10000 ] Train Loss: 1.08063   Valid Loss: 1.01281\n",
            "Early Stop Saving Model on Epoch 2554/10000\n",
            "[ Epoch 2555/10000 ] Train Loss: 1.08034   Valid Loss: 1.01510\n",
            "[ Epoch 2556/10000 ] Train Loss: 1.08326   Valid Loss: 1.01661\n",
            "[ Epoch 2557/10000 ] Train Loss: 1.08151   Valid Loss: 1.01354\n",
            "[ Epoch 2558/10000 ] Train Loss: 1.08093   Valid Loss: 1.01648\n",
            "[ Epoch 2559/10000 ] Train Loss: 1.07905   Valid Loss: 1.01660\n",
            "[ Epoch 2560/10000 ] Train Loss: 1.08161   Valid Loss: 1.01312\n",
            "[ Epoch 2561/10000 ] Train Loss: 1.07985   Valid Loss: 1.01658\n",
            "[ Epoch 2562/10000 ] Train Loss: 1.08097   Valid Loss: 1.01820\n",
            "[ Epoch 2563/10000 ] Train Loss: 1.08019   Valid Loss: 1.01459\n",
            "[ Epoch 2564/10000 ] Train Loss: 1.07935   Valid Loss: 1.01402\n",
            "[ Epoch 2565/10000 ] Train Loss: 1.07833   Valid Loss: 1.01398\n",
            "[ Epoch 2566/10000 ] Train Loss: 1.07905   Valid Loss: 1.01351\n",
            "[ Epoch 2567/10000 ] Train Loss: 1.08100   Valid Loss: 1.01720\n",
            "[ Epoch 2568/10000 ] Train Loss: 1.07979   Valid Loss: 1.01312\n",
            "[ Epoch 2569/10000 ] Train Loss: 1.08032   Valid Loss: 1.01425\n",
            "[ Epoch 2570/10000 ] Train Loss: 1.07958   Valid Loss: 1.01538\n",
            "[ Epoch 2571/10000 ] Train Loss: 1.08146   Valid Loss: 1.01785\n",
            "[ Epoch 2572/10000 ] Train Loss: 1.08103   Valid Loss: 1.01530\n",
            "[ Epoch 2573/10000 ] Train Loss: 1.08273   Valid Loss: 1.01561\n",
            "[ Epoch 2574/10000 ] Train Loss: 1.08256   Valid Loss: 1.01838\n",
            "[ Epoch 2575/10000 ] Train Loss: 1.07834   Valid Loss: 1.01677\n",
            "[ Epoch 2576/10000 ] Train Loss: 1.08000   Valid Loss: 1.01755\n",
            "[ Epoch 2577/10000 ] Train Loss: 1.08021   Valid Loss: 1.01415\n",
            "[ Epoch 2578/10000 ] Train Loss: 1.07939   Valid Loss: 1.01386\n",
            "[ Epoch 2579/10000 ] Train Loss: 1.08018   Valid Loss: 1.01447\n",
            "[ Epoch 2580/10000 ] Train Loss: 1.07960   Valid Loss: 1.01436\n",
            "[ Epoch 2581/10000 ] Train Loss: 1.07909   Valid Loss: 1.01409\n",
            "[ Epoch 2582/10000 ] Train Loss: 1.07914   Valid Loss: 1.01386\n",
            "[ Epoch 2583/10000 ] Train Loss: 1.08078   Valid Loss: 1.01367\n",
            "[ Epoch 2584/10000 ] Train Loss: 1.07963   Valid Loss: 1.01338\n",
            "[ Epoch 2585/10000 ] Train Loss: 1.07922   Valid Loss: 1.01467\n",
            "[ Epoch 2586/10000 ] Train Loss: 1.08104   Valid Loss: 1.01467\n",
            "[ Epoch 2587/10000 ] Train Loss: 1.07880   Valid Loss: 1.01373\n",
            "[ Epoch 2588/10000 ] Train Loss: 1.08078   Valid Loss: 1.01290\n",
            "[ Epoch 2589/10000 ] Train Loss: 1.07769   Valid Loss: 1.01408\n",
            "[ Epoch 2590/10000 ] Train Loss: 1.07884   Valid Loss: 1.01430\n",
            "[ Epoch 2591/10000 ] Train Loss: 1.07973   Valid Loss: 1.01977\n",
            "[ Epoch 2592/10000 ] Train Loss: 1.08038   Valid Loss: 1.01625\n",
            "[ Epoch 2593/10000 ] Train Loss: 1.08080   Valid Loss: 1.01423\n",
            "[ Epoch 2594/10000 ] Train Loss: 1.08097   Valid Loss: 1.01467\n",
            "[ Epoch 2595/10000 ] Train Loss: 1.07813   Valid Loss: 1.01399\n",
            "[ Epoch 2596/10000 ] Train Loss: 1.08130   Valid Loss: 1.02010\n",
            "[ Epoch 2597/10000 ] Train Loss: 1.08883   Valid Loss: 1.01578\n",
            "[ Epoch 2598/10000 ] Train Loss: 1.08018   Valid Loss: 1.01434\n",
            "[ Epoch 2599/10000 ] Train Loss: 1.08250   Valid Loss: 1.01694\n",
            "[ Epoch 2600/10000 ] Train Loss: 1.08116   Valid Loss: 1.01459\n",
            "[ Epoch 2601/10000 ] Train Loss: 1.08205   Valid Loss: 1.01396\n",
            "[ Epoch 2602/10000 ] Train Loss: 1.08043   Valid Loss: 1.01492\n",
            "[ Epoch 2603/10000 ] Train Loss: 1.08020   Valid Loss: 1.01311\n",
            "[ Epoch 2604/10000 ] Train Loss: 1.07580   Valid Loss: 1.01355\n",
            "[ Epoch 2605/10000 ] Train Loss: 1.07990   Valid Loss: 1.01312\n",
            "[ Epoch 2606/10000 ] Train Loss: 1.07953   Valid Loss: 1.01459\n",
            "[ Epoch 2607/10000 ] Train Loss: 1.08051   Valid Loss: 1.02110\n",
            "[ Epoch 2608/10000 ] Train Loss: 1.08549   Valid Loss: 1.01235\n",
            "Early Stop Saving Model on Epoch 2608/10000\n",
            "[ Epoch 2609/10000 ] Train Loss: 1.07827   Valid Loss: 1.01400\n",
            "[ Epoch 2610/10000 ] Train Loss: 1.07948   Valid Loss: 1.01304\n",
            "[ Epoch 2611/10000 ] Train Loss: 1.08193   Valid Loss: 1.01381\n",
            "[ Epoch 2612/10000 ] Train Loss: 1.07942   Valid Loss: 1.01304\n",
            "[ Epoch 2613/10000 ] Train Loss: 1.07934   Valid Loss: 1.01422\n",
            "[ Epoch 2614/10000 ] Train Loss: 1.07855   Valid Loss: 1.01294\n",
            "[ Epoch 2615/10000 ] Train Loss: 1.08294   Valid Loss: 1.01341\n",
            "[ Epoch 2616/10000 ] Train Loss: 1.07919   Valid Loss: 1.01271\n",
            "[ Epoch 2617/10000 ] Train Loss: 1.07960   Valid Loss: 1.01430\n",
            "[ Epoch 2618/10000 ] Train Loss: 1.07825   Valid Loss: 1.01254\n",
            "[ Epoch 2619/10000 ] Train Loss: 1.08141   Valid Loss: 1.01377\n",
            "[ Epoch 2620/10000 ] Train Loss: 1.07960   Valid Loss: 1.01309\n",
            "[ Epoch 2621/10000 ] Train Loss: 1.07837   Valid Loss: 1.01281\n",
            "[ Epoch 2622/10000 ] Train Loss: 1.07814   Valid Loss: 1.01296\n",
            "[ Epoch 2623/10000 ] Train Loss: 1.07835   Valid Loss: 1.01293\n",
            "[ Epoch 2624/10000 ] Train Loss: 1.07835   Valid Loss: 1.01230\n",
            "Early Stop Saving Model on Epoch 2624/10000\n",
            "[ Epoch 2625/10000 ] Train Loss: 1.07963   Valid Loss: 1.01629\n",
            "[ Epoch 2626/10000 ] Train Loss: 1.08019   Valid Loss: 1.01294\n",
            "[ Epoch 2627/10000 ] Train Loss: 1.07866   Valid Loss: 1.01249\n",
            "[ Epoch 2628/10000 ] Train Loss: 1.07751   Valid Loss: 1.01299\n",
            "[ Epoch 2629/10000 ] Train Loss: 1.07954   Valid Loss: 1.01818\n",
            "[ Epoch 2630/10000 ] Train Loss: 1.08348   Valid Loss: 1.02233\n",
            "[ Epoch 2631/10000 ] Train Loss: 1.07898   Valid Loss: 1.01734\n",
            "[ Epoch 2632/10000 ] Train Loss: 1.07956   Valid Loss: 1.01378\n",
            "[ Epoch 2633/10000 ] Train Loss: 1.08092   Valid Loss: 1.01265\n",
            "[ Epoch 2634/10000 ] Train Loss: 1.08030   Valid Loss: 1.01437\n",
            "[ Epoch 2635/10000 ] Train Loss: 1.07906   Valid Loss: 1.01460\n",
            "[ Epoch 2636/10000 ] Train Loss: 1.08016   Valid Loss: 1.01361\n",
            "[ Epoch 2637/10000 ] Train Loss: 1.07845   Valid Loss: 1.01241\n",
            "[ Epoch 2638/10000 ] Train Loss: 1.07843   Valid Loss: 1.01357\n",
            "[ Epoch 2639/10000 ] Train Loss: 1.07765   Valid Loss: 1.01352\n",
            "[ Epoch 2640/10000 ] Train Loss: 1.07858   Valid Loss: 1.01228\n",
            "Early Stop Saving Model on Epoch 2640/10000\n",
            "[ Epoch 2641/10000 ] Train Loss: 1.07936   Valid Loss: 1.01351\n",
            "[ Epoch 2642/10000 ] Train Loss: 1.08030   Valid Loss: 1.01399\n",
            "[ Epoch 2643/10000 ] Train Loss: 1.07951   Valid Loss: 1.01411\n",
            "[ Epoch 2644/10000 ] Train Loss: 1.07902   Valid Loss: 1.01327\n",
            "[ Epoch 2645/10000 ] Train Loss: 1.07936   Valid Loss: 1.01820\n",
            "[ Epoch 2646/10000 ] Train Loss: 1.08690   Valid Loss: 1.01497\n",
            "[ Epoch 2647/10000 ] Train Loss: 1.07596   Valid Loss: 1.01242\n",
            "[ Epoch 2648/10000 ] Train Loss: 1.07858   Valid Loss: 1.01450\n",
            "[ Epoch 2649/10000 ] Train Loss: 1.07986   Valid Loss: 1.01405\n",
            "[ Epoch 2650/10000 ] Train Loss: 1.07691   Valid Loss: 1.01265\n",
            "[ Epoch 2651/10000 ] Train Loss: 1.07730   Valid Loss: 1.01292\n",
            "[ Epoch 2652/10000 ] Train Loss: 1.07854   Valid Loss: 1.01258\n",
            "[ Epoch 2653/10000 ] Train Loss: 1.07830   Valid Loss: 1.01197\n",
            "Early Stop Saving Model on Epoch 2653/10000\n",
            "[ Epoch 2654/10000 ] Train Loss: 1.07741   Valid Loss: 1.01323\n",
            "[ Epoch 2655/10000 ] Train Loss: 1.07926   Valid Loss: 1.01689\n",
            "[ Epoch 2656/10000 ] Train Loss: 1.07937   Valid Loss: 1.01281\n",
            "[ Epoch 2657/10000 ] Train Loss: 1.07669   Valid Loss: 1.01493\n",
            "[ Epoch 2658/10000 ] Train Loss: 1.07846   Valid Loss: 1.01152\n",
            "Early Stop Saving Model on Epoch 2658/10000\n",
            "[ Epoch 2659/10000 ] Train Loss: 1.07751   Valid Loss: 1.01290\n",
            "[ Epoch 2660/10000 ] Train Loss: 1.07804   Valid Loss: 1.01250\n",
            "[ Epoch 2661/10000 ] Train Loss: 1.07703   Valid Loss: 1.01444\n",
            "[ Epoch 2662/10000 ] Train Loss: 1.08051   Valid Loss: 1.01280\n",
            "[ Epoch 2663/10000 ] Train Loss: 1.07776   Valid Loss: 1.01205\n",
            "[ Epoch 2664/10000 ] Train Loss: 1.07802   Valid Loss: 1.01313\n",
            "[ Epoch 2665/10000 ] Train Loss: 1.07977   Valid Loss: 1.01281\n",
            "[ Epoch 2666/10000 ] Train Loss: 1.07850   Valid Loss: 1.01121\n",
            "Early Stop Saving Model on Epoch 2666/10000\n",
            "[ Epoch 2667/10000 ] Train Loss: 1.07803   Valid Loss: 1.01277\n",
            "[ Epoch 2668/10000 ] Train Loss: 1.07875   Valid Loss: 1.01354\n",
            "[ Epoch 2669/10000 ] Train Loss: 1.08038   Valid Loss: 1.01518\n",
            "[ Epoch 2670/10000 ] Train Loss: 1.08065   Valid Loss: 1.01179\n",
            "[ Epoch 2671/10000 ] Train Loss: 1.07888   Valid Loss: 1.01410\n",
            "[ Epoch 2672/10000 ] Train Loss: 1.07721   Valid Loss: 1.01337\n",
            "[ Epoch 2673/10000 ] Train Loss: 1.07808   Valid Loss: 1.01501\n",
            "[ Epoch 2674/10000 ] Train Loss: 1.07961   Valid Loss: 1.01130\n",
            "[ Epoch 2675/10000 ] Train Loss: 1.07941   Valid Loss: 1.01284\n",
            "[ Epoch 2676/10000 ] Train Loss: 1.07924   Valid Loss: 1.01234\n",
            "[ Epoch 2677/10000 ] Train Loss: 1.07909   Valid Loss: 1.01191\n",
            "[ Epoch 2678/10000 ] Train Loss: 1.08100   Valid Loss: 1.01445\n",
            "[ Epoch 2679/10000 ] Train Loss: 1.07938   Valid Loss: 1.01227\n",
            "[ Epoch 2680/10000 ] Train Loss: 1.07880   Valid Loss: 1.01128\n",
            "[ Epoch 2681/10000 ] Train Loss: 1.07784   Valid Loss: 1.01167\n",
            "[ Epoch 2682/10000 ] Train Loss: 1.07910   Valid Loss: 1.01279\n",
            "[ Epoch 2683/10000 ] Train Loss: 1.07958   Valid Loss: 1.01798\n",
            "[ Epoch 2684/10000 ] Train Loss: 1.08338   Valid Loss: 1.01224\n",
            "[ Epoch 2685/10000 ] Train Loss: 1.07837   Valid Loss: 1.01311\n",
            "[ Epoch 2686/10000 ] Train Loss: 1.07838   Valid Loss: 1.01660\n",
            "[ Epoch 2687/10000 ] Train Loss: 1.08240   Valid Loss: 1.01176\n",
            "[ Epoch 2688/10000 ] Train Loss: 1.07822   Valid Loss: 1.01114\n",
            "Early Stop Saving Model on Epoch 2688/10000\n",
            "[ Epoch 2689/10000 ] Train Loss: 1.07712   Valid Loss: 1.01355\n",
            "[ Epoch 2690/10000 ] Train Loss: 1.07869   Valid Loss: 1.01306\n",
            "[ Epoch 2691/10000 ] Train Loss: 1.07764   Valid Loss: 1.01099\n",
            "Early Stop Saving Model on Epoch 2691/10000\n",
            "[ Epoch 2692/10000 ] Train Loss: 1.07777   Valid Loss: 1.01800\n",
            "[ Epoch 2693/10000 ] Train Loss: 1.08043   Valid Loss: 1.01974\n",
            "[ Epoch 2694/10000 ] Train Loss: 1.08000   Valid Loss: 1.01236\n",
            "[ Epoch 2695/10000 ] Train Loss: 1.07723   Valid Loss: 1.01141\n",
            "[ Epoch 2696/10000 ] Train Loss: 1.07798   Valid Loss: 1.01114\n",
            "[ Epoch 2697/10000 ] Train Loss: 1.07814   Valid Loss: 1.01254\n",
            "[ Epoch 2698/10000 ] Train Loss: 1.07828   Valid Loss: 1.01129\n",
            "[ Epoch 2699/10000 ] Train Loss: 1.07875   Valid Loss: 1.01385\n",
            "[ Epoch 2700/10000 ] Train Loss: 1.08074   Valid Loss: 1.01916\n",
            "[ Epoch 2701/10000 ] Train Loss: 1.08429   Valid Loss: 1.01389\n",
            "[ Epoch 2702/10000 ] Train Loss: 1.08046   Valid Loss: 1.01267\n",
            "[ Epoch 2703/10000 ] Train Loss: 1.07826   Valid Loss: 1.01165\n",
            "[ Epoch 2704/10000 ] Train Loss: 1.07756   Valid Loss: 1.01247\n",
            "[ Epoch 2705/10000 ] Train Loss: 1.07745   Valid Loss: 1.01152\n",
            "[ Epoch 2706/10000 ] Train Loss: 1.07832   Valid Loss: 1.01232\n",
            "[ Epoch 2707/10000 ] Train Loss: 1.07867   Valid Loss: 1.01054\n",
            "Early Stop Saving Model on Epoch 2707/10000\n",
            "[ Epoch 2708/10000 ] Train Loss: 1.07988   Valid Loss: 1.01390\n",
            "[ Epoch 2709/10000 ] Train Loss: 1.07698   Valid Loss: 1.01311\n",
            "[ Epoch 2710/10000 ] Train Loss: 1.07873   Valid Loss: 1.01287\n",
            "[ Epoch 2711/10000 ] Train Loss: 1.07715   Valid Loss: 1.01181\n",
            "[ Epoch 2712/10000 ] Train Loss: 1.07767   Valid Loss: 1.01197\n",
            "[ Epoch 2713/10000 ] Train Loss: 1.07835   Valid Loss: 1.01141\n",
            "[ Epoch 2714/10000 ] Train Loss: 1.07941   Valid Loss: 1.01182\n",
            "[ Epoch 2715/10000 ] Train Loss: 1.07950   Valid Loss: 1.01346\n",
            "[ Epoch 2716/10000 ] Train Loss: 1.07710   Valid Loss: 1.01376\n",
            "[ Epoch 2717/10000 ] Train Loss: 1.07913   Valid Loss: 1.01135\n",
            "[ Epoch 2718/10000 ] Train Loss: 1.07809   Valid Loss: 1.01261\n",
            "[ Epoch 2719/10000 ] Train Loss: 1.07499   Valid Loss: 1.01159\n",
            "[ Epoch 2720/10000 ] Train Loss: 1.07697   Valid Loss: 1.01239\n",
            "[ Epoch 2721/10000 ] Train Loss: 1.07795   Valid Loss: 1.01386\n",
            "[ Epoch 2722/10000 ] Train Loss: 1.08062   Valid Loss: 1.02598\n",
            "[ Epoch 2723/10000 ] Train Loss: 1.08370   Valid Loss: 1.02341\n",
            "[ Epoch 2724/10000 ] Train Loss: 1.08013   Valid Loss: 1.01556\n",
            "[ Epoch 2725/10000 ] Train Loss: 1.08032   Valid Loss: 1.01108\n",
            "[ Epoch 2726/10000 ] Train Loss: 1.07875   Valid Loss: 1.01285\n",
            "[ Epoch 2727/10000 ] Train Loss: 1.07886   Valid Loss: 1.01050\n",
            "Early Stop Saving Model on Epoch 2727/10000\n",
            "[ Epoch 2728/10000 ] Train Loss: 1.07604   Valid Loss: 1.01169\n",
            "[ Epoch 2729/10000 ] Train Loss: 1.07630   Valid Loss: 1.01034\n",
            "Early Stop Saving Model on Epoch 2729/10000\n",
            "[ Epoch 2730/10000 ] Train Loss: 1.07617   Valid Loss: 1.01304\n",
            "[ Epoch 2731/10000 ] Train Loss: 1.07685   Valid Loss: 1.01155\n",
            "[ Epoch 2732/10000 ] Train Loss: 1.07788   Valid Loss: 1.01299\n",
            "[ Epoch 2733/10000 ] Train Loss: 1.07738   Valid Loss: 1.01115\n",
            "[ Epoch 2734/10000 ] Train Loss: 1.07599   Valid Loss: 1.01122\n",
            "[ Epoch 2735/10000 ] Train Loss: 1.07727   Valid Loss: 1.01052\n",
            "[ Epoch 2736/10000 ] Train Loss: 1.07783   Valid Loss: 1.01441\n",
            "[ Epoch 2737/10000 ] Train Loss: 1.07786   Valid Loss: 1.01368\n",
            "[ Epoch 2738/10000 ] Train Loss: 1.07828   Valid Loss: 1.01058\n",
            "[ Epoch 2739/10000 ] Train Loss: 1.07840   Valid Loss: 1.01222\n",
            "[ Epoch 2740/10000 ] Train Loss: 1.07929   Valid Loss: 1.01282\n",
            "[ Epoch 2741/10000 ] Train Loss: 1.07830   Valid Loss: 1.01463\n",
            "[ Epoch 2742/10000 ] Train Loss: 1.07742   Valid Loss: 1.01234\n",
            "[ Epoch 2743/10000 ] Train Loss: 1.07585   Valid Loss: 1.01075\n",
            "[ Epoch 2744/10000 ] Train Loss: 1.07639   Valid Loss: 1.01202\n",
            "[ Epoch 2745/10000 ] Train Loss: 1.07586   Valid Loss: 1.01286\n",
            "[ Epoch 2746/10000 ] Train Loss: 1.07735   Valid Loss: 1.01187\n",
            "[ Epoch 2747/10000 ] Train Loss: 1.07601   Valid Loss: 1.01002\n",
            "Early Stop Saving Model on Epoch 2747/10000\n",
            "[ Epoch 2748/10000 ] Train Loss: 1.07705   Valid Loss: 1.01142\n",
            "[ Epoch 2749/10000 ] Train Loss: 1.07665   Valid Loss: 1.01491\n",
            "[ Epoch 2750/10000 ] Train Loss: 1.07728   Valid Loss: 1.01267\n",
            "[ Epoch 2751/10000 ] Train Loss: 1.07909   Valid Loss: 1.01108\n",
            "[ Epoch 2752/10000 ] Train Loss: 1.07715   Valid Loss: 1.01090\n",
            "[ Epoch 2753/10000 ] Train Loss: 1.07676   Valid Loss: 1.01210\n",
            "[ Epoch 2754/10000 ] Train Loss: 1.07678   Valid Loss: 1.01139\n",
            "[ Epoch 2755/10000 ] Train Loss: 1.07690   Valid Loss: 1.01111\n",
            "[ Epoch 2756/10000 ] Train Loss: 1.07646   Valid Loss: 1.01195\n",
            "[ Epoch 2757/10000 ] Train Loss: 1.07722   Valid Loss: 1.01164\n",
            "[ Epoch 2758/10000 ] Train Loss: 1.07696   Valid Loss: 1.01126\n",
            "[ Epoch 2759/10000 ] Train Loss: 1.07677   Valid Loss: 1.01129\n",
            "[ Epoch 2760/10000 ] Train Loss: 1.07625   Valid Loss: 1.01015\n",
            "[ Epoch 2761/10000 ] Train Loss: 1.07776   Valid Loss: 1.01059\n",
            "[ Epoch 2762/10000 ] Train Loss: 1.07717   Valid Loss: 1.01151\n",
            "[ Epoch 2763/10000 ] Train Loss: 1.07519   Valid Loss: 1.01490\n",
            "[ Epoch 2764/10000 ] Train Loss: 1.07999   Valid Loss: 1.01216\n",
            "[ Epoch 2765/10000 ] Train Loss: 1.08161   Valid Loss: 1.01301\n",
            "[ Epoch 2766/10000 ] Train Loss: 1.07935   Valid Loss: 1.01490\n",
            "[ Epoch 2767/10000 ] Train Loss: 1.08034   Valid Loss: 1.01616\n",
            "[ Epoch 2768/10000 ] Train Loss: 1.08164   Valid Loss: 1.01124\n",
            "[ Epoch 2769/10000 ] Train Loss: 1.07716   Valid Loss: 1.01055\n",
            "[ Epoch 2770/10000 ] Train Loss: 1.07673   Valid Loss: 1.01135\n",
            "[ Epoch 2771/10000 ] Train Loss: 1.07526   Valid Loss: 1.01045\n",
            "[ Epoch 2772/10000 ] Train Loss: 1.07619   Valid Loss: 1.00968\n",
            "Early Stop Saving Model on Epoch 2772/10000\n",
            "[ Epoch 2773/10000 ] Train Loss: 1.07568   Valid Loss: 1.01123\n",
            "[ Epoch 2774/10000 ] Train Loss: 1.07597   Valid Loss: 1.01118\n",
            "[ Epoch 2775/10000 ] Train Loss: 1.07850   Valid Loss: 1.01266\n",
            "[ Epoch 2776/10000 ] Train Loss: 1.07644   Valid Loss: 1.01271\n",
            "[ Epoch 2777/10000 ] Train Loss: 1.07684   Valid Loss: 1.01212\n",
            "[ Epoch 2778/10000 ] Train Loss: 1.07628   Valid Loss: 1.00965\n",
            "Early Stop Saving Model on Epoch 2778/10000\n",
            "[ Epoch 2779/10000 ] Train Loss: 1.07599   Valid Loss: 1.00976\n",
            "[ Epoch 2780/10000 ] Train Loss: 1.07570   Valid Loss: 1.01082\n",
            "[ Epoch 2781/10000 ] Train Loss: 1.07659   Valid Loss: 1.00960\n",
            "Early Stop Saving Model on Epoch 2781/10000\n",
            "[ Epoch 2782/10000 ] Train Loss: 1.07612   Valid Loss: 1.01126\n",
            "[ Epoch 2783/10000 ] Train Loss: 1.07583   Valid Loss: 1.01360\n",
            "[ Epoch 2784/10000 ] Train Loss: 1.07907   Valid Loss: 1.01299\n",
            "[ Epoch 2785/10000 ] Train Loss: 1.08192   Valid Loss: 1.00952\n",
            "Early Stop Saving Model on Epoch 2785/10000\n",
            "[ Epoch 2786/10000 ] Train Loss: 1.07857   Valid Loss: 1.01398\n",
            "[ Epoch 2787/10000 ] Train Loss: 1.07983   Valid Loss: 1.01955\n",
            "[ Epoch 2788/10000 ] Train Loss: 1.07873   Valid Loss: 1.01321\n",
            "[ Epoch 2789/10000 ] Train Loss: 1.08137   Valid Loss: 1.01130\n",
            "[ Epoch 2790/10000 ] Train Loss: 1.07686   Valid Loss: 1.00964\n",
            "[ Epoch 2791/10000 ] Train Loss: 1.07712   Valid Loss: 1.01098\n",
            "[ Epoch 2792/10000 ] Train Loss: 1.07472   Valid Loss: 1.01393\n",
            "[ Epoch 2793/10000 ] Train Loss: 1.07490   Valid Loss: 1.00992\n",
            "[ Epoch 2794/10000 ] Train Loss: 1.07460   Valid Loss: 1.01045\n",
            "[ Epoch 2795/10000 ] Train Loss: 1.07434   Valid Loss: 1.00953\n",
            "[ Epoch 2796/10000 ] Train Loss: 1.07807   Valid Loss: 1.01135\n",
            "[ Epoch 2797/10000 ] Train Loss: 1.07605   Valid Loss: 1.00941\n",
            "Early Stop Saving Model on Epoch 2797/10000\n",
            "[ Epoch 2798/10000 ] Train Loss: 1.07614   Valid Loss: 1.00972\n",
            "[ Epoch 2799/10000 ] Train Loss: 1.07556   Valid Loss: 1.01059\n",
            "[ Epoch 2800/10000 ] Train Loss: 1.07657   Valid Loss: 1.00982\n",
            "[ Epoch 2801/10000 ] Train Loss: 1.07799   Valid Loss: 1.01064\n",
            "[ Epoch 2802/10000 ] Train Loss: 1.07587   Valid Loss: 1.01082\n",
            "[ Epoch 2803/10000 ] Train Loss: 1.07695   Valid Loss: 1.01041\n",
            "[ Epoch 2804/10000 ] Train Loss: 1.07681   Valid Loss: 1.01403\n",
            "[ Epoch 2805/10000 ] Train Loss: 1.07919   Valid Loss: 1.01126\n",
            "[ Epoch 2806/10000 ] Train Loss: 1.07527   Valid Loss: 1.00983\n",
            "[ Epoch 2807/10000 ] Train Loss: 1.07796   Valid Loss: 1.01049\n",
            "[ Epoch 2808/10000 ] Train Loss: 1.07748   Valid Loss: 1.01072\n",
            "[ Epoch 2809/10000 ] Train Loss: 1.07495   Valid Loss: 1.01195\n",
            "[ Epoch 2810/10000 ] Train Loss: 1.07504   Valid Loss: 1.01045\n",
            "[ Epoch 2811/10000 ] Train Loss: 1.07464   Valid Loss: 1.01432\n",
            "[ Epoch 2812/10000 ] Train Loss: 1.08398   Valid Loss: 1.01261\n",
            "[ Epoch 2813/10000 ] Train Loss: 1.07614   Valid Loss: 1.00943\n",
            "[ Epoch 2814/10000 ] Train Loss: 1.07486   Valid Loss: 1.01157\n",
            "[ Epoch 2815/10000 ] Train Loss: 1.07549   Valid Loss: 1.01538\n",
            "[ Epoch 2816/10000 ] Train Loss: 1.07852   Valid Loss: 1.01270\n",
            "[ Epoch 2817/10000 ] Train Loss: 1.08217   Valid Loss: 1.01300\n",
            "[ Epoch 2818/10000 ] Train Loss: 1.08248   Valid Loss: 1.01175\n",
            "[ Epoch 2819/10000 ] Train Loss: 1.07894   Valid Loss: 1.00924\n",
            "Early Stop Saving Model on Epoch 2819/10000\n",
            "[ Epoch 2820/10000 ] Train Loss: 1.07344   Valid Loss: 1.01117\n",
            "[ Epoch 2821/10000 ] Train Loss: 1.07545   Valid Loss: 1.01027\n",
            "[ Epoch 2822/10000 ] Train Loss: 1.07513   Valid Loss: 1.00897\n",
            "Early Stop Saving Model on Epoch 2822/10000\n",
            "[ Epoch 2823/10000 ] Train Loss: 1.07534   Valid Loss: 1.01008\n",
            "[ Epoch 2824/10000 ] Train Loss: 1.07707   Valid Loss: 1.01235\n",
            "[ Epoch 2825/10000 ] Train Loss: 1.07726   Valid Loss: 1.01068\n",
            "[ Epoch 2826/10000 ] Train Loss: 1.07694   Valid Loss: 1.00928\n",
            "[ Epoch 2827/10000 ] Train Loss: 1.07648   Valid Loss: 1.00950\n",
            "[ Epoch 2828/10000 ] Train Loss: 1.07520   Valid Loss: 1.01013\n",
            "[ Epoch 2829/10000 ] Train Loss: 1.07448   Valid Loss: 1.00853\n",
            "Early Stop Saving Model on Epoch 2829/10000\n",
            "[ Epoch 2830/10000 ] Train Loss: 1.07548   Valid Loss: 1.00922\n",
            "[ Epoch 2831/10000 ] Train Loss: 1.07939   Valid Loss: 1.01777\n",
            "[ Epoch 2832/10000 ] Train Loss: 1.08005   Valid Loss: 1.01052\n",
            "[ Epoch 2833/10000 ] Train Loss: 1.07687   Valid Loss: 1.01057\n",
            "[ Epoch 2834/10000 ] Train Loss: 1.07807   Valid Loss: 1.00899\n",
            "[ Epoch 2835/10000 ] Train Loss: 1.07557   Valid Loss: 1.00920\n",
            "[ Epoch 2836/10000 ] Train Loss: 1.07727   Valid Loss: 1.01000\n",
            "[ Epoch 2837/10000 ] Train Loss: 1.07657   Valid Loss: 1.00880\n",
            "[ Epoch 2838/10000 ] Train Loss: 1.08086   Valid Loss: 1.01829\n",
            "[ Epoch 2839/10000 ] Train Loss: 1.07631   Valid Loss: 1.01032\n",
            "[ Epoch 2840/10000 ] Train Loss: 1.07392   Valid Loss: 1.00845\n",
            "Early Stop Saving Model on Epoch 2840/10000\n",
            "[ Epoch 2841/10000 ] Train Loss: 1.07601   Valid Loss: 1.00999\n",
            "[ Epoch 2842/10000 ] Train Loss: 1.07605   Valid Loss: 1.00920\n",
            "[ Epoch 2843/10000 ] Train Loss: 1.07661   Valid Loss: 1.01248\n",
            "[ Epoch 2844/10000 ] Train Loss: 1.07476   Valid Loss: 1.01516\n",
            "[ Epoch 2845/10000 ] Train Loss: 1.07867   Valid Loss: 1.01562\n",
            "[ Epoch 2846/10000 ] Train Loss: 1.07995   Valid Loss: 1.00907\n",
            "[ Epoch 2847/10000 ] Train Loss: 1.07604   Valid Loss: 1.01078\n",
            "[ Epoch 2848/10000 ] Train Loss: 1.07903   Valid Loss: 1.01278\n",
            "[ Epoch 2849/10000 ] Train Loss: 1.07877   Valid Loss: 1.01013\n",
            "[ Epoch 2850/10000 ] Train Loss: 1.07401   Valid Loss: 1.01007\n",
            "[ Epoch 2851/10000 ] Train Loss: 1.07654   Valid Loss: 1.00927\n",
            "[ Epoch 2852/10000 ] Train Loss: 1.07380   Valid Loss: 1.00923\n",
            "[ Epoch 2853/10000 ] Train Loss: 1.07579   Valid Loss: 1.01134\n",
            "[ Epoch 2854/10000 ] Train Loss: 1.07594   Valid Loss: 1.00895\n",
            "[ Epoch 2855/10000 ] Train Loss: 1.07683   Valid Loss: 1.01340\n",
            "[ Epoch 2856/10000 ] Train Loss: 1.07499   Valid Loss: 1.00927\n",
            "[ Epoch 2857/10000 ] Train Loss: 1.07615   Valid Loss: 1.00982\n",
            "[ Epoch 2858/10000 ] Train Loss: 1.07917   Valid Loss: 1.01188\n",
            "[ Epoch 2859/10000 ] Train Loss: 1.07781   Valid Loss: 1.00870\n",
            "[ Epoch 2860/10000 ] Train Loss: 1.07663   Valid Loss: 1.01153\n",
            "[ Epoch 2861/10000 ] Train Loss: 1.07734   Valid Loss: 1.01192\n",
            "[ Epoch 2862/10000 ] Train Loss: 1.07566   Valid Loss: 1.00930\n",
            "[ Epoch 2863/10000 ] Train Loss: 1.07695   Valid Loss: 1.00865\n",
            "[ Epoch 2864/10000 ] Train Loss: 1.07614   Valid Loss: 1.00939\n",
            "[ Epoch 2865/10000 ] Train Loss: 1.07452   Valid Loss: 1.00898\n",
            "[ Epoch 2866/10000 ] Train Loss: 1.07350   Valid Loss: 1.00946\n",
            "[ Epoch 2867/10000 ] Train Loss: 1.07327   Valid Loss: 1.00902\n",
            "[ Epoch 2868/10000 ] Train Loss: 1.07481   Valid Loss: 1.00973\n",
            "[ Epoch 2869/10000 ] Train Loss: 1.07461   Valid Loss: 1.00959\n",
            "[ Epoch 2870/10000 ] Train Loss: 1.07535   Valid Loss: 1.01000\n",
            "[ Epoch 2871/10000 ] Train Loss: 1.07505   Valid Loss: 1.00934\n",
            "[ Epoch 2872/10000 ] Train Loss: 1.07330   Valid Loss: 1.00883\n",
            "[ Epoch 2873/10000 ] Train Loss: 1.07335   Valid Loss: 1.00845\n",
            "[ Epoch 2874/10000 ] Train Loss: 1.07422   Valid Loss: 1.00989\n",
            "[ Epoch 2875/10000 ] Train Loss: 1.07505   Valid Loss: 1.01212\n",
            "[ Epoch 2876/10000 ] Train Loss: 1.07629   Valid Loss: 1.00784\n",
            "Early Stop Saving Model on Epoch 2876/10000\n",
            "[ Epoch 2877/10000 ] Train Loss: 1.07471   Valid Loss: 1.00897\n",
            "[ Epoch 2878/10000 ] Train Loss: 1.07717   Valid Loss: 1.01108\n",
            "[ Epoch 2879/10000 ] Train Loss: 1.07683   Valid Loss: 1.00770\n",
            "Early Stop Saving Model on Epoch 2879/10000\n",
            "[ Epoch 2880/10000 ] Train Loss: 1.07808   Valid Loss: 1.01455\n",
            "[ Epoch 2881/10000 ] Train Loss: 1.07939   Valid Loss: 1.00849\n",
            "[ Epoch 2882/10000 ] Train Loss: 1.07682   Valid Loss: 1.00891\n",
            "[ Epoch 2883/10000 ] Train Loss: 1.07621   Valid Loss: 1.01076\n",
            "[ Epoch 2884/10000 ] Train Loss: 1.07372   Valid Loss: 1.00869\n",
            "[ Epoch 2885/10000 ] Train Loss: 1.07498   Valid Loss: 1.00918\n",
            "[ Epoch 2886/10000 ] Train Loss: 1.07502   Valid Loss: 1.01208\n",
            "[ Epoch 2887/10000 ] Train Loss: 1.07746   Valid Loss: 1.00811\n",
            "[ Epoch 2888/10000 ] Train Loss: 1.07430   Valid Loss: 1.00786\n",
            "[ Epoch 2889/10000 ] Train Loss: 1.07268   Valid Loss: 1.00972\n",
            "[ Epoch 2890/10000 ] Train Loss: 1.07399   Valid Loss: 1.00793\n",
            "[ Epoch 2891/10000 ] Train Loss: 1.07271   Valid Loss: 1.01248\n",
            "[ Epoch 2892/10000 ] Train Loss: 1.07789   Valid Loss: 1.01333\n",
            "[ Epoch 2893/10000 ] Train Loss: 1.07529   Valid Loss: 1.00810\n",
            "[ Epoch 2894/10000 ] Train Loss: 1.07461   Valid Loss: 1.00946\n",
            "[ Epoch 2895/10000 ] Train Loss: 1.07650   Valid Loss: 1.00783\n",
            "[ Epoch 2896/10000 ] Train Loss: 1.07474   Valid Loss: 1.00811\n",
            "[ Epoch 2897/10000 ] Train Loss: 1.07455   Valid Loss: 1.00800\n",
            "[ Epoch 2898/10000 ] Train Loss: 1.07464   Valid Loss: 1.00780\n",
            "[ Epoch 2899/10000 ] Train Loss: 1.07429   Valid Loss: 1.00848\n",
            "[ Epoch 2900/10000 ] Train Loss: 1.07463   Valid Loss: 1.00923\n",
            "[ Epoch 2901/10000 ] Train Loss: 1.07485   Valid Loss: 1.00710\n",
            "Early Stop Saving Model on Epoch 2901/10000\n",
            "[ Epoch 2902/10000 ] Train Loss: 1.07507   Valid Loss: 1.00937\n",
            "[ Epoch 2903/10000 ] Train Loss: 1.07347   Valid Loss: 1.00790\n",
            "[ Epoch 2904/10000 ] Train Loss: 1.07494   Valid Loss: 1.00981\n",
            "[ Epoch 2905/10000 ] Train Loss: 1.07506   Valid Loss: 1.01027\n",
            "[ Epoch 2906/10000 ] Train Loss: 1.07507   Valid Loss: 1.00704\n",
            "Early Stop Saving Model on Epoch 2906/10000\n",
            "[ Epoch 2907/10000 ] Train Loss: 1.07358   Valid Loss: 1.00907\n",
            "[ Epoch 2908/10000 ] Train Loss: 1.07491   Valid Loss: 1.00732\n",
            "[ Epoch 2909/10000 ] Train Loss: 1.07372   Valid Loss: 1.00829\n",
            "[ Epoch 2910/10000 ] Train Loss: 1.07459   Valid Loss: 1.00784\n",
            "[ Epoch 2911/10000 ] Train Loss: 1.07452   Valid Loss: 1.00920\n",
            "[ Epoch 2912/10000 ] Train Loss: 1.07522   Valid Loss: 1.00734\n",
            "[ Epoch 2913/10000 ] Train Loss: 1.07552   Valid Loss: 1.00875\n",
            "[ Epoch 2914/10000 ] Train Loss: 1.07378   Valid Loss: 1.00937\n",
            "[ Epoch 2915/10000 ] Train Loss: 1.07449   Valid Loss: 1.00792\n",
            "[ Epoch 2916/10000 ] Train Loss: 1.07543   Valid Loss: 1.00731\n",
            "[ Epoch 2917/10000 ] Train Loss: 1.07514   Valid Loss: 1.00907\n",
            "[ Epoch 2918/10000 ] Train Loss: 1.07511   Valid Loss: 1.00857\n",
            "[ Epoch 2919/10000 ] Train Loss: 1.07448   Valid Loss: 1.01102\n",
            "[ Epoch 2920/10000 ] Train Loss: 1.07500   Valid Loss: 1.00636\n",
            "Early Stop Saving Model on Epoch 2920/10000\n",
            "[ Epoch 2921/10000 ] Train Loss: 1.07333   Valid Loss: 1.00824\n",
            "[ Epoch 2922/10000 ] Train Loss: 1.07266   Valid Loss: 1.00744\n",
            "[ Epoch 2923/10000 ] Train Loss: 1.07400   Valid Loss: 1.01030\n",
            "[ Epoch 2924/10000 ] Train Loss: 1.07596   Valid Loss: 1.00908\n",
            "[ Epoch 2925/10000 ] Train Loss: 1.07447   Valid Loss: 1.00661\n",
            "[ Epoch 2926/10000 ] Train Loss: 1.07337   Valid Loss: 1.00816\n",
            "[ Epoch 2927/10000 ] Train Loss: 1.07198   Valid Loss: 1.00825\n",
            "[ Epoch 2928/10000 ] Train Loss: 1.07322   Valid Loss: 1.00707\n",
            "[ Epoch 2929/10000 ] Train Loss: 1.07349   Valid Loss: 1.00902\n",
            "[ Epoch 2930/10000 ] Train Loss: 1.07394   Valid Loss: 1.00662\n",
            "[ Epoch 2931/10000 ] Train Loss: 1.07516   Valid Loss: 1.00898\n",
            "[ Epoch 2932/10000 ] Train Loss: 1.07411   Valid Loss: 1.00736\n",
            "[ Epoch 2933/10000 ] Train Loss: 1.07414   Valid Loss: 1.00703\n",
            "[ Epoch 2934/10000 ] Train Loss: 1.07369   Valid Loss: 1.00735\n",
            "[ Epoch 2935/10000 ] Train Loss: 1.07509   Valid Loss: 1.01029\n",
            "[ Epoch 2936/10000 ] Train Loss: 1.07401   Valid Loss: 1.00728\n",
            "[ Epoch 2937/10000 ] Train Loss: 1.07317   Valid Loss: 1.00714\n",
            "[ Epoch 2938/10000 ] Train Loss: 1.07455   Valid Loss: 1.00879\n",
            "[ Epoch 2939/10000 ] Train Loss: 1.07267   Valid Loss: 1.00835\n",
            "[ Epoch 2940/10000 ] Train Loss: 1.07311   Valid Loss: 1.01022\n",
            "[ Epoch 2941/10000 ] Train Loss: 1.07404   Valid Loss: 1.00939\n",
            "[ Epoch 2942/10000 ] Train Loss: 1.07347   Valid Loss: 1.00682\n",
            "[ Epoch 2943/10000 ] Train Loss: 1.07313   Valid Loss: 1.00637\n",
            "[ Epoch 2944/10000 ] Train Loss: 1.07280   Valid Loss: 1.00578\n",
            "Early Stop Saving Model on Epoch 2944/10000\n",
            "[ Epoch 2945/10000 ] Train Loss: 1.07307   Valid Loss: 1.00670\n",
            "[ Epoch 2946/10000 ] Train Loss: 1.07385   Valid Loss: 1.00928\n",
            "[ Epoch 2947/10000 ] Train Loss: 1.07448   Valid Loss: 1.00767\n",
            "[ Epoch 2948/10000 ] Train Loss: 1.07485   Valid Loss: 1.00672\n",
            "[ Epoch 2949/10000 ] Train Loss: 1.07394   Valid Loss: 1.00787\n",
            "[ Epoch 2950/10000 ] Train Loss: 1.07404   Valid Loss: 1.00634\n",
            "[ Epoch 2951/10000 ] Train Loss: 1.07351   Valid Loss: 1.00856\n",
            "[ Epoch 2952/10000 ] Train Loss: 1.07154   Valid Loss: 1.00664\n",
            "[ Epoch 2953/10000 ] Train Loss: 1.07459   Valid Loss: 1.00729\n",
            "[ Epoch 2954/10000 ] Train Loss: 1.07198   Valid Loss: 1.00624\n",
            "[ Epoch 2955/10000 ] Train Loss: 1.07560   Valid Loss: 1.00739\n",
            "[ Epoch 2956/10000 ] Train Loss: 1.07351   Valid Loss: 1.00606\n",
            "[ Epoch 2957/10000 ] Train Loss: 1.07287   Valid Loss: 1.00689\n",
            "[ Epoch 2958/10000 ] Train Loss: 1.07139   Valid Loss: 1.00700\n",
            "[ Epoch 2959/10000 ] Train Loss: 1.07202   Valid Loss: 1.00696\n",
            "[ Epoch 2960/10000 ] Train Loss: 1.07373   Valid Loss: 1.00518\n",
            "Early Stop Saving Model on Epoch 2960/10000\n",
            "[ Epoch 2961/10000 ] Train Loss: 1.07277   Valid Loss: 1.00878\n",
            "[ Epoch 2962/10000 ] Train Loss: 1.07571   Valid Loss: 1.00726\n",
            "[ Epoch 2963/10000 ] Train Loss: 1.07268   Valid Loss: 1.00677\n",
            "[ Epoch 2964/10000 ] Train Loss: 1.07306   Valid Loss: 1.00662\n",
            "[ Epoch 2965/10000 ] Train Loss: 1.07149   Valid Loss: 1.00699\n",
            "[ Epoch 2966/10000 ] Train Loss: 1.07241   Valid Loss: 1.00639\n",
            "[ Epoch 2967/10000 ] Train Loss: 1.07209   Valid Loss: 1.00715\n",
            "[ Epoch 2968/10000 ] Train Loss: 1.07209   Valid Loss: 1.00609\n",
            "[ Epoch 2969/10000 ] Train Loss: 1.07161   Valid Loss: 1.00564\n",
            "[ Epoch 2970/10000 ] Train Loss: 1.07276   Valid Loss: 1.00883\n",
            "[ Epoch 2971/10000 ] Train Loss: 1.07376   Valid Loss: 1.00941\n",
            "[ Epoch 2972/10000 ] Train Loss: 1.07649   Valid Loss: 1.01326\n",
            "[ Epoch 2973/10000 ] Train Loss: 1.07257   Valid Loss: 1.01240\n",
            "[ Epoch 2974/10000 ] Train Loss: 1.07347   Valid Loss: 1.00736\n",
            "[ Epoch 2975/10000 ] Train Loss: 1.07232   Valid Loss: 1.00996\n",
            "[ Epoch 2976/10000 ] Train Loss: 1.07413   Valid Loss: 1.00833\n",
            "[ Epoch 2977/10000 ] Train Loss: 1.07272   Valid Loss: 1.01137\n",
            "[ Epoch 2978/10000 ] Train Loss: 1.07586   Valid Loss: 1.00584\n",
            "[ Epoch 2979/10000 ] Train Loss: 1.07439   Valid Loss: 1.00840\n",
            "[ Epoch 2980/10000 ] Train Loss: 1.07389   Valid Loss: 1.01122\n",
            "[ Epoch 2981/10000 ] Train Loss: 1.07320   Valid Loss: 1.00677\n",
            "[ Epoch 2982/10000 ] Train Loss: 1.07341   Valid Loss: 1.00656\n",
            "[ Epoch 2983/10000 ] Train Loss: 1.07492   Valid Loss: 1.00901\n",
            "[ Epoch 2984/10000 ] Train Loss: 1.07435   Valid Loss: 1.00521\n",
            "[ Epoch 2985/10000 ] Train Loss: 1.07436   Valid Loss: 1.00802\n",
            "[ Epoch 2986/10000 ] Train Loss: 1.07347   Valid Loss: 1.00795\n",
            "[ Epoch 2987/10000 ] Train Loss: 1.07105   Valid Loss: 1.00672\n",
            "[ Epoch 2988/10000 ] Train Loss: 1.07396   Valid Loss: 1.00768\n",
            "[ Epoch 2989/10000 ] Train Loss: 1.07461   Valid Loss: 1.00788\n",
            "[ Epoch 2990/10000 ] Train Loss: 1.07196   Valid Loss: 1.00663\n",
            "[ Epoch 2991/10000 ] Train Loss: 1.07172   Valid Loss: 1.00633\n",
            "[ Epoch 2992/10000 ] Train Loss: 1.07226   Valid Loss: 1.00611\n",
            "[ Epoch 2993/10000 ] Train Loss: 1.07186   Valid Loss: 1.00616\n",
            "[ Epoch 2994/10000 ] Train Loss: 1.07260   Valid Loss: 1.00740\n",
            "[ Epoch 2995/10000 ] Train Loss: 1.07185   Valid Loss: 1.00599\n",
            "[ Epoch 2996/10000 ] Train Loss: 1.07110   Valid Loss: 1.00698\n",
            "[ Epoch 2997/10000 ] Train Loss: 1.07109   Valid Loss: 1.00654\n",
            "[ Epoch 2998/10000 ] Train Loss: 1.07330   Valid Loss: 1.00600\n",
            "[ Epoch 2999/10000 ] Train Loss: 1.07105   Valid Loss: 1.00804\n",
            "[ Epoch 3000/10000 ] Train Loss: 1.07394   Valid Loss: 1.00785\n",
            "[ Epoch 3001/10000 ] Train Loss: 1.07441   Valid Loss: 1.00557\n",
            "[ Epoch 3002/10000 ] Train Loss: 1.07251   Valid Loss: 1.00865\n",
            "[ Epoch 3003/10000 ] Train Loss: 1.07173   Valid Loss: 1.00697\n",
            "[ Epoch 3004/10000 ] Train Loss: 1.07197   Valid Loss: 1.00566\n",
            "[ Epoch 3005/10000 ] Train Loss: 1.07285   Valid Loss: 1.00704\n",
            "[ Epoch 3006/10000 ] Train Loss: 1.07288   Valid Loss: 1.01289\n",
            "[ Epoch 3007/10000 ] Train Loss: 1.07932   Valid Loss: 1.01398\n",
            "[ Epoch 3008/10000 ] Train Loss: 1.07151   Valid Loss: 1.00946\n",
            "[ Epoch 3009/10000 ] Train Loss: 1.07408   Valid Loss: 1.00593\n",
            "[ Epoch 3010/10000 ] Train Loss: 1.07243   Valid Loss: 1.00658\n",
            "[ Epoch 3011/10000 ] Train Loss: 1.07217   Valid Loss: 1.00623\n",
            "[ Epoch 3012/10000 ] Train Loss: 1.06896   Valid Loss: 1.00509\n",
            "Early Stop Saving Model on Epoch 3012/10000\n",
            "[ Epoch 3013/10000 ] Train Loss: 1.07149   Valid Loss: 1.00723\n",
            "[ Epoch 3014/10000 ] Train Loss: 1.07383   Valid Loss: 1.01287\n",
            "[ Epoch 3015/10000 ] Train Loss: 1.07571   Valid Loss: 1.00462\n",
            "Early Stop Saving Model on Epoch 3015/10000\n",
            "[ Epoch 3016/10000 ] Train Loss: 1.07252   Valid Loss: 1.00669\n",
            "[ Epoch 3017/10000 ] Train Loss: 1.06974   Valid Loss: 1.00672\n",
            "[ Epoch 3018/10000 ] Train Loss: 1.07252   Valid Loss: 1.01010\n",
            "[ Epoch 3019/10000 ] Train Loss: 1.07202   Valid Loss: 1.00676\n",
            "[ Epoch 3020/10000 ] Train Loss: 1.07098   Valid Loss: 1.00667\n",
            "[ Epoch 3021/10000 ] Train Loss: 1.07237   Valid Loss: 1.00463\n",
            "[ Epoch 3022/10000 ] Train Loss: 1.07084   Valid Loss: 1.00631\n",
            "[ Epoch 3023/10000 ] Train Loss: 1.07209   Valid Loss: 1.00541\n",
            "[ Epoch 3024/10000 ] Train Loss: 1.07186   Valid Loss: 1.00559\n",
            "[ Epoch 3025/10000 ] Train Loss: 1.07216   Valid Loss: 1.00709\n",
            "[ Epoch 3026/10000 ] Train Loss: 1.07266   Valid Loss: 1.00468\n",
            "[ Epoch 3027/10000 ] Train Loss: 1.07084   Valid Loss: 1.00585\n",
            "[ Epoch 3028/10000 ] Train Loss: 1.07149   Valid Loss: 1.00523\n",
            "[ Epoch 3029/10000 ] Train Loss: 1.07110   Valid Loss: 1.00544\n",
            "[ Epoch 3030/10000 ] Train Loss: 1.07209   Valid Loss: 1.00525\n",
            "[ Epoch 3031/10000 ] Train Loss: 1.07121   Valid Loss: 1.00612\n",
            "[ Epoch 3032/10000 ] Train Loss: 1.07037   Valid Loss: 1.00576\n",
            "[ Epoch 3033/10000 ] Train Loss: 1.07179   Valid Loss: 1.00421\n",
            "Early Stop Saving Model on Epoch 3033/10000\n",
            "[ Epoch 3034/10000 ] Train Loss: 1.07126   Valid Loss: 1.00477\n",
            "[ Epoch 3035/10000 ] Train Loss: 1.07240   Valid Loss: 1.00756\n",
            "[ Epoch 3036/10000 ] Train Loss: 1.07158   Valid Loss: 1.00601\n",
            "[ Epoch 3037/10000 ] Train Loss: 1.07274   Valid Loss: 1.00429\n",
            "[ Epoch 3038/10000 ] Train Loss: 1.07411   Valid Loss: 1.00568\n",
            "[ Epoch 3039/10000 ] Train Loss: 1.06954   Valid Loss: 1.00392\n",
            "Early Stop Saving Model on Epoch 3039/10000\n",
            "[ Epoch 3040/10000 ] Train Loss: 1.07060   Valid Loss: 1.00450\n",
            "[ Epoch 3041/10000 ] Train Loss: 1.07001   Valid Loss: 1.00645\n",
            "[ Epoch 3042/10000 ] Train Loss: 1.06929   Valid Loss: 1.00464\n",
            "[ Epoch 3043/10000 ] Train Loss: 1.07061   Valid Loss: 1.00647\n",
            "[ Epoch 3044/10000 ] Train Loss: 1.07121   Valid Loss: 1.00454\n",
            "[ Epoch 3045/10000 ] Train Loss: 1.07456   Valid Loss: 1.00934\n",
            "[ Epoch 3046/10000 ] Train Loss: 1.07370   Valid Loss: 1.00886\n",
            "[ Epoch 3047/10000 ] Train Loss: 1.07365   Valid Loss: 1.00393\n",
            "[ Epoch 3048/10000 ] Train Loss: 1.07147   Valid Loss: 1.00479\n",
            "[ Epoch 3049/10000 ] Train Loss: 1.07095   Valid Loss: 1.00444\n",
            "[ Epoch 3050/10000 ] Train Loss: 1.07232   Valid Loss: 1.00592\n",
            "[ Epoch 3051/10000 ] Train Loss: 1.07148   Valid Loss: 1.00681\n",
            "[ Epoch 3052/10000 ] Train Loss: 1.06954   Valid Loss: 1.00397\n",
            "[ Epoch 3053/10000 ] Train Loss: 1.07109   Valid Loss: 1.00380\n",
            "Early Stop Saving Model on Epoch 3053/10000\n",
            "[ Epoch 3054/10000 ] Train Loss: 1.07032   Valid Loss: 1.00453\n",
            "[ Epoch 3055/10000 ] Train Loss: 1.07019   Valid Loss: 1.00536\n",
            "[ Epoch 3056/10000 ] Train Loss: 1.07029   Valid Loss: 1.00573\n",
            "[ Epoch 3057/10000 ] Train Loss: 1.07235   Valid Loss: 1.00804\n",
            "[ Epoch 3058/10000 ] Train Loss: 1.07462   Valid Loss: 1.00589\n",
            "[ Epoch 3059/10000 ] Train Loss: 1.07264   Valid Loss: 1.00559\n",
            "[ Epoch 3060/10000 ] Train Loss: 1.07050   Valid Loss: 1.00706\n",
            "[ Epoch 3061/10000 ] Train Loss: 1.07331   Valid Loss: 1.01218\n",
            "[ Epoch 3062/10000 ] Train Loss: 1.07536   Valid Loss: 1.00432\n",
            "[ Epoch 3063/10000 ] Train Loss: 1.07201   Valid Loss: 1.00564\n",
            "[ Epoch 3064/10000 ] Train Loss: 1.07343   Valid Loss: 1.00653\n",
            "[ Epoch 3065/10000 ] Train Loss: 1.07220   Valid Loss: 1.00426\n",
            "[ Epoch 3066/10000 ] Train Loss: 1.07160   Valid Loss: 1.00585\n",
            "[ Epoch 3067/10000 ] Train Loss: 1.07067   Valid Loss: 1.00383\n",
            "[ Epoch 3068/10000 ] Train Loss: 1.06897   Valid Loss: 1.00581\n",
            "[ Epoch 3069/10000 ] Train Loss: 1.07122   Valid Loss: 1.00679\n",
            "[ Epoch 3070/10000 ] Train Loss: 1.07246   Valid Loss: 1.00436\n",
            "[ Epoch 3071/10000 ] Train Loss: 1.07184   Valid Loss: 1.00553\n",
            "[ Epoch 3072/10000 ] Train Loss: 1.07004   Valid Loss: 1.00456\n",
            "[ Epoch 3073/10000 ] Train Loss: 1.07024   Valid Loss: 1.00554\n",
            "[ Epoch 3074/10000 ] Train Loss: 1.07018   Valid Loss: 1.00537\n",
            "[ Epoch 3075/10000 ] Train Loss: 1.07092   Valid Loss: 1.00504\n",
            "[ Epoch 3076/10000 ] Train Loss: 1.06949   Valid Loss: 1.00490\n",
            "[ Epoch 3077/10000 ] Train Loss: 1.07069   Valid Loss: 1.00424\n",
            "[ Epoch 3078/10000 ] Train Loss: 1.07134   Valid Loss: 1.00649\n",
            "[ Epoch 3079/10000 ] Train Loss: 1.07300   Valid Loss: 1.00521\n",
            "[ Epoch 3080/10000 ] Train Loss: 1.07190   Valid Loss: 1.00523\n",
            "[ Epoch 3081/10000 ] Train Loss: 1.07171   Valid Loss: 1.00407\n",
            "[ Epoch 3082/10000 ] Train Loss: 1.06999   Valid Loss: 1.00494\n",
            "[ Epoch 3083/10000 ] Train Loss: 1.07090   Valid Loss: 1.00386\n",
            "[ Epoch 3084/10000 ] Train Loss: 1.07080   Valid Loss: 1.00360\n",
            "Early Stop Saving Model on Epoch 3084/10000\n",
            "[ Epoch 3085/10000 ] Train Loss: 1.06865   Valid Loss: 1.00341\n",
            "Early Stop Saving Model on Epoch 3085/10000\n",
            "[ Epoch 3086/10000 ] Train Loss: 1.07062   Valid Loss: 1.00360\n",
            "[ Epoch 3087/10000 ] Train Loss: 1.07201   Valid Loss: 1.00930\n",
            "[ Epoch 3088/10000 ] Train Loss: 1.07685   Valid Loss: 1.01232\n",
            "[ Epoch 3089/10000 ] Train Loss: 1.07194   Valid Loss: 1.00545\n",
            "[ Epoch 3090/10000 ] Train Loss: 1.07163   Valid Loss: 1.00343\n",
            "[ Epoch 3091/10000 ] Train Loss: 1.06899   Valid Loss: 1.00496\n",
            "[ Epoch 3092/10000 ] Train Loss: 1.06807   Valid Loss: 1.00333\n",
            "Early Stop Saving Model on Epoch 3092/10000\n",
            "[ Epoch 3093/10000 ] Train Loss: 1.07103   Valid Loss: 1.00349\n",
            "[ Epoch 3094/10000 ] Train Loss: 1.07001   Valid Loss: 1.00468\n",
            "[ Epoch 3095/10000 ] Train Loss: 1.06909   Valid Loss: 1.00292\n",
            "Early Stop Saving Model on Epoch 3095/10000\n",
            "[ Epoch 3096/10000 ] Train Loss: 1.06892   Valid Loss: 1.00379\n",
            "[ Epoch 3097/10000 ] Train Loss: 1.07098   Valid Loss: 1.00683\n",
            "[ Epoch 3098/10000 ] Train Loss: 1.07225   Valid Loss: 1.00276\n",
            "Early Stop Saving Model on Epoch 3098/10000\n",
            "[ Epoch 3099/10000 ] Train Loss: 1.06990   Valid Loss: 1.00374\n",
            "[ Epoch 3100/10000 ] Train Loss: 1.06953   Valid Loss: 1.00294\n",
            "[ Epoch 3101/10000 ] Train Loss: 1.07046   Valid Loss: 1.00344\n",
            "[ Epoch 3102/10000 ] Train Loss: 1.06929   Valid Loss: 1.00354\n",
            "[ Epoch 3103/10000 ] Train Loss: 1.07007   Valid Loss: 1.00415\n",
            "[ Epoch 3104/10000 ] Train Loss: 1.06914   Valid Loss: 1.00244\n",
            "Early Stop Saving Model on Epoch 3104/10000\n",
            "[ Epoch 3105/10000 ] Train Loss: 1.07232   Valid Loss: 1.00311\n",
            "[ Epoch 3106/10000 ] Train Loss: 1.07134   Valid Loss: 1.00435\n",
            "[ Epoch 3107/10000 ] Train Loss: 1.06796   Valid Loss: 1.00649\n",
            "[ Epoch 3108/10000 ] Train Loss: 1.06972   Valid Loss: 1.00403\n",
            "[ Epoch 3109/10000 ] Train Loss: 1.07034   Valid Loss: 1.00223\n",
            "Early Stop Saving Model on Epoch 3109/10000\n",
            "[ Epoch 3110/10000 ] Train Loss: 1.07014   Valid Loss: 1.00641\n",
            "[ Epoch 3111/10000 ] Train Loss: 1.06995   Valid Loss: 1.00318\n",
            "[ Epoch 3112/10000 ] Train Loss: 1.06671   Valid Loss: 1.00393\n",
            "[ Epoch 3113/10000 ] Train Loss: 1.06936   Valid Loss: 1.00381\n",
            "[ Epoch 3114/10000 ] Train Loss: 1.06952   Valid Loss: 1.00233\n",
            "[ Epoch 3115/10000 ] Train Loss: 1.07000   Valid Loss: 1.00343\n",
            "[ Epoch 3116/10000 ] Train Loss: 1.07149   Valid Loss: 1.00848\n",
            "[ Epoch 3117/10000 ] Train Loss: 1.07066   Valid Loss: 1.00389\n",
            "[ Epoch 3118/10000 ] Train Loss: 1.07031   Valid Loss: 1.00262\n",
            "[ Epoch 3119/10000 ] Train Loss: 1.07001   Valid Loss: 1.00291\n",
            "[ Epoch 3120/10000 ] Train Loss: 1.06984   Valid Loss: 1.00553\n",
            "[ Epoch 3121/10000 ] Train Loss: 1.07029   Valid Loss: 1.00252\n",
            "[ Epoch 3122/10000 ] Train Loss: 1.07010   Valid Loss: 1.00171\n",
            "Early Stop Saving Model on Epoch 3122/10000\n",
            "[ Epoch 3123/10000 ] Train Loss: 1.06822   Valid Loss: 1.00282\n",
            "[ Epoch 3124/10000 ] Train Loss: 1.06877   Valid Loss: 1.00354\n",
            "[ Epoch 3125/10000 ] Train Loss: 1.06911   Valid Loss: 1.00211\n",
            "[ Epoch 3126/10000 ] Train Loss: 1.06891   Valid Loss: 1.00384\n",
            "[ Epoch 3127/10000 ] Train Loss: 1.07056   Valid Loss: 1.00384\n",
            "[ Epoch 3128/10000 ] Train Loss: 1.07081   Valid Loss: 1.00497\n",
            "[ Epoch 3129/10000 ] Train Loss: 1.07299   Valid Loss: 1.00348\n",
            "[ Epoch 3130/10000 ] Train Loss: 1.07471   Valid Loss: 1.01068\n",
            "[ Epoch 3131/10000 ] Train Loss: 1.07194   Valid Loss: 1.00529\n",
            "[ Epoch 3132/10000 ] Train Loss: 1.06909   Valid Loss: 1.00360\n",
            "[ Epoch 3133/10000 ] Train Loss: 1.06908   Valid Loss: 1.00256\n",
            "[ Epoch 3134/10000 ] Train Loss: 1.06826   Valid Loss: 1.00362\n",
            "[ Epoch 3135/10000 ] Train Loss: 1.07049   Valid Loss: 1.00654\n",
            "[ Epoch 3136/10000 ] Train Loss: 1.07062   Valid Loss: 1.00198\n",
            "[ Epoch 3137/10000 ] Train Loss: 1.06857   Valid Loss: 1.00258\n",
            "[ Epoch 3138/10000 ] Train Loss: 1.06800   Valid Loss: 1.00471\n",
            "[ Epoch 3139/10000 ] Train Loss: 1.06947   Valid Loss: 1.00402\n",
            "[ Epoch 3140/10000 ] Train Loss: 1.07059   Valid Loss: 1.00251\n",
            "[ Epoch 3141/10000 ] Train Loss: 1.06860   Valid Loss: 1.00320\n",
            "[ Epoch 3142/10000 ] Train Loss: 1.06934   Valid Loss: 1.00320\n",
            "[ Epoch 3143/10000 ] Train Loss: 1.06856   Valid Loss: 1.00246\n",
            "[ Epoch 3144/10000 ] Train Loss: 1.06925   Valid Loss: 1.00135\n",
            "Early Stop Saving Model on Epoch 3144/10000\n",
            "[ Epoch 3145/10000 ] Train Loss: 1.06693   Valid Loss: 1.00276\n",
            "[ Epoch 3146/10000 ] Train Loss: 1.06871   Valid Loss: 1.00297\n",
            "[ Epoch 3147/10000 ] Train Loss: 1.06888   Valid Loss: 1.00174\n",
            "[ Epoch 3148/10000 ] Train Loss: 1.06849   Valid Loss: 1.00202\n",
            "[ Epoch 3149/10000 ] Train Loss: 1.06680   Valid Loss: 1.00258\n",
            "[ Epoch 3150/10000 ] Train Loss: 1.06768   Valid Loss: 1.00188\n",
            "[ Epoch 3151/10000 ] Train Loss: 1.06787   Valid Loss: 1.00348\n",
            "[ Epoch 3152/10000 ] Train Loss: 1.06785   Valid Loss: 1.00194\n",
            "[ Epoch 3153/10000 ] Train Loss: 1.06700   Valid Loss: 1.00208\n",
            "[ Epoch 3154/10000 ] Train Loss: 1.06958   Valid Loss: 1.00286\n",
            "[ Epoch 3155/10000 ] Train Loss: 1.06858   Valid Loss: 1.00272\n",
            "[ Epoch 3156/10000 ] Train Loss: 1.06816   Valid Loss: 1.00263\n",
            "[ Epoch 3157/10000 ] Train Loss: 1.06887   Valid Loss: 1.00106\n",
            "Early Stop Saving Model on Epoch 3157/10000\n",
            "[ Epoch 3158/10000 ] Train Loss: 1.06867   Valid Loss: 1.00313\n",
            "[ Epoch 3159/10000 ] Train Loss: 1.06707   Valid Loss: 1.00401\n",
            "[ Epoch 3160/10000 ] Train Loss: 1.07108   Valid Loss: 1.00146\n",
            "[ Epoch 3161/10000 ] Train Loss: 1.06776   Valid Loss: 1.00231\n",
            "[ Epoch 3162/10000 ] Train Loss: 1.06961   Valid Loss: 1.00176\n",
            "[ Epoch 3163/10000 ] Train Loss: 1.06838   Valid Loss: 1.00237\n",
            "[ Epoch 3164/10000 ] Train Loss: 1.06840   Valid Loss: 1.00268\n",
            "[ Epoch 3165/10000 ] Train Loss: 1.07085   Valid Loss: 1.00323\n",
            "[ Epoch 3166/10000 ] Train Loss: 1.06896   Valid Loss: 1.00228\n",
            "[ Epoch 3167/10000 ] Train Loss: 1.06820   Valid Loss: 1.00328\n",
            "[ Epoch 3168/10000 ] Train Loss: 1.06850   Valid Loss: 1.00711\n",
            "[ Epoch 3169/10000 ] Train Loss: 1.07143   Valid Loss: 1.00841\n",
            "[ Epoch 3170/10000 ] Train Loss: 1.07160   Valid Loss: 1.00713\n",
            "[ Epoch 3171/10000 ] Train Loss: 1.06934   Valid Loss: 1.00347\n",
            "[ Epoch 3172/10000 ] Train Loss: 1.07121   Valid Loss: 1.00304\n",
            "[ Epoch 3173/10000 ] Train Loss: 1.07281   Valid Loss: 1.00901\n",
            "[ Epoch 3174/10000 ] Train Loss: 1.07091   Valid Loss: 1.00230\n",
            "[ Epoch 3175/10000 ] Train Loss: 1.06853   Valid Loss: 1.00037\n",
            "Early Stop Saving Model on Epoch 3175/10000\n",
            "[ Epoch 3176/10000 ] Train Loss: 1.06948   Valid Loss: 1.00369\n",
            "[ Epoch 3177/10000 ] Train Loss: 1.07174   Valid Loss: 1.00604\n",
            "[ Epoch 3178/10000 ] Train Loss: 1.06846   Valid Loss: 1.00206\n",
            "[ Epoch 3179/10000 ] Train Loss: 1.06839   Valid Loss: 1.00637\n",
            "[ Epoch 3180/10000 ] Train Loss: 1.06961   Valid Loss: 1.00128\n",
            "[ Epoch 3181/10000 ] Train Loss: 1.06774   Valid Loss: 1.00132\n",
            "[ Epoch 3182/10000 ] Train Loss: 1.06944   Valid Loss: 1.00546\n",
            "[ Epoch 3183/10000 ] Train Loss: 1.06877   Valid Loss: 1.00224\n",
            "[ Epoch 3184/10000 ] Train Loss: 1.06704   Valid Loss: 1.00127\n",
            "[ Epoch 3185/10000 ] Train Loss: 1.06767   Valid Loss: 1.00080\n",
            "[ Epoch 3186/10000 ] Train Loss: 1.06865   Valid Loss: 1.00085\n",
            "[ Epoch 3187/10000 ] Train Loss: 1.06958   Valid Loss: 1.00362\n",
            "[ Epoch 3188/10000 ] Train Loss: 1.06796   Valid Loss: 1.00189\n",
            "[ Epoch 3189/10000 ] Train Loss: 1.06912   Valid Loss: 1.00166\n",
            "[ Epoch 3190/10000 ] Train Loss: 1.06928   Valid Loss: 1.00434\n",
            "[ Epoch 3191/10000 ] Train Loss: 1.06854   Valid Loss: 1.00316\n",
            "[ Epoch 3192/10000 ] Train Loss: 1.06743   Valid Loss: 0.99991\n",
            "Early Stop Saving Model on Epoch 3192/10000\n",
            "[ Epoch 3193/10000 ] Train Loss: 1.06739   Valid Loss: 1.00139\n",
            "[ Epoch 3194/10000 ] Train Loss: 1.06783   Valid Loss: 1.00263\n",
            "[ Epoch 3195/10000 ] Train Loss: 1.06788   Valid Loss: 1.00382\n",
            "[ Epoch 3196/10000 ] Train Loss: 1.07163   Valid Loss: 1.00297\n",
            "[ Epoch 3197/10000 ] Train Loss: 1.06899   Valid Loss: 1.00095\n",
            "[ Epoch 3198/10000 ] Train Loss: 1.06899   Valid Loss: 1.00067\n",
            "[ Epoch 3199/10000 ] Train Loss: 1.06509   Valid Loss: 1.00312\n",
            "[ Epoch 3200/10000 ] Train Loss: 1.06843   Valid Loss: 1.00051\n",
            "[ Epoch 3201/10000 ] Train Loss: 1.06800   Valid Loss: 1.00092\n",
            "[ Epoch 3202/10000 ] Train Loss: 1.06881   Valid Loss: 1.00287\n",
            "[ Epoch 3203/10000 ] Train Loss: 1.06534   Valid Loss: 1.00256\n",
            "[ Epoch 3204/10000 ] Train Loss: 1.06677   Valid Loss: 1.00145\n",
            "[ Epoch 3205/10000 ] Train Loss: 1.06764   Valid Loss: 0.99999\n",
            "[ Epoch 3206/10000 ] Train Loss: 1.06627   Valid Loss: 1.00058\n",
            "[ Epoch 3207/10000 ] Train Loss: 1.06812   Valid Loss: 1.00239\n",
            "[ Epoch 3208/10000 ] Train Loss: 1.06723   Valid Loss: 0.99956\n",
            "Early Stop Saving Model on Epoch 3208/10000\n",
            "[ Epoch 3209/10000 ] Train Loss: 1.06715   Valid Loss: 1.00086\n",
            "[ Epoch 3210/10000 ] Train Loss: 1.06675   Valid Loss: 1.00066\n",
            "[ Epoch 3211/10000 ] Train Loss: 1.06789   Valid Loss: 1.00163\n",
            "[ Epoch 3212/10000 ] Train Loss: 1.06763   Valid Loss: 0.99966\n",
            "[ Epoch 3213/10000 ] Train Loss: 1.06773   Valid Loss: 1.00012\n",
            "[ Epoch 3214/10000 ] Train Loss: 1.06695   Valid Loss: 1.00033\n",
            "[ Epoch 3215/10000 ] Train Loss: 1.06636   Valid Loss: 1.00004\n",
            "[ Epoch 3216/10000 ] Train Loss: 1.06861   Valid Loss: 0.99930\n",
            "Early Stop Saving Model on Epoch 3216/10000\n",
            "[ Epoch 3217/10000 ] Train Loss: 1.06649   Valid Loss: 1.00104\n",
            "[ Epoch 3218/10000 ] Train Loss: 1.06601   Valid Loss: 1.00122\n",
            "[ Epoch 3219/10000 ] Train Loss: 1.06712   Valid Loss: 1.00280\n",
            "[ Epoch 3220/10000 ] Train Loss: 1.06814   Valid Loss: 1.00146\n",
            "[ Epoch 3221/10000 ] Train Loss: 1.06673   Valid Loss: 1.00182\n",
            "[ Epoch 3222/10000 ] Train Loss: 1.06719   Valid Loss: 0.99894\n",
            "Early Stop Saving Model on Epoch 3222/10000\n",
            "[ Epoch 3223/10000 ] Train Loss: 1.06677   Valid Loss: 0.99977\n",
            "[ Epoch 3224/10000 ] Train Loss: 1.06673   Valid Loss: 1.00027\n",
            "[ Epoch 3225/10000 ] Train Loss: 1.06872   Valid Loss: 1.00192\n",
            "[ Epoch 3226/10000 ] Train Loss: 1.06957   Valid Loss: 1.00198\n",
            "[ Epoch 3227/10000 ] Train Loss: 1.06646   Valid Loss: 1.00140\n",
            "[ Epoch 3228/10000 ] Train Loss: 1.06692   Valid Loss: 1.00167\n",
            "[ Epoch 3229/10000 ] Train Loss: 1.06689   Valid Loss: 0.99919\n",
            "[ Epoch 3230/10000 ] Train Loss: 1.06724   Valid Loss: 0.99954\n",
            "[ Epoch 3231/10000 ] Train Loss: 1.06885   Valid Loss: 1.00220\n",
            "[ Epoch 3232/10000 ] Train Loss: 1.06744   Valid Loss: 0.99899\n",
            "[ Epoch 3233/10000 ] Train Loss: 1.06472   Valid Loss: 0.99994\n",
            "[ Epoch 3234/10000 ] Train Loss: 1.06531   Valid Loss: 0.99898\n",
            "[ Epoch 3235/10000 ] Train Loss: 1.06671   Valid Loss: 1.00241\n",
            "[ Epoch 3236/10000 ] Train Loss: 1.06939   Valid Loss: 1.00115\n",
            "[ Epoch 3237/10000 ] Train Loss: 1.06544   Valid Loss: 1.00196\n",
            "[ Epoch 3238/10000 ] Train Loss: 1.06574   Valid Loss: 0.99834\n",
            "Early Stop Saving Model on Epoch 3238/10000\n",
            "[ Epoch 3239/10000 ] Train Loss: 1.06505   Valid Loss: 0.99922\n",
            "[ Epoch 3240/10000 ] Train Loss: 1.06608   Valid Loss: 1.00156\n",
            "[ Epoch 3241/10000 ] Train Loss: 1.06541   Valid Loss: 0.99971\n",
            "[ Epoch 3242/10000 ] Train Loss: 1.06491   Valid Loss: 0.99883\n",
            "[ Epoch 3243/10000 ] Train Loss: 1.06488   Valid Loss: 0.99941\n",
            "[ Epoch 3244/10000 ] Train Loss: 1.06424   Valid Loss: 0.99963\n",
            "[ Epoch 3245/10000 ] Train Loss: 1.06498   Valid Loss: 0.99956\n",
            "[ Epoch 3246/10000 ] Train Loss: 1.06694   Valid Loss: 0.99978\n",
            "[ Epoch 3247/10000 ] Train Loss: 1.06558   Valid Loss: 1.00040\n",
            "[ Epoch 3248/10000 ] Train Loss: 1.06425   Valid Loss: 1.00083\n",
            "[ Epoch 3249/10000 ] Train Loss: 1.06757   Valid Loss: 0.99838\n",
            "[ Epoch 3250/10000 ] Train Loss: 1.06622   Valid Loss: 1.00048\n",
            "[ Epoch 3251/10000 ] Train Loss: 1.06692   Valid Loss: 1.00182\n",
            "[ Epoch 3252/10000 ] Train Loss: 1.06663   Valid Loss: 1.00011\n",
            "[ Epoch 3253/10000 ] Train Loss: 1.06638   Valid Loss: 0.99940\n",
            "[ Epoch 3254/10000 ] Train Loss: 1.06683   Valid Loss: 1.00112\n",
            "[ Epoch 3255/10000 ] Train Loss: 1.06706   Valid Loss: 1.00020\n",
            "[ Epoch 3256/10000 ] Train Loss: 1.06785   Valid Loss: 0.99931\n",
            "[ Epoch 3257/10000 ] Train Loss: 1.06281   Valid Loss: 0.99895\n",
            "[ Epoch 3258/10000 ] Train Loss: 1.06569   Valid Loss: 1.00012\n",
            "[ Epoch 3259/10000 ] Train Loss: 1.06545   Valid Loss: 0.99868\n",
            "[ Epoch 3260/10000 ] Train Loss: 1.06683   Valid Loss: 1.00076\n",
            "[ Epoch 3261/10000 ] Train Loss: 1.06721   Valid Loss: 0.99952\n",
            "[ Epoch 3262/10000 ] Train Loss: 1.06726   Valid Loss: 0.99821\n",
            "Early Stop Saving Model on Epoch 3262/10000\n",
            "[ Epoch 3263/10000 ] Train Loss: 1.06780   Valid Loss: 1.00087\n",
            "[ Epoch 3264/10000 ] Train Loss: 1.06814   Valid Loss: 0.99924\n",
            "[ Epoch 3265/10000 ] Train Loss: 1.06840   Valid Loss: 1.00156\n",
            "[ Epoch 3266/10000 ] Train Loss: 1.06894   Valid Loss: 1.00244\n",
            "[ Epoch 3267/10000 ] Train Loss: 1.06423   Valid Loss: 1.00004\n",
            "[ Epoch 3268/10000 ] Train Loss: 1.06898   Valid Loss: 1.00184\n",
            "[ Epoch 3269/10000 ] Train Loss: 1.06617   Valid Loss: 1.00074\n",
            "[ Epoch 3270/10000 ] Train Loss: 1.06682   Valid Loss: 0.99793\n",
            "Early Stop Saving Model on Epoch 3270/10000\n",
            "[ Epoch 3271/10000 ] Train Loss: 1.06492   Valid Loss: 0.99983\n",
            "[ Epoch 3272/10000 ] Train Loss: 1.06313   Valid Loss: 0.99906\n",
            "[ Epoch 3273/10000 ] Train Loss: 1.06364   Valid Loss: 0.99882\n",
            "[ Epoch 3274/10000 ] Train Loss: 1.06613   Valid Loss: 0.99920\n",
            "[ Epoch 3275/10000 ] Train Loss: 1.06786   Valid Loss: 1.00036\n",
            "[ Epoch 3276/10000 ] Train Loss: 1.07327   Valid Loss: 1.00911\n",
            "[ Epoch 3277/10000 ] Train Loss: 1.07424   Valid Loss: 0.99808\n",
            "[ Epoch 3278/10000 ] Train Loss: 1.06700   Valid Loss: 1.00284\n",
            "[ Epoch 3279/10000 ] Train Loss: 1.06652   Valid Loss: 1.00482\n",
            "[ Epoch 3280/10000 ] Train Loss: 1.06468   Valid Loss: 1.00542\n",
            "[ Epoch 3281/10000 ] Train Loss: 1.06625   Valid Loss: 1.00106\n",
            "[ Epoch 3282/10000 ] Train Loss: 1.06730   Valid Loss: 0.99803\n",
            "[ Epoch 3283/10000 ] Train Loss: 1.06436   Valid Loss: 0.99872\n",
            "[ Epoch 3284/10000 ] Train Loss: 1.06452   Valid Loss: 0.99818\n",
            "[ Epoch 3285/10000 ] Train Loss: 1.06581   Valid Loss: 0.99923\n",
            "[ Epoch 3286/10000 ] Train Loss: 1.06560   Valid Loss: 0.99970\n",
            "[ Epoch 3287/10000 ] Train Loss: 1.06582   Valid Loss: 1.00486\n",
            "[ Epoch 3288/10000 ] Train Loss: 1.07031   Valid Loss: 1.00145\n",
            "[ Epoch 3289/10000 ] Train Loss: 1.06387   Valid Loss: 0.99896\n",
            "[ Epoch 3290/10000 ] Train Loss: 1.06302   Valid Loss: 0.99793\n",
            "Early Stop Saving Model on Epoch 3290/10000\n",
            "[ Epoch 3291/10000 ] Train Loss: 1.06685   Valid Loss: 0.99771\n",
            "Early Stop Saving Model on Epoch 3291/10000\n",
            "[ Epoch 3292/10000 ] Train Loss: 1.06684   Valid Loss: 0.99813\n",
            "[ Epoch 3293/10000 ] Train Loss: 1.06261   Valid Loss: 0.99865\n",
            "[ Epoch 3294/10000 ] Train Loss: 1.06411   Valid Loss: 0.99824\n",
            "[ Epoch 3295/10000 ] Train Loss: 1.06573   Valid Loss: 0.99894\n",
            "[ Epoch 3296/10000 ] Train Loss: 1.06931   Valid Loss: 1.00263\n",
            "[ Epoch 3297/10000 ] Train Loss: 1.07042   Valid Loss: 1.00976\n",
            "[ Epoch 3298/10000 ] Train Loss: 1.07071   Valid Loss: 1.00185\n",
            "[ Epoch 3299/10000 ] Train Loss: 1.06479   Valid Loss: 0.99828\n",
            "[ Epoch 3300/10000 ] Train Loss: 1.06546   Valid Loss: 0.99792\n",
            "[ Epoch 3301/10000 ] Train Loss: 1.06689   Valid Loss: 1.00024\n",
            "[ Epoch 3302/10000 ] Train Loss: 1.07310   Valid Loss: 1.01431\n",
            "[ Epoch 3303/10000 ] Train Loss: 1.06839   Valid Loss: 1.00164\n",
            "[ Epoch 3304/10000 ] Train Loss: 1.06273   Valid Loss: 1.00379\n",
            "[ Epoch 3305/10000 ] Train Loss: 1.06467   Valid Loss: 1.00598\n",
            "[ Epoch 3306/10000 ] Train Loss: 1.06750   Valid Loss: 0.99779\n",
            "[ Epoch 3307/10000 ] Train Loss: 1.06438   Valid Loss: 0.99748\n",
            "Early Stop Saving Model on Epoch 3307/10000\n",
            "[ Epoch 3308/10000 ] Train Loss: 1.06371   Valid Loss: 0.99833\n",
            "[ Epoch 3309/10000 ] Train Loss: 1.06449   Valid Loss: 0.99711\n",
            "Early Stop Saving Model on Epoch 3309/10000\n",
            "[ Epoch 3310/10000 ] Train Loss: 1.06461   Valid Loss: 0.99912\n",
            "[ Epoch 3311/10000 ] Train Loss: 1.06634   Valid Loss: 1.00211\n",
            "[ Epoch 3312/10000 ] Train Loss: 1.06853   Valid Loss: 0.99628\n",
            "Early Stop Saving Model on Epoch 3312/10000\n",
            "[ Epoch 3313/10000 ] Train Loss: 1.06577   Valid Loss: 0.99769\n",
            "[ Epoch 3314/10000 ] Train Loss: 1.06463   Valid Loss: 0.99673\n",
            "[ Epoch 3315/10000 ] Train Loss: 1.06353   Valid Loss: 0.99750\n",
            "[ Epoch 3316/10000 ] Train Loss: 1.06301   Valid Loss: 0.99967\n",
            "[ Epoch 3317/10000 ] Train Loss: 1.06574   Valid Loss: 1.00118\n",
            "[ Epoch 3318/10000 ] Train Loss: 1.06664   Valid Loss: 1.00031\n",
            "[ Epoch 3319/10000 ] Train Loss: 1.06473   Valid Loss: 0.99692\n",
            "[ Epoch 3320/10000 ] Train Loss: 1.06395   Valid Loss: 0.99835\n",
            "[ Epoch 3321/10000 ] Train Loss: 1.06681   Valid Loss: 1.00240\n",
            "[ Epoch 3322/10000 ] Train Loss: 1.06495   Valid Loss: 0.99636\n",
            "[ Epoch 3323/10000 ] Train Loss: 1.06307   Valid Loss: 0.99707\n",
            "[ Epoch 3324/10000 ] Train Loss: 1.06678   Valid Loss: 1.00117\n",
            "[ Epoch 3325/10000 ] Train Loss: 1.06393   Valid Loss: 0.99615\n",
            "Early Stop Saving Model on Epoch 3325/10000\n",
            "[ Epoch 3326/10000 ] Train Loss: 1.06418   Valid Loss: 0.99921\n",
            "[ Epoch 3327/10000 ] Train Loss: 1.06514   Valid Loss: 0.99809\n",
            "[ Epoch 3328/10000 ] Train Loss: 1.06574   Valid Loss: 0.99892\n",
            "[ Epoch 3329/10000 ] Train Loss: 1.06624   Valid Loss: 0.99750\n",
            "[ Epoch 3330/10000 ] Train Loss: 1.06502   Valid Loss: 0.99650\n",
            "[ Epoch 3331/10000 ] Train Loss: 1.06478   Valid Loss: 0.99971\n",
            "[ Epoch 3332/10000 ] Train Loss: 1.06503   Valid Loss: 1.00182\n",
            "[ Epoch 3333/10000 ] Train Loss: 1.06692   Valid Loss: 0.99712\n",
            "[ Epoch 3334/10000 ] Train Loss: 1.06411   Valid Loss: 0.99731\n",
            "[ Epoch 3335/10000 ] Train Loss: 1.06328   Valid Loss: 0.99763\n",
            "[ Epoch 3336/10000 ] Train Loss: 1.06257   Valid Loss: 0.99669\n",
            "[ Epoch 3337/10000 ] Train Loss: 1.06347   Valid Loss: 0.99730\n",
            "[ Epoch 3338/10000 ] Train Loss: 1.06451   Valid Loss: 0.99589\n",
            "Early Stop Saving Model on Epoch 3338/10000\n",
            "[ Epoch 3339/10000 ] Train Loss: 1.06282   Valid Loss: 0.99712\n",
            "[ Epoch 3340/10000 ] Train Loss: 1.06371   Valid Loss: 0.99926\n",
            "[ Epoch 3341/10000 ] Train Loss: 1.06268   Valid Loss: 0.99516\n",
            "Early Stop Saving Model on Epoch 3341/10000\n",
            "[ Epoch 3342/10000 ] Train Loss: 1.06229   Valid Loss: 0.99626\n",
            "[ Epoch 3343/10000 ] Train Loss: 1.06310   Valid Loss: 0.99719\n",
            "[ Epoch 3344/10000 ] Train Loss: 1.06257   Valid Loss: 0.99852\n",
            "[ Epoch 3345/10000 ] Train Loss: 1.06235   Valid Loss: 0.99808\n",
            "[ Epoch 3346/10000 ] Train Loss: 1.06236   Valid Loss: 1.00547\n",
            "[ Epoch 3347/10000 ] Train Loss: 1.06882   Valid Loss: 0.99746\n",
            "[ Epoch 3348/10000 ] Train Loss: 1.06360   Valid Loss: 0.99604\n",
            "[ Epoch 3349/10000 ] Train Loss: 1.06399   Valid Loss: 0.99991\n",
            "[ Epoch 3350/10000 ] Train Loss: 1.06630   Valid Loss: 0.99720\n",
            "[ Epoch 3351/10000 ] Train Loss: 1.06329   Valid Loss: 0.99697\n",
            "[ Epoch 3352/10000 ] Train Loss: 1.06286   Valid Loss: 0.99638\n",
            "[ Epoch 3353/10000 ] Train Loss: 1.06250   Valid Loss: 0.99582\n",
            "[ Epoch 3354/10000 ] Train Loss: 1.06374   Valid Loss: 0.99586\n",
            "[ Epoch 3355/10000 ] Train Loss: 1.06271   Valid Loss: 0.99612\n",
            "[ Epoch 3356/10000 ] Train Loss: 1.06251   Valid Loss: 0.99606\n",
            "[ Epoch 3357/10000 ] Train Loss: 1.06379   Valid Loss: 0.99640\n",
            "[ Epoch 3358/10000 ] Train Loss: 1.06376   Valid Loss: 0.99808\n",
            "[ Epoch 3359/10000 ] Train Loss: 1.06294   Valid Loss: 0.99952\n",
            "[ Epoch 3360/10000 ] Train Loss: 1.06867   Valid Loss: 1.00081\n",
            "[ Epoch 3361/10000 ] Train Loss: 1.06712   Valid Loss: 1.00581\n",
            "[ Epoch 3362/10000 ] Train Loss: 1.06815   Valid Loss: 0.99689\n",
            "[ Epoch 3363/10000 ] Train Loss: 1.06397   Valid Loss: 0.99711\n",
            "[ Epoch 3364/10000 ] Train Loss: 1.05941   Valid Loss: 0.99746\n",
            "[ Epoch 3365/10000 ] Train Loss: 1.06414   Valid Loss: 0.99729\n",
            "[ Epoch 3366/10000 ] Train Loss: 1.06590   Valid Loss: 0.99924\n",
            "[ Epoch 3367/10000 ] Train Loss: 1.06506   Valid Loss: 0.99583\n",
            "[ Epoch 3368/10000 ] Train Loss: 1.06135   Valid Loss: 0.99670\n",
            "[ Epoch 3369/10000 ] Train Loss: 1.06258   Valid Loss: 0.99818\n",
            "[ Epoch 3370/10000 ] Train Loss: 1.06629   Valid Loss: 0.99583\n",
            "[ Epoch 3371/10000 ] Train Loss: 1.06205   Valid Loss: 0.99678\n",
            "[ Epoch 3372/10000 ] Train Loss: 1.06249   Valid Loss: 0.99662\n",
            "[ Epoch 3373/10000 ] Train Loss: 1.06476   Valid Loss: 0.99748\n",
            "[ Epoch 3374/10000 ] Train Loss: 1.06649   Valid Loss: 0.99678\n",
            "[ Epoch 3375/10000 ] Train Loss: 1.06311   Valid Loss: 1.00159\n",
            "[ Epoch 3376/10000 ] Train Loss: 1.06980   Valid Loss: 0.99577\n",
            "[ Epoch 3377/10000 ] Train Loss: 1.06420   Valid Loss: 0.99704\n",
            "[ Epoch 3378/10000 ] Train Loss: 1.06373   Valid Loss: 0.99818\n",
            "[ Epoch 3379/10000 ] Train Loss: 1.06299   Valid Loss: 0.99732\n",
            "[ Epoch 3380/10000 ] Train Loss: 1.06156   Valid Loss: 0.99619\n",
            "[ Epoch 3381/10000 ] Train Loss: 1.06136   Valid Loss: 0.99537\n",
            "[ Epoch 3382/10000 ] Train Loss: 1.06302   Valid Loss: 0.99676\n",
            "[ Epoch 3383/10000 ] Train Loss: 1.06204   Valid Loss: 0.99485\n",
            "Early Stop Saving Model on Epoch 3383/10000\n",
            "[ Epoch 3384/10000 ] Train Loss: 1.06281   Valid Loss: 0.99598\n",
            "[ Epoch 3385/10000 ] Train Loss: 1.06174   Valid Loss: 0.99746\n",
            "[ Epoch 3386/10000 ] Train Loss: 1.06270   Valid Loss: 0.99657\n",
            "[ Epoch 3387/10000 ] Train Loss: 1.06269   Valid Loss: 0.99518\n",
            "[ Epoch 3388/10000 ] Train Loss: 1.06212   Valid Loss: 0.99714\n",
            "[ Epoch 3389/10000 ] Train Loss: 1.06565   Valid Loss: 1.00097\n",
            "[ Epoch 3390/10000 ] Train Loss: 1.06556   Valid Loss: 0.99666\n",
            "[ Epoch 3391/10000 ] Train Loss: 1.06355   Valid Loss: 0.99543\n",
            "[ Epoch 3392/10000 ] Train Loss: 1.06306   Valid Loss: 0.99723\n",
            "[ Epoch 3393/10000 ] Train Loss: 1.06273   Valid Loss: 0.99605\n",
            "[ Epoch 3394/10000 ] Train Loss: 1.06166   Valid Loss: 0.99632\n",
            "[ Epoch 3395/10000 ] Train Loss: 1.06286   Valid Loss: 0.99630\n",
            "[ Epoch 3396/10000 ] Train Loss: 1.06107   Valid Loss: 0.99739\n",
            "[ Epoch 3397/10000 ] Train Loss: 1.06214   Valid Loss: 0.99562\n",
            "[ Epoch 3398/10000 ] Train Loss: 1.06051   Valid Loss: 0.99648\n",
            "[ Epoch 3399/10000 ] Train Loss: 1.06182   Valid Loss: 0.99732\n",
            "[ Epoch 3400/10000 ] Train Loss: 1.06206   Valid Loss: 0.99495\n",
            "[ Epoch 3401/10000 ] Train Loss: 1.06252   Valid Loss: 0.99631\n",
            "[ Epoch 3402/10000 ] Train Loss: 1.06288   Valid Loss: 0.99500\n",
            "[ Epoch 3403/10000 ] Train Loss: 1.06217   Valid Loss: 0.99587\n",
            "[ Epoch 3404/10000 ] Train Loss: 1.06025   Valid Loss: 0.99469\n",
            "Early Stop Saving Model on Epoch 3404/10000\n",
            "[ Epoch 3405/10000 ] Train Loss: 1.06133   Valid Loss: 0.99591\n",
            "[ Epoch 3406/10000 ] Train Loss: 1.06264   Valid Loss: 0.99511\n",
            "[ Epoch 3407/10000 ] Train Loss: 1.05967   Valid Loss: 0.99777\n",
            "[ Epoch 3408/10000 ] Train Loss: 1.06362   Valid Loss: 0.99543\n",
            "[ Epoch 3409/10000 ] Train Loss: 1.06216   Valid Loss: 0.99462\n",
            "Early Stop Saving Model on Epoch 3409/10000\n",
            "[ Epoch 3410/10000 ] Train Loss: 1.06113   Valid Loss: 0.99555\n",
            "[ Epoch 3411/10000 ] Train Loss: 1.06162   Valid Loss: 0.99576\n",
            "[ Epoch 3412/10000 ] Train Loss: 1.06303   Valid Loss: 0.99666\n",
            "[ Epoch 3413/10000 ] Train Loss: 1.06104   Valid Loss: 0.99692\n",
            "[ Epoch 3414/10000 ] Train Loss: 1.06312   Valid Loss: 0.99705\n",
            "[ Epoch 3415/10000 ] Train Loss: 1.06234   Valid Loss: 0.99587\n",
            "[ Epoch 3416/10000 ] Train Loss: 1.06273   Valid Loss: 0.99510\n",
            "[ Epoch 3417/10000 ] Train Loss: 1.06201   Valid Loss: 0.99799\n",
            "[ Epoch 3418/10000 ] Train Loss: 1.06244   Valid Loss: 0.99513\n",
            "[ Epoch 3419/10000 ] Train Loss: 1.06132   Valid Loss: 0.99772\n",
            "[ Epoch 3420/10000 ] Train Loss: 1.06175   Valid Loss: 0.99473\n",
            "[ Epoch 3421/10000 ] Train Loss: 1.06091   Valid Loss: 0.99559\n",
            "[ Epoch 3422/10000 ] Train Loss: 1.06242   Valid Loss: 0.99683\n",
            "[ Epoch 3423/10000 ] Train Loss: 1.06258   Valid Loss: 0.99571\n",
            "[ Epoch 3424/10000 ] Train Loss: 1.06105   Valid Loss: 0.99557\n",
            "[ Epoch 3425/10000 ] Train Loss: 1.06091   Valid Loss: 0.99445\n",
            "Early Stop Saving Model on Epoch 3425/10000\n",
            "[ Epoch 3426/10000 ] Train Loss: 1.06211   Valid Loss: 0.99625\n",
            "[ Epoch 3427/10000 ] Train Loss: 1.06257   Valid Loss: 0.99676\n",
            "[ Epoch 3428/10000 ] Train Loss: 1.06332   Valid Loss: 0.99477\n",
            "[ Epoch 3429/10000 ] Train Loss: 1.06303   Valid Loss: 0.99763\n",
            "[ Epoch 3430/10000 ] Train Loss: 1.06070   Valid Loss: 0.99730\n",
            "[ Epoch 3431/10000 ] Train Loss: 1.06325   Valid Loss: 0.99722\n",
            "[ Epoch 3432/10000 ] Train Loss: 1.06164   Valid Loss: 0.99471\n",
            "[ Epoch 3433/10000 ] Train Loss: 1.06185   Valid Loss: 0.99616\n",
            "[ Epoch 3434/10000 ] Train Loss: 1.06175   Valid Loss: 0.99417\n",
            "Early Stop Saving Model on Epoch 3434/10000\n",
            "[ Epoch 3435/10000 ] Train Loss: 1.06121   Valid Loss: 0.99843\n",
            "[ Epoch 3436/10000 ] Train Loss: 1.06358   Valid Loss: 0.99513\n",
            "[ Epoch 3437/10000 ] Train Loss: 1.06153   Valid Loss: 0.99642\n",
            "[ Epoch 3438/10000 ] Train Loss: 1.06468   Valid Loss: 0.99516\n",
            "[ Epoch 3439/10000 ] Train Loss: 1.06363   Valid Loss: 0.99873\n",
            "[ Epoch 3440/10000 ] Train Loss: 1.06354   Valid Loss: 0.99551\n",
            "[ Epoch 3441/10000 ] Train Loss: 1.06288   Valid Loss: 0.99540\n",
            "[ Epoch 3442/10000 ] Train Loss: 1.06222   Valid Loss: 0.99506\n",
            "[ Epoch 3443/10000 ] Train Loss: 1.06111   Valid Loss: 0.99565\n",
            "[ Epoch 3444/10000 ] Train Loss: 1.06187   Valid Loss: 0.99484\n",
            "[ Epoch 3445/10000 ] Train Loss: 1.06217   Valid Loss: 0.99513\n",
            "[ Epoch 3446/10000 ] Train Loss: 1.05863   Valid Loss: 0.99699\n",
            "[ Epoch 3447/10000 ] Train Loss: 1.06429   Valid Loss: 0.99753\n",
            "[ Epoch 3448/10000 ] Train Loss: 1.06215   Valid Loss: 0.99752\n",
            "[ Epoch 3449/10000 ] Train Loss: 1.06212   Valid Loss: 0.99542\n",
            "[ Epoch 3450/10000 ] Train Loss: 1.06112   Valid Loss: 0.99780\n",
            "[ Epoch 3451/10000 ] Train Loss: 1.06631   Valid Loss: 0.99792\n",
            "[ Epoch 3452/10000 ] Train Loss: 1.06128   Valid Loss: 0.99530\n",
            "[ Epoch 3453/10000 ] Train Loss: 1.06133   Valid Loss: 0.99598\n",
            "[ Epoch 3454/10000 ] Train Loss: 1.06060   Valid Loss: 0.99540\n",
            "[ Epoch 3455/10000 ] Train Loss: 1.06165   Valid Loss: 0.99560\n",
            "[ Epoch 3456/10000 ] Train Loss: 1.06162   Valid Loss: 0.99607\n",
            "[ Epoch 3457/10000 ] Train Loss: 1.06240   Valid Loss: 0.99475\n",
            "[ Epoch 3458/10000 ] Train Loss: 1.06141   Valid Loss: 0.99782\n",
            "[ Epoch 3459/10000 ] Train Loss: 1.06390   Valid Loss: 1.00155\n",
            "[ Epoch 3460/10000 ] Train Loss: 1.06498   Valid Loss: 0.99440\n",
            "[ Epoch 3461/10000 ] Train Loss: 1.06899   Valid Loss: 1.00111\n",
            "[ Epoch 3462/10000 ] Train Loss: 1.06428   Valid Loss: 1.00176\n",
            "[ Epoch 3463/10000 ] Train Loss: 1.06192   Valid Loss: 0.99688\n",
            "[ Epoch 3464/10000 ] Train Loss: 1.06497   Valid Loss: 0.99608\n",
            "[ Epoch 3465/10000 ] Train Loss: 1.06410   Valid Loss: 0.99419\n",
            "[ Epoch 3466/10000 ] Train Loss: 1.06142   Valid Loss: 0.99478\n",
            "[ Epoch 3467/10000 ] Train Loss: 1.06134   Valid Loss: 0.99519\n",
            "[ Epoch 3468/10000 ] Train Loss: 1.05989   Valid Loss: 0.99426\n",
            "[ Epoch 3469/10000 ] Train Loss: 1.06082   Valid Loss: 0.99352\n",
            "Early Stop Saving Model on Epoch 3469/10000\n",
            "[ Epoch 3470/10000 ] Train Loss: 1.06026   Valid Loss: 0.99576\n",
            "[ Epoch 3471/10000 ] Train Loss: 1.06106   Valid Loss: 0.99606\n",
            "[ Epoch 3472/10000 ] Train Loss: 1.06369   Valid Loss: 0.99645\n",
            "[ Epoch 3473/10000 ] Train Loss: 1.06011   Valid Loss: 0.99568\n",
            "[ Epoch 3474/10000 ] Train Loss: 1.05854   Valid Loss: 0.99498\n",
            "[ Epoch 3475/10000 ] Train Loss: 1.06196   Valid Loss: 0.99506\n",
            "[ Epoch 3476/10000 ] Train Loss: 1.06025   Valid Loss: 0.99435\n",
            "[ Epoch 3477/10000 ] Train Loss: 1.06224   Valid Loss: 0.99383\n",
            "[ Epoch 3478/10000 ] Train Loss: 1.06086   Valid Loss: 0.99515\n",
            "[ Epoch 3479/10000 ] Train Loss: 1.06119   Valid Loss: 0.99999\n",
            "[ Epoch 3480/10000 ] Train Loss: 1.06560   Valid Loss: 0.99880\n",
            "[ Epoch 3481/10000 ] Train Loss: 1.06077   Valid Loss: 0.99727\n",
            "[ Epoch 3482/10000 ] Train Loss: 1.06299   Valid Loss: 0.99954\n",
            "[ Epoch 3483/10000 ] Train Loss: 1.06076   Valid Loss: 0.99411\n",
            "[ Epoch 3484/10000 ] Train Loss: 1.06155   Valid Loss: 0.99481\n",
            "[ Epoch 3485/10000 ] Train Loss: 1.05970   Valid Loss: 0.99488\n",
            "[ Epoch 3486/10000 ] Train Loss: 1.05950   Valid Loss: 0.99757\n",
            "[ Epoch 3487/10000 ] Train Loss: 1.06369   Valid Loss: 0.99734\n",
            "[ Epoch 3488/10000 ] Train Loss: 1.06191   Valid Loss: 0.99377\n",
            "[ Epoch 3489/10000 ] Train Loss: 1.06177   Valid Loss: 0.99495\n",
            "[ Epoch 3490/10000 ] Train Loss: 1.06081   Valid Loss: 1.00002\n",
            "[ Epoch 3491/10000 ] Train Loss: 1.06422   Valid Loss: 0.99450\n",
            "[ Epoch 3492/10000 ] Train Loss: 1.06213   Valid Loss: 0.99454\n",
            "[ Epoch 3493/10000 ] Train Loss: 1.06138   Valid Loss: 0.99715\n",
            "[ Epoch 3494/10000 ] Train Loss: 1.06436   Valid Loss: 0.99443\n",
            "[ Epoch 3495/10000 ] Train Loss: 1.06258   Valid Loss: 0.99936\n",
            "[ Epoch 3496/10000 ] Train Loss: 1.06282   Valid Loss: 0.99396\n",
            "[ Epoch 3497/10000 ] Train Loss: 1.06029   Valid Loss: 0.99466\n",
            "[ Epoch 3498/10000 ] Train Loss: 1.06112   Valid Loss: 0.99582\n",
            "[ Epoch 3499/10000 ] Train Loss: 1.06139   Valid Loss: 0.99425\n",
            "[ Epoch 3500/10000 ] Train Loss: 1.06168   Valid Loss: 0.99371\n",
            "[ Epoch 3501/10000 ] Train Loss: 1.05961   Valid Loss: 0.99582\n",
            "[ Epoch 3502/10000 ] Train Loss: 1.06137   Valid Loss: 0.99420\n",
            "[ Epoch 3503/10000 ] Train Loss: 1.06011   Valid Loss: 0.99331\n",
            "Early Stop Saving Model on Epoch 3503/10000\n",
            "[ Epoch 3504/10000 ] Train Loss: 1.05849   Valid Loss: 0.99597\n",
            "[ Epoch 3505/10000 ] Train Loss: 1.05999   Valid Loss: 0.99515\n",
            "[ Epoch 3506/10000 ] Train Loss: 1.05928   Valid Loss: 0.99704\n",
            "[ Epoch 3507/10000 ] Train Loss: 1.06253   Valid Loss: 0.99547\n",
            "[ Epoch 3508/10000 ] Train Loss: 1.06110   Valid Loss: 0.99353\n",
            "[ Epoch 3509/10000 ] Train Loss: 1.06130   Valid Loss: 0.99441\n",
            "[ Epoch 3510/10000 ] Train Loss: 1.06224   Valid Loss: 0.99538\n",
            "[ Epoch 3511/10000 ] Train Loss: 1.06006   Valid Loss: 0.99545\n",
            "[ Epoch 3512/10000 ] Train Loss: 1.05984   Valid Loss: 0.99602\n",
            "[ Epoch 3513/10000 ] Train Loss: 1.05969   Valid Loss: 0.99459\n",
            "[ Epoch 3514/10000 ] Train Loss: 1.06259   Valid Loss: 0.99473\n",
            "[ Epoch 3515/10000 ] Train Loss: 1.06226   Valid Loss: 0.99355\n",
            "[ Epoch 3516/10000 ] Train Loss: 1.06068   Valid Loss: 0.99446\n",
            "[ Epoch 3517/10000 ] Train Loss: 1.06079   Valid Loss: 0.99397\n",
            "[ Epoch 3518/10000 ] Train Loss: 1.05982   Valid Loss: 0.99368\n",
            "[ Epoch 3519/10000 ] Train Loss: 1.06051   Valid Loss: 0.99460\n",
            "[ Epoch 3520/10000 ] Train Loss: 1.06155   Valid Loss: 0.99457\n",
            "[ Epoch 3521/10000 ] Train Loss: 1.05988   Valid Loss: 0.99701\n",
            "[ Epoch 3522/10000 ] Train Loss: 1.06351   Valid Loss: 0.99380\n",
            "[ Epoch 3523/10000 ] Train Loss: 1.06284   Valid Loss: 0.99659\n",
            "[ Epoch 3524/10000 ] Train Loss: 1.06279   Valid Loss: 0.99865\n",
            "[ Epoch 3525/10000 ] Train Loss: 1.06010   Valid Loss: 0.99565\n",
            "[ Epoch 3526/10000 ] Train Loss: 1.06195   Valid Loss: 0.99482\n",
            "[ Epoch 3527/10000 ] Train Loss: 1.05913   Valid Loss: 0.99313\n",
            "Early Stop Saving Model on Epoch 3527/10000\n",
            "[ Epoch 3528/10000 ] Train Loss: 1.06195   Valid Loss: 0.99621\n",
            "[ Epoch 3529/10000 ] Train Loss: 1.06394   Valid Loss: 0.99589\n",
            "[ Epoch 3530/10000 ] Train Loss: 1.06282   Valid Loss: 0.99363\n",
            "[ Epoch 3531/10000 ] Train Loss: 1.06207   Valid Loss: 0.99383\n",
            "[ Epoch 3532/10000 ] Train Loss: 1.06083   Valid Loss: 0.99675\n",
            "[ Epoch 3533/10000 ] Train Loss: 1.06017   Valid Loss: 0.99432\n",
            "[ Epoch 3534/10000 ] Train Loss: 1.05909   Valid Loss: 0.99662\n",
            "[ Epoch 3535/10000 ] Train Loss: 1.06118   Valid Loss: 0.99485\n",
            "[ Epoch 3536/10000 ] Train Loss: 1.06033   Valid Loss: 0.99317\n",
            "[ Epoch 3537/10000 ] Train Loss: 1.06216   Valid Loss: 1.00001\n",
            "[ Epoch 3538/10000 ] Train Loss: 1.06255   Valid Loss: 0.99897\n",
            "[ Epoch 3539/10000 ] Train Loss: 1.05817   Valid Loss: 0.99623\n",
            "[ Epoch 3540/10000 ] Train Loss: 1.06129   Valid Loss: 0.99597\n",
            "[ Epoch 3541/10000 ] Train Loss: 1.06292   Valid Loss: 0.99450\n",
            "[ Epoch 3542/10000 ] Train Loss: 1.06315   Valid Loss: 0.99637\n",
            "[ Epoch 3543/10000 ] Train Loss: 1.06220   Valid Loss: 0.99339\n",
            "[ Epoch 3544/10000 ] Train Loss: 1.06233   Valid Loss: 0.99663\n",
            "[ Epoch 3545/10000 ] Train Loss: 1.06251   Valid Loss: 0.99391\n",
            "[ Epoch 3546/10000 ] Train Loss: 1.06069   Valid Loss: 0.99305\n",
            "Early Stop Saving Model on Epoch 3546/10000\n",
            "[ Epoch 3547/10000 ] Train Loss: 1.05956   Valid Loss: 0.99642\n",
            "[ Epoch 3548/10000 ] Train Loss: 1.06101   Valid Loss: 0.99354\n",
            "[ Epoch 3549/10000 ] Train Loss: 1.05925   Valid Loss: 0.99468\n",
            "[ Epoch 3550/10000 ] Train Loss: 1.06188   Valid Loss: 0.99451\n",
            "[ Epoch 3551/10000 ] Train Loss: 1.06187   Valid Loss: 0.99343\n",
            "[ Epoch 3552/10000 ] Train Loss: 1.06068   Valid Loss: 0.99474\n",
            "[ Epoch 3553/10000 ] Train Loss: 1.06058   Valid Loss: 0.99326\n",
            "[ Epoch 3554/10000 ] Train Loss: 1.06034   Valid Loss: 0.99455\n",
            "[ Epoch 3555/10000 ] Train Loss: 1.06075   Valid Loss: 0.99320\n",
            "[ Epoch 3556/10000 ] Train Loss: 1.06047   Valid Loss: 0.99498\n",
            "[ Epoch 3557/10000 ] Train Loss: 1.06475   Valid Loss: 0.99623\n",
            "[ Epoch 3558/10000 ] Train Loss: 1.06266   Valid Loss: 0.99395\n",
            "[ Epoch 3559/10000 ] Train Loss: 1.06042   Valid Loss: 0.99378\n",
            "[ Epoch 3560/10000 ] Train Loss: 1.06238   Valid Loss: 0.99260\n",
            "Early Stop Saving Model on Epoch 3560/10000\n",
            "[ Epoch 3561/10000 ] Train Loss: 1.06054   Valid Loss: 0.99373\n",
            "[ Epoch 3562/10000 ] Train Loss: 1.06292   Valid Loss: 1.00062\n",
            "[ Epoch 3563/10000 ] Train Loss: 1.06247   Valid Loss: 0.99473\n",
            "[ Epoch 3564/10000 ] Train Loss: 1.06710   Valid Loss: 0.99438\n",
            "[ Epoch 3565/10000 ] Train Loss: 1.06173   Valid Loss: 0.99797\n",
            "[ Epoch 3566/10000 ] Train Loss: 1.06101   Valid Loss: 0.99514\n",
            "[ Epoch 3567/10000 ] Train Loss: 1.06099   Valid Loss: 0.99407\n",
            "[ Epoch 3568/10000 ] Train Loss: 1.05819   Valid Loss: 0.99450\n",
            "[ Epoch 3569/10000 ] Train Loss: 1.05998   Valid Loss: 0.99350\n",
            "[ Epoch 3570/10000 ] Train Loss: 1.06124   Valid Loss: 0.99532\n",
            "[ Epoch 3571/10000 ] Train Loss: 1.05843   Valid Loss: 0.99273\n",
            "[ Epoch 3572/10000 ] Train Loss: 1.05874   Valid Loss: 0.99474\n",
            "[ Epoch 3573/10000 ] Train Loss: 1.06081   Valid Loss: 0.99618\n",
            "[ Epoch 3574/10000 ] Train Loss: 1.05967   Valid Loss: 0.99394\n",
            "[ Epoch 3575/10000 ] Train Loss: 1.06047   Valid Loss: 0.99590\n",
            "[ Epoch 3576/10000 ] Train Loss: 1.06162   Valid Loss: 0.99559\n",
            "[ Epoch 3577/10000 ] Train Loss: 1.06096   Valid Loss: 0.99553\n",
            "[ Epoch 3578/10000 ] Train Loss: 1.06102   Valid Loss: 0.99362\n",
            "[ Epoch 3579/10000 ] Train Loss: 1.05985   Valid Loss: 0.99405\n",
            "[ Epoch 3580/10000 ] Train Loss: 1.06008   Valid Loss: 0.99826\n",
            "[ Epoch 3581/10000 ] Train Loss: 1.06311   Valid Loss: 0.99354\n",
            "[ Epoch 3582/10000 ] Train Loss: 1.05842   Valid Loss: 0.99331\n",
            "[ Epoch 3583/10000 ] Train Loss: 1.06035   Valid Loss: 0.99403\n",
            "[ Epoch 3584/10000 ] Train Loss: 1.05878   Valid Loss: 0.99458\n",
            "[ Epoch 3585/10000 ] Train Loss: 1.05993   Valid Loss: 0.99301\n",
            "[ Epoch 3586/10000 ] Train Loss: 1.05977   Valid Loss: 0.99280\n",
            "[ Epoch 3587/10000 ] Train Loss: 1.06127   Valid Loss: 1.00015\n",
            "[ Epoch 3588/10000 ] Train Loss: 1.06887   Valid Loss: 0.99761\n",
            "[ Epoch 3589/10000 ] Train Loss: 1.05921   Valid Loss: 0.99437\n",
            "[ Epoch 3590/10000 ] Train Loss: 1.05884   Valid Loss: 0.99264\n",
            "[ Epoch 3591/10000 ] Train Loss: 1.05959   Valid Loss: 0.99288\n",
            "[ Epoch 3592/10000 ] Train Loss: 1.05949   Valid Loss: 0.99311\n",
            "[ Epoch 3593/10000 ] Train Loss: 1.05945   Valid Loss: 0.99350\n",
            "[ Epoch 3594/10000 ] Train Loss: 1.06001   Valid Loss: 0.99577\n",
            "[ Epoch 3595/10000 ] Train Loss: 1.06020   Valid Loss: 0.99216\n",
            "Early Stop Saving Model on Epoch 3595/10000\n",
            "[ Epoch 3596/10000 ] Train Loss: 1.05929   Valid Loss: 0.99401\n",
            "[ Epoch 3597/10000 ] Train Loss: 1.05957   Valid Loss: 0.99303\n",
            "[ Epoch 3598/10000 ] Train Loss: 1.05792   Valid Loss: 0.99408\n",
            "[ Epoch 3599/10000 ] Train Loss: 1.05854   Valid Loss: 0.99258\n",
            "[ Epoch 3600/10000 ] Train Loss: 1.05986   Valid Loss: 0.99441\n",
            "[ Epoch 3601/10000 ] Train Loss: 1.05891   Valid Loss: 0.99406\n",
            "[ Epoch 3602/10000 ] Train Loss: 1.05909   Valid Loss: 0.99285\n",
            "[ Epoch 3603/10000 ] Train Loss: 1.05763   Valid Loss: 0.99445\n",
            "[ Epoch 3604/10000 ] Train Loss: 1.05967   Valid Loss: 0.99275\n",
            "[ Epoch 3605/10000 ] Train Loss: 1.06136   Valid Loss: 0.99636\n",
            "[ Epoch 3606/10000 ] Train Loss: 1.06094   Valid Loss: 0.99662\n",
            "[ Epoch 3607/10000 ] Train Loss: 1.06176   Valid Loss: 0.99463\n",
            "[ Epoch 3608/10000 ] Train Loss: 1.05793   Valid Loss: 0.99487\n",
            "[ Epoch 3609/10000 ] Train Loss: 1.05791   Valid Loss: 0.99240\n",
            "[ Epoch 3610/10000 ] Train Loss: 1.05957   Valid Loss: 0.99256\n",
            "[ Epoch 3611/10000 ] Train Loss: 1.06139   Valid Loss: 0.99443\n",
            "[ Epoch 3612/10000 ] Train Loss: 1.05713   Valid Loss: 0.99445\n",
            "[ Epoch 3613/10000 ] Train Loss: 1.06296   Valid Loss: 0.99273\n",
            "[ Epoch 3614/10000 ] Train Loss: 1.06061   Valid Loss: 0.99519\n",
            "[ Epoch 3615/10000 ] Train Loss: 1.06172   Valid Loss: 0.99566\n",
            "[ Epoch 3616/10000 ] Train Loss: 1.05992   Valid Loss: 0.99454\n",
            "[ Epoch 3617/10000 ] Train Loss: 1.06063   Valid Loss: 0.99253\n",
            "[ Epoch 3618/10000 ] Train Loss: 1.06072   Valid Loss: 0.99228\n",
            "[ Epoch 3619/10000 ] Train Loss: 1.06099   Valid Loss: 0.99320\n",
            "[ Epoch 3620/10000 ] Train Loss: 1.05985   Valid Loss: 0.99208\n",
            "Early Stop Saving Model on Epoch 3620/10000\n",
            "[ Epoch 3621/10000 ] Train Loss: 1.05848   Valid Loss: 0.99263\n",
            "[ Epoch 3622/10000 ] Train Loss: 1.05790   Valid Loss: 0.99236\n",
            "[ Epoch 3623/10000 ] Train Loss: 1.05758   Valid Loss: 0.99276\n",
            "[ Epoch 3624/10000 ] Train Loss: 1.06154   Valid Loss: 0.99454\n",
            "[ Epoch 3625/10000 ] Train Loss: 1.06071   Valid Loss: 0.99385\n",
            "[ Epoch 3626/10000 ] Train Loss: 1.06203   Valid Loss: 0.99396\n",
            "[ Epoch 3627/10000 ] Train Loss: 1.06380   Valid Loss: 0.99461\n",
            "[ Epoch 3628/10000 ] Train Loss: 1.06096   Valid Loss: 0.99461\n",
            "[ Epoch 3629/10000 ] Train Loss: 1.05673   Valid Loss: 0.99293\n",
            "[ Epoch 3630/10000 ] Train Loss: 1.05813   Valid Loss: 0.99293\n",
            "[ Epoch 3631/10000 ] Train Loss: 1.05911   Valid Loss: 0.99204\n",
            "Early Stop Saving Model on Epoch 3631/10000\n",
            "[ Epoch 3632/10000 ] Train Loss: 1.05852   Valid Loss: 0.99230\n",
            "[ Epoch 3633/10000 ] Train Loss: 1.05977   Valid Loss: 0.99295\n",
            "[ Epoch 3634/10000 ] Train Loss: 1.06056   Valid Loss: 0.99389\n",
            "[ Epoch 3635/10000 ] Train Loss: 1.05738   Valid Loss: 0.99419\n",
            "[ Epoch 3636/10000 ] Train Loss: 1.05971   Valid Loss: 0.99164\n",
            "Early Stop Saving Model on Epoch 3636/10000\n",
            "[ Epoch 3637/10000 ] Train Loss: 1.05828   Valid Loss: 0.99214\n",
            "[ Epoch 3638/10000 ] Train Loss: 1.05815   Valid Loss: 0.99201\n",
            "[ Epoch 3639/10000 ] Train Loss: 1.05911   Valid Loss: 0.99277\n",
            "[ Epoch 3640/10000 ] Train Loss: 1.06035   Valid Loss: 0.99395\n",
            "[ Epoch 3641/10000 ] Train Loss: 1.05810   Valid Loss: 0.99252\n",
            "[ Epoch 3642/10000 ] Train Loss: 1.05840   Valid Loss: 0.99379\n",
            "[ Epoch 3643/10000 ] Train Loss: 1.05860   Valid Loss: 0.99244\n",
            "[ Epoch 3644/10000 ] Train Loss: 1.05830   Valid Loss: 0.99138\n",
            "Early Stop Saving Model on Epoch 3644/10000\n",
            "[ Epoch 3645/10000 ] Train Loss: 1.05908   Valid Loss: 0.99312\n",
            "[ Epoch 3646/10000 ] Train Loss: 1.05643   Valid Loss: 0.99177\n",
            "[ Epoch 3647/10000 ] Train Loss: 1.05951   Valid Loss: 0.99274\n",
            "[ Epoch 3648/10000 ] Train Loss: 1.05868   Valid Loss: 0.99193\n",
            "[ Epoch 3649/10000 ] Train Loss: 1.05878   Valid Loss: 0.99366\n",
            "[ Epoch 3650/10000 ] Train Loss: 1.05837   Valid Loss: 0.99288\n",
            "[ Epoch 3651/10000 ] Train Loss: 1.05894   Valid Loss: 0.99153\n",
            "[ Epoch 3652/10000 ] Train Loss: 1.05900   Valid Loss: 0.99221\n",
            "[ Epoch 3653/10000 ] Train Loss: 1.05778   Valid Loss: 0.99330\n",
            "[ Epoch 3654/10000 ] Train Loss: 1.05819   Valid Loss: 0.99191\n",
            "[ Epoch 3655/10000 ] Train Loss: 1.05862   Valid Loss: 0.99263\n",
            "[ Epoch 3656/10000 ] Train Loss: 1.05826   Valid Loss: 0.99222\n",
            "[ Epoch 3657/10000 ] Train Loss: 1.05770   Valid Loss: 0.99460\n",
            "[ Epoch 3658/10000 ] Train Loss: 1.05804   Valid Loss: 0.99174\n",
            "[ Epoch 3659/10000 ] Train Loss: 1.06006   Valid Loss: 0.99435\n",
            "[ Epoch 3660/10000 ] Train Loss: 1.06034   Valid Loss: 0.99178\n",
            "[ Epoch 3661/10000 ] Train Loss: 1.06140   Valid Loss: 0.99424\n",
            "[ Epoch 3662/10000 ] Train Loss: 1.06181   Valid Loss: 0.99549\n",
            "[ Epoch 3663/10000 ] Train Loss: 1.05727   Valid Loss: 0.99201\n",
            "[ Epoch 3664/10000 ] Train Loss: 1.05746   Valid Loss: 0.99256\n",
            "[ Epoch 3665/10000 ] Train Loss: 1.05848   Valid Loss: 0.99536\n",
            "[ Epoch 3666/10000 ] Train Loss: 1.06072   Valid Loss: 0.99094\n",
            "Early Stop Saving Model on Epoch 3666/10000\n",
            "[ Epoch 3667/10000 ] Train Loss: 1.05981   Valid Loss: 0.99318\n",
            "[ Epoch 3668/10000 ] Train Loss: 1.05855   Valid Loss: 0.99171\n",
            "[ Epoch 3669/10000 ] Train Loss: 1.05882   Valid Loss: 0.99468\n",
            "[ Epoch 3670/10000 ] Train Loss: 1.05778   Valid Loss: 0.99502\n",
            "[ Epoch 3671/10000 ] Train Loss: 1.06126   Valid Loss: 0.99147\n",
            "[ Epoch 3672/10000 ] Train Loss: 1.05988   Valid Loss: 0.99490\n",
            "[ Epoch 3673/10000 ] Train Loss: 1.05941   Valid Loss: 0.99378\n",
            "[ Epoch 3674/10000 ] Train Loss: 1.06085   Valid Loss: 0.99457\n",
            "[ Epoch 3675/10000 ] Train Loss: 1.05921   Valid Loss: 0.99340\n",
            "[ Epoch 3676/10000 ] Train Loss: 1.06012   Valid Loss: 0.99196\n",
            "[ Epoch 3677/10000 ] Train Loss: 1.05788   Valid Loss: 0.99215\n",
            "[ Epoch 3678/10000 ] Train Loss: 1.05934   Valid Loss: 0.99524\n",
            "[ Epoch 3679/10000 ] Train Loss: 1.06028   Valid Loss: 0.99046\n",
            "Early Stop Saving Model on Epoch 3679/10000\n",
            "[ Epoch 3680/10000 ] Train Loss: 1.05884   Valid Loss: 0.99193\n",
            "[ Epoch 3681/10000 ] Train Loss: 1.05742   Valid Loss: 0.99285\n",
            "[ Epoch 3682/10000 ] Train Loss: 1.05672   Valid Loss: 0.99146\n",
            "[ Epoch 3683/10000 ] Train Loss: 1.05945   Valid Loss: 0.99187\n",
            "[ Epoch 3684/10000 ] Train Loss: 1.05908   Valid Loss: 0.99142\n",
            "[ Epoch 3685/10000 ] Train Loss: 1.05774   Valid Loss: 0.99148\n",
            "[ Epoch 3686/10000 ] Train Loss: 1.05805   Valid Loss: 0.99137\n",
            "[ Epoch 3687/10000 ] Train Loss: 1.05633   Valid Loss: 0.99246\n",
            "[ Epoch 3688/10000 ] Train Loss: 1.05723   Valid Loss: 0.99093\n",
            "[ Epoch 3689/10000 ] Train Loss: 1.05795   Valid Loss: 0.99237\n",
            "[ Epoch 3690/10000 ] Train Loss: 1.05627   Valid Loss: 0.99329\n",
            "[ Epoch 3691/10000 ] Train Loss: 1.05707   Valid Loss: 0.99081\n",
            "[ Epoch 3692/10000 ] Train Loss: 1.05744   Valid Loss: 0.99234\n",
            "[ Epoch 3693/10000 ] Train Loss: 1.05749   Valid Loss: 0.99564\n",
            "[ Epoch 3694/10000 ] Train Loss: 1.05862   Valid Loss: 0.99515\n",
            "[ Epoch 3695/10000 ] Train Loss: 1.06219   Valid Loss: 0.99085\n",
            "[ Epoch 3696/10000 ] Train Loss: 1.05975   Valid Loss: 0.99412\n",
            "[ Epoch 3697/10000 ] Train Loss: 1.06026   Valid Loss: 0.99273\n",
            "[ Epoch 3698/10000 ] Train Loss: 1.05997   Valid Loss: 0.99219\n",
            "[ Epoch 3699/10000 ] Train Loss: 1.05784   Valid Loss: 0.99166\n",
            "[ Epoch 3700/10000 ] Train Loss: 1.05829   Valid Loss: 0.99218\n",
            "[ Epoch 3701/10000 ] Train Loss: 1.05702   Valid Loss: 0.99044\n",
            "Early Stop Saving Model on Epoch 3701/10000\n",
            "[ Epoch 3702/10000 ] Train Loss: 1.05665   Valid Loss: 0.99225\n",
            "[ Epoch 3703/10000 ] Train Loss: 1.05628   Valid Loss: 0.99216\n",
            "[ Epoch 3704/10000 ] Train Loss: 1.05864   Valid Loss: 0.99049\n",
            "[ Epoch 3705/10000 ] Train Loss: 1.05752   Valid Loss: 0.99247\n",
            "[ Epoch 3706/10000 ] Train Loss: 1.05722   Valid Loss: 0.99056\n",
            "[ Epoch 3707/10000 ] Train Loss: 1.05688   Valid Loss: 0.99299\n",
            "[ Epoch 3708/10000 ] Train Loss: 1.06016   Valid Loss: 0.99162\n",
            "[ Epoch 3709/10000 ] Train Loss: 1.05695   Valid Loss: 0.99075\n",
            "[ Epoch 3710/10000 ] Train Loss: 1.05881   Valid Loss: 0.99368\n",
            "[ Epoch 3711/10000 ] Train Loss: 1.05692   Valid Loss: 0.99159\n",
            "[ Epoch 3712/10000 ] Train Loss: 1.05727   Valid Loss: 0.99026\n",
            "Early Stop Saving Model on Epoch 3712/10000\n",
            "[ Epoch 3713/10000 ] Train Loss: 1.05828   Valid Loss: 0.99085\n",
            "[ Epoch 3714/10000 ] Train Loss: 1.05714   Valid Loss: 0.99325\n",
            "[ Epoch 3715/10000 ] Train Loss: 1.05766   Valid Loss: 0.99119\n",
            "[ Epoch 3716/10000 ] Train Loss: 1.05710   Valid Loss: 0.99118\n",
            "[ Epoch 3717/10000 ] Train Loss: 1.05566   Valid Loss: 0.99049\n",
            "[ Epoch 3718/10000 ] Train Loss: 1.05776   Valid Loss: 0.99291\n",
            "[ Epoch 3719/10000 ] Train Loss: 1.05346   Valid Loss: 0.99038\n",
            "[ Epoch 3720/10000 ] Train Loss: 1.05494   Valid Loss: 0.99292\n",
            "[ Epoch 3721/10000 ] Train Loss: 1.05495   Valid Loss: 0.99125\n",
            "[ Epoch 3722/10000 ] Train Loss: 1.05882   Valid Loss: 0.99250\n",
            "[ Epoch 3723/10000 ] Train Loss: 1.05958   Valid Loss: 0.99886\n",
            "[ Epoch 3724/10000 ] Train Loss: 1.06332   Valid Loss: 0.99472\n",
            "[ Epoch 3725/10000 ] Train Loss: 1.06079   Valid Loss: 0.99027\n",
            "[ Epoch 3726/10000 ] Train Loss: 1.05924   Valid Loss: 0.99286\n",
            "[ Epoch 3727/10000 ] Train Loss: 1.05565   Valid Loss: 0.99080\n",
            "[ Epoch 3728/10000 ] Train Loss: 1.05739   Valid Loss: 0.99018\n",
            "Early Stop Saving Model on Epoch 3728/10000\n",
            "[ Epoch 3729/10000 ] Train Loss: 1.05969   Valid Loss: 0.99305\n",
            "[ Epoch 3730/10000 ] Train Loss: 1.05548   Valid Loss: 0.99267\n",
            "[ Epoch 3731/10000 ] Train Loss: 1.05724   Valid Loss: 0.99040\n",
            "[ Epoch 3732/10000 ] Train Loss: 1.05745   Valid Loss: 0.99096\n",
            "[ Epoch 3733/10000 ] Train Loss: 1.05811   Valid Loss: 0.99086\n",
            "[ Epoch 3734/10000 ] Train Loss: 1.05849   Valid Loss: 0.99140\n",
            "[ Epoch 3735/10000 ] Train Loss: 1.05702   Valid Loss: 0.99022\n",
            "[ Epoch 3736/10000 ] Train Loss: 1.05564   Valid Loss: 0.99045\n",
            "[ Epoch 3737/10000 ] Train Loss: 1.05624   Valid Loss: 0.99108\n",
            "[ Epoch 3738/10000 ] Train Loss: 1.05847   Valid Loss: 0.99067\n",
            "[ Epoch 3739/10000 ] Train Loss: 1.05805   Valid Loss: 0.99057\n",
            "[ Epoch 3740/10000 ] Train Loss: 1.05980   Valid Loss: 0.99349\n",
            "[ Epoch 3741/10000 ] Train Loss: 1.05743   Valid Loss: 0.98959\n",
            "Early Stop Saving Model on Epoch 3741/10000\n",
            "[ Epoch 3742/10000 ] Train Loss: 1.05791   Valid Loss: 0.99084\n",
            "[ Epoch 3743/10000 ] Train Loss: 1.05825   Valid Loss: 0.99187\n",
            "[ Epoch 3744/10000 ] Train Loss: 1.05789   Valid Loss: 0.98982\n",
            "[ Epoch 3745/10000 ] Train Loss: 1.05777   Valid Loss: 0.99269\n",
            "[ Epoch 3746/10000 ] Train Loss: 1.05926   Valid Loss: 0.99050\n",
            "[ Epoch 3747/10000 ] Train Loss: 1.06012   Valid Loss: 0.99159\n",
            "[ Epoch 3748/10000 ] Train Loss: 1.05666   Valid Loss: 0.99322\n",
            "[ Epoch 3749/10000 ] Train Loss: 1.06241   Valid Loss: 0.99055\n",
            "[ Epoch 3750/10000 ] Train Loss: 1.05954   Valid Loss: 0.99387\n",
            "[ Epoch 3751/10000 ] Train Loss: 1.05922   Valid Loss: 0.99033\n",
            "[ Epoch 3752/10000 ] Train Loss: 1.05716   Valid Loss: 0.99172\n",
            "[ Epoch 3753/10000 ] Train Loss: 1.05774   Valid Loss: 0.99363\n",
            "[ Epoch 3754/10000 ] Train Loss: 1.05849   Valid Loss: 0.99099\n",
            "[ Epoch 3755/10000 ] Train Loss: 1.05728   Valid Loss: 0.99066\n",
            "[ Epoch 3756/10000 ] Train Loss: 1.05445   Valid Loss: 0.99014\n",
            "[ Epoch 3757/10000 ] Train Loss: 1.05761   Valid Loss: 0.99386\n",
            "[ Epoch 3758/10000 ] Train Loss: 1.05529   Valid Loss: 0.99200\n",
            "[ Epoch 3759/10000 ] Train Loss: 1.05867   Valid Loss: 0.98919\n",
            "Early Stop Saving Model on Epoch 3759/10000\n",
            "[ Epoch 3760/10000 ] Train Loss: 1.05847   Valid Loss: 0.99172\n",
            "[ Epoch 3761/10000 ] Train Loss: 1.05805   Valid Loss: 0.99117\n",
            "[ Epoch 3762/10000 ] Train Loss: 1.05753   Valid Loss: 0.99178\n",
            "[ Epoch 3763/10000 ] Train Loss: 1.05677   Valid Loss: 0.98959\n",
            "[ Epoch 3764/10000 ] Train Loss: 1.05683   Valid Loss: 0.99299\n",
            "[ Epoch 3765/10000 ] Train Loss: 1.05776   Valid Loss: 0.99081\n",
            "[ Epoch 3766/10000 ] Train Loss: 1.05645   Valid Loss: 0.99068\n",
            "[ Epoch 3767/10000 ] Train Loss: 1.05635   Valid Loss: 0.99021\n",
            "[ Epoch 3768/10000 ] Train Loss: 1.05661   Valid Loss: 0.99081\n",
            "[ Epoch 3769/10000 ] Train Loss: 1.05691   Valid Loss: 0.99049\n",
            "[ Epoch 3770/10000 ] Train Loss: 1.05762   Valid Loss: 0.99054\n",
            "[ Epoch 3771/10000 ] Train Loss: 1.05707   Valid Loss: 0.99077\n",
            "[ Epoch 3772/10000 ] Train Loss: 1.05728   Valid Loss: 0.99002\n",
            "[ Epoch 3773/10000 ] Train Loss: 1.05722   Valid Loss: 0.99532\n",
            "[ Epoch 3774/10000 ] Train Loss: 1.06029   Valid Loss: 0.99020\n",
            "[ Epoch 3775/10000 ] Train Loss: 1.05755   Valid Loss: 0.99285\n",
            "[ Epoch 3776/10000 ] Train Loss: 1.06131   Valid Loss: 0.99544\n",
            "[ Epoch 3777/10000 ] Train Loss: 1.05818   Valid Loss: 0.99560\n",
            "[ Epoch 3778/10000 ] Train Loss: 1.05697   Valid Loss: 0.99256\n",
            "[ Epoch 3779/10000 ] Train Loss: 1.05778   Valid Loss: 0.99042\n",
            "[ Epoch 3780/10000 ] Train Loss: 1.05447   Valid Loss: 0.99353\n",
            "[ Epoch 3781/10000 ] Train Loss: 1.05859   Valid Loss: 0.99242\n",
            "[ Epoch 3782/10000 ] Train Loss: 1.05959   Valid Loss: 0.98943\n",
            "[ Epoch 3783/10000 ] Train Loss: 1.05776   Valid Loss: 0.99083\n",
            "[ Epoch 3784/10000 ] Train Loss: 1.05666   Valid Loss: 0.98892\n",
            "Early Stop Saving Model on Epoch 3784/10000\n",
            "[ Epoch 3785/10000 ] Train Loss: 1.05467   Valid Loss: 0.99006\n",
            "[ Epoch 3786/10000 ] Train Loss: 1.05518   Valid Loss: 0.99004\n",
            "[ Epoch 3787/10000 ] Train Loss: 1.05681   Valid Loss: 0.99079\n",
            "[ Epoch 3788/10000 ] Train Loss: 1.05640   Valid Loss: 0.98962\n",
            "[ Epoch 3789/10000 ] Train Loss: 1.05679   Valid Loss: 0.99199\n",
            "[ Epoch 3790/10000 ] Train Loss: 1.05859   Valid Loss: 0.98891\n",
            "Early Stop Saving Model on Epoch 3790/10000\n",
            "[ Epoch 3791/10000 ] Train Loss: 1.05775   Valid Loss: 0.99397\n",
            "[ Epoch 3792/10000 ] Train Loss: 1.05667   Valid Loss: 0.99003\n",
            "[ Epoch 3793/10000 ] Train Loss: 1.05644   Valid Loss: 0.99013\n",
            "[ Epoch 3794/10000 ] Train Loss: 1.05686   Valid Loss: 0.98989\n",
            "[ Epoch 3795/10000 ] Train Loss: 1.05598   Valid Loss: 0.99031\n",
            "[ Epoch 3796/10000 ] Train Loss: 1.05762   Valid Loss: 0.99160\n",
            "[ Epoch 3797/10000 ] Train Loss: 1.05595   Valid Loss: 0.99201\n",
            "[ Epoch 3798/10000 ] Train Loss: 1.05626   Valid Loss: 0.99761\n",
            "[ Epoch 3799/10000 ] Train Loss: 1.05827   Valid Loss: 0.99217\n",
            "[ Epoch 3800/10000 ] Train Loss: 1.05810   Valid Loss: 0.98850\n",
            "Early Stop Saving Model on Epoch 3800/10000\n",
            "[ Epoch 3801/10000 ] Train Loss: 1.05684   Valid Loss: 0.98888\n",
            "[ Epoch 3802/10000 ] Train Loss: 1.05526   Valid Loss: 0.99071\n",
            "[ Epoch 3803/10000 ] Train Loss: 1.05561   Valid Loss: 0.99109\n",
            "[ Epoch 3804/10000 ] Train Loss: 1.05331   Valid Loss: 0.99189\n",
            "[ Epoch 3805/10000 ] Train Loss: 1.05526   Valid Loss: 0.99302\n",
            "[ Epoch 3806/10000 ] Train Loss: 1.05708   Valid Loss: 0.99749\n",
            "[ Epoch 3807/10000 ] Train Loss: 1.05806   Valid Loss: 0.99148\n",
            "[ Epoch 3808/10000 ] Train Loss: 1.05945   Valid Loss: 0.98908\n",
            "[ Epoch 3809/10000 ] Train Loss: 1.05663   Valid Loss: 0.99070\n",
            "[ Epoch 3810/10000 ] Train Loss: 1.05597   Valid Loss: 0.99374\n",
            "[ Epoch 3811/10000 ] Train Loss: 1.05701   Valid Loss: 0.98905\n",
            "[ Epoch 3812/10000 ] Train Loss: 1.05601   Valid Loss: 0.98989\n",
            "[ Epoch 3813/10000 ] Train Loss: 1.05504   Valid Loss: 0.98827\n",
            "Early Stop Saving Model on Epoch 3813/10000\n",
            "[ Epoch 3814/10000 ] Train Loss: 1.05570   Valid Loss: 0.98963\n",
            "[ Epoch 3815/10000 ] Train Loss: 1.05683   Valid Loss: 0.99147\n",
            "[ Epoch 3816/10000 ] Train Loss: 1.05620   Valid Loss: 0.98929\n",
            "[ Epoch 3817/10000 ] Train Loss: 1.05684   Valid Loss: 0.99033\n",
            "[ Epoch 3818/10000 ] Train Loss: 1.05803   Valid Loss: 0.99614\n",
            "[ Epoch 3819/10000 ] Train Loss: 1.05978   Valid Loss: 0.99112\n",
            "[ Epoch 3820/10000 ] Train Loss: 1.05512   Valid Loss: 0.99161\n",
            "[ Epoch 3821/10000 ] Train Loss: 1.05641   Valid Loss: 0.98856\n",
            "[ Epoch 3822/10000 ] Train Loss: 1.05598   Valid Loss: 0.98913\n",
            "[ Epoch 3823/10000 ] Train Loss: 1.05581   Valid Loss: 0.99081\n",
            "[ Epoch 3824/10000 ] Train Loss: 1.05692   Valid Loss: 0.99047\n",
            "[ Epoch 3825/10000 ] Train Loss: 1.05660   Valid Loss: 0.99038\n",
            "[ Epoch 3826/10000 ] Train Loss: 1.05470   Valid Loss: 0.98864\n",
            "[ Epoch 3827/10000 ] Train Loss: 1.05550   Valid Loss: 0.98946\n",
            "[ Epoch 3828/10000 ] Train Loss: 1.05507   Valid Loss: 0.98865\n",
            "[ Epoch 3829/10000 ] Train Loss: 1.05577   Valid Loss: 0.98907\n",
            "[ Epoch 3830/10000 ] Train Loss: 1.05571   Valid Loss: 0.98790\n",
            "Early Stop Saving Model on Epoch 3830/10000\n",
            "[ Epoch 3831/10000 ] Train Loss: 1.05613   Valid Loss: 0.99149\n",
            "[ Epoch 3832/10000 ] Train Loss: 1.05464   Valid Loss: 0.98951\n",
            "[ Epoch 3833/10000 ] Train Loss: 1.05488   Valid Loss: 0.98776\n",
            "Early Stop Saving Model on Epoch 3833/10000\n",
            "[ Epoch 3834/10000 ] Train Loss: 1.05523   Valid Loss: 0.98889\n",
            "[ Epoch 3835/10000 ] Train Loss: 1.05700   Valid Loss: 0.99047\n",
            "[ Epoch 3836/10000 ] Train Loss: 1.05653   Valid Loss: 0.99126\n",
            "[ Epoch 3837/10000 ] Train Loss: 1.05543   Valid Loss: 0.98924\n",
            "[ Epoch 3838/10000 ] Train Loss: 1.05619   Valid Loss: 0.98869\n",
            "[ Epoch 3839/10000 ] Train Loss: 1.05471   Valid Loss: 0.98951\n",
            "[ Epoch 3840/10000 ] Train Loss: 1.05599   Valid Loss: 0.98723\n",
            "Early Stop Saving Model on Epoch 3840/10000\n",
            "[ Epoch 3841/10000 ] Train Loss: 1.05484   Valid Loss: 0.99071\n",
            "[ Epoch 3842/10000 ] Train Loss: 1.05664   Valid Loss: 0.99331\n",
            "[ Epoch 3843/10000 ] Train Loss: 1.05827   Valid Loss: 0.99142\n",
            "[ Epoch 3844/10000 ] Train Loss: 1.05251   Valid Loss: 0.98942\n",
            "[ Epoch 3845/10000 ] Train Loss: 1.05344   Valid Loss: 0.98869\n",
            "[ Epoch 3846/10000 ] Train Loss: 1.05452   Valid Loss: 0.98875\n",
            "[ Epoch 3847/10000 ] Train Loss: 1.05619   Valid Loss: 0.99005\n",
            "[ Epoch 3848/10000 ] Train Loss: 1.05414   Valid Loss: 0.99027\n",
            "[ Epoch 3849/10000 ] Train Loss: 1.05542   Valid Loss: 0.99193\n",
            "[ Epoch 3850/10000 ] Train Loss: 1.05799   Valid Loss: 0.98894\n",
            "[ Epoch 3851/10000 ] Train Loss: 1.05533   Valid Loss: 0.98882\n",
            "[ Epoch 3852/10000 ] Train Loss: 1.05837   Valid Loss: 0.99702\n",
            "[ Epoch 3853/10000 ] Train Loss: 1.05623   Valid Loss: 0.98922\n",
            "[ Epoch 3854/10000 ] Train Loss: 1.05537   Valid Loss: 0.98787\n",
            "[ Epoch 3855/10000 ] Train Loss: 1.05406   Valid Loss: 0.98764\n",
            "[ Epoch 3856/10000 ] Train Loss: 1.05488   Valid Loss: 0.98905\n",
            "[ Epoch 3857/10000 ] Train Loss: 1.05406   Valid Loss: 0.98802\n",
            "[ Epoch 3858/10000 ] Train Loss: 1.05505   Valid Loss: 0.98737\n",
            "[ Epoch 3859/10000 ] Train Loss: 1.05613   Valid Loss: 0.98786\n",
            "[ Epoch 3860/10000 ] Train Loss: 1.05513   Valid Loss: 0.99092\n",
            "[ Epoch 3861/10000 ] Train Loss: 1.05483   Valid Loss: 0.99031\n",
            "[ Epoch 3862/10000 ] Train Loss: 1.05527   Valid Loss: 0.98924\n",
            "[ Epoch 3863/10000 ] Train Loss: 1.05508   Valid Loss: 0.98875\n",
            "[ Epoch 3864/10000 ] Train Loss: 1.05379   Valid Loss: 0.98735\n",
            "[ Epoch 3865/10000 ] Train Loss: 1.05443   Valid Loss: 0.98859\n",
            "[ Epoch 3866/10000 ] Train Loss: 1.05494   Valid Loss: 0.98903\n",
            "[ Epoch 3867/10000 ] Train Loss: 1.05637   Valid Loss: 0.99127\n",
            "[ Epoch 3868/10000 ] Train Loss: 1.05690   Valid Loss: 0.98782\n",
            "[ Epoch 3869/10000 ] Train Loss: 1.05436   Valid Loss: 0.98730\n",
            "[ Epoch 3870/10000 ] Train Loss: 1.05508   Valid Loss: 0.99391\n",
            "[ Epoch 3871/10000 ] Train Loss: 1.05587   Valid Loss: 0.99134\n",
            "[ Epoch 3872/10000 ] Train Loss: 1.05485   Valid Loss: 0.98686\n",
            "Early Stop Saving Model on Epoch 3872/10000\n",
            "[ Epoch 3873/10000 ] Train Loss: 1.05499   Valid Loss: 0.98914\n",
            "[ Epoch 3874/10000 ] Train Loss: 1.05373   Valid Loss: 0.98789\n",
            "[ Epoch 3875/10000 ] Train Loss: 1.05483   Valid Loss: 0.98842\n",
            "[ Epoch 3876/10000 ] Train Loss: 1.05338   Valid Loss: 0.98954\n",
            "[ Epoch 3877/10000 ] Train Loss: 1.05665   Valid Loss: 0.98823\n",
            "[ Epoch 3878/10000 ] Train Loss: 1.05429   Valid Loss: 0.98749\n",
            "[ Epoch 3879/10000 ] Train Loss: 1.05387   Valid Loss: 0.98707\n",
            "[ Epoch 3880/10000 ] Train Loss: 1.05568   Valid Loss: 0.99004\n",
            "[ Epoch 3881/10000 ] Train Loss: 1.05614   Valid Loss: 0.98955\n",
            "[ Epoch 3882/10000 ] Train Loss: 1.05412   Valid Loss: 0.98739\n",
            "[ Epoch 3883/10000 ] Train Loss: 1.05447   Valid Loss: 0.98818\n",
            "[ Epoch 3884/10000 ] Train Loss: 1.05423   Valid Loss: 0.98883\n",
            "[ Epoch 3885/10000 ] Train Loss: 1.05486   Valid Loss: 0.99095\n",
            "[ Epoch 3886/10000 ] Train Loss: 1.05288   Valid Loss: 0.98710\n",
            "[ Epoch 3887/10000 ] Train Loss: 1.05358   Valid Loss: 0.98855\n",
            "[ Epoch 3888/10000 ] Train Loss: 1.05471   Valid Loss: 0.98882\n",
            "[ Epoch 3889/10000 ] Train Loss: 1.05533   Valid Loss: 0.98720\n",
            "[ Epoch 3890/10000 ] Train Loss: 1.05548   Valid Loss: 0.98800\n",
            "[ Epoch 3891/10000 ] Train Loss: 1.05509   Valid Loss: 0.98774\n",
            "[ Epoch 3892/10000 ] Train Loss: 1.05426   Valid Loss: 0.98850\n",
            "[ Epoch 3893/10000 ] Train Loss: 1.05538   Valid Loss: 0.98649\n",
            "Early Stop Saving Model on Epoch 3893/10000\n",
            "[ Epoch 3894/10000 ] Train Loss: 1.05432   Valid Loss: 0.98782\n",
            "[ Epoch 3895/10000 ] Train Loss: 1.05431   Valid Loss: 0.98769\n",
            "[ Epoch 3896/10000 ] Train Loss: 1.05669   Valid Loss: 0.99014\n",
            "[ Epoch 3897/10000 ] Train Loss: 1.05512   Valid Loss: 0.98805\n",
            "[ Epoch 3898/10000 ] Train Loss: 1.05509   Valid Loss: 0.98838\n",
            "[ Epoch 3899/10000 ] Train Loss: 1.05759   Valid Loss: 0.99157\n",
            "[ Epoch 3900/10000 ] Train Loss: 1.05558   Valid Loss: 0.99090\n",
            "[ Epoch 3901/10000 ] Train Loss: 1.05825   Valid Loss: 0.98835\n",
            "[ Epoch 3902/10000 ] Train Loss: 1.05685   Valid Loss: 0.99143\n",
            "[ Epoch 3903/10000 ] Train Loss: 1.05593   Valid Loss: 0.98675\n",
            "[ Epoch 3904/10000 ] Train Loss: 1.05535   Valid Loss: 0.98723\n",
            "[ Epoch 3905/10000 ] Train Loss: 1.05499   Valid Loss: 0.99261\n",
            "[ Epoch 3906/10000 ] Train Loss: 1.05481   Valid Loss: 0.98819\n",
            "[ Epoch 3907/10000 ] Train Loss: 1.05193   Valid Loss: 0.98669\n",
            "[ Epoch 3908/10000 ] Train Loss: 1.05298   Valid Loss: 0.98907\n",
            "[ Epoch 3909/10000 ] Train Loss: 1.05356   Valid Loss: 0.98887\n",
            "[ Epoch 3910/10000 ] Train Loss: 1.05518   Valid Loss: 0.98786\n",
            "[ Epoch 3911/10000 ] Train Loss: 1.05162   Valid Loss: 0.98799\n",
            "[ Epoch 3912/10000 ] Train Loss: 1.05528   Valid Loss: 0.98870\n",
            "[ Epoch 3913/10000 ] Train Loss: 1.05628   Valid Loss: 0.98912\n",
            "[ Epoch 3914/10000 ] Train Loss: 1.05537   Valid Loss: 0.98778\n",
            "[ Epoch 3915/10000 ] Train Loss: 1.05441   Valid Loss: 0.98729\n",
            "[ Epoch 3916/10000 ] Train Loss: 1.05216   Valid Loss: 0.98634\n",
            "Early Stop Saving Model on Epoch 3916/10000\n",
            "[ Epoch 3917/10000 ] Train Loss: 1.05379   Valid Loss: 0.98769\n",
            "[ Epoch 3918/10000 ] Train Loss: 1.05454   Valid Loss: 0.99031\n",
            "[ Epoch 3919/10000 ] Train Loss: 1.05636   Valid Loss: 0.99309\n",
            "[ Epoch 3920/10000 ] Train Loss: 1.05703   Valid Loss: 0.98791\n",
            "[ Epoch 3921/10000 ] Train Loss: 1.05470   Valid Loss: 0.98559\n",
            "Early Stop Saving Model on Epoch 3921/10000\n",
            "[ Epoch 3922/10000 ] Train Loss: 1.05460   Valid Loss: 0.98803\n",
            "[ Epoch 3923/10000 ] Train Loss: 1.05545   Valid Loss: 0.99062\n",
            "[ Epoch 3924/10000 ] Train Loss: 1.05538   Valid Loss: 0.98542\n",
            "Early Stop Saving Model on Epoch 3924/10000\n",
            "[ Epoch 3925/10000 ] Train Loss: 1.05269   Valid Loss: 0.98762\n",
            "[ Epoch 3926/10000 ] Train Loss: 1.05282   Valid Loss: 0.98953\n",
            "[ Epoch 3927/10000 ] Train Loss: 1.05552   Valid Loss: 0.98719\n",
            "[ Epoch 3928/10000 ] Train Loss: 1.05377   Valid Loss: 0.98656\n",
            "[ Epoch 3929/10000 ] Train Loss: 1.05320   Valid Loss: 0.98604\n",
            "[ Epoch 3930/10000 ] Train Loss: 1.05266   Valid Loss: 0.98680\n",
            "[ Epoch 3931/10000 ] Train Loss: 1.05340   Valid Loss: 0.98775\n",
            "[ Epoch 3932/10000 ] Train Loss: 1.05895   Valid Loss: 0.98555\n",
            "[ Epoch 3933/10000 ] Train Loss: 1.05281   Valid Loss: 0.98886\n",
            "[ Epoch 3934/10000 ] Train Loss: 1.05375   Valid Loss: 0.98934\n",
            "[ Epoch 3935/10000 ] Train Loss: 1.05489   Valid Loss: 0.98659\n",
            "[ Epoch 3936/10000 ] Train Loss: 1.05389   Valid Loss: 0.98623\n",
            "[ Epoch 3937/10000 ] Train Loss: 1.05218   Valid Loss: 0.98713\n",
            "[ Epoch 3938/10000 ] Train Loss: 1.05368   Valid Loss: 0.98726\n",
            "[ Epoch 3939/10000 ] Train Loss: 1.05489   Valid Loss: 0.98629\n",
            "[ Epoch 3940/10000 ] Train Loss: 1.05466   Valid Loss: 0.98717\n",
            "[ Epoch 3941/10000 ] Train Loss: 1.05360   Valid Loss: 0.98561\n",
            "[ Epoch 3942/10000 ] Train Loss: 1.05396   Valid Loss: 0.98716\n",
            "[ Epoch 3943/10000 ] Train Loss: 1.05223   Valid Loss: 0.98726\n",
            "[ Epoch 3944/10000 ] Train Loss: 1.05252   Valid Loss: 0.98542\n",
            "Early Stop Saving Model on Epoch 3944/10000\n",
            "[ Epoch 3945/10000 ] Train Loss: 1.05358   Valid Loss: 0.98600\n",
            "[ Epoch 3946/10000 ] Train Loss: 1.05408   Valid Loss: 0.98999\n",
            "[ Epoch 3947/10000 ] Train Loss: 1.05620   Valid Loss: 0.98805\n",
            "[ Epoch 3948/10000 ] Train Loss: 1.05543   Valid Loss: 0.98667\n",
            "[ Epoch 3949/10000 ] Train Loss: 1.05280   Valid Loss: 0.98605\n",
            "[ Epoch 3950/10000 ] Train Loss: 1.05265   Valid Loss: 0.98679\n",
            "[ Epoch 3951/10000 ] Train Loss: 1.05139   Valid Loss: 0.98581\n",
            "[ Epoch 3952/10000 ] Train Loss: 1.05453   Valid Loss: 0.98612\n",
            "[ Epoch 3953/10000 ] Train Loss: 1.05428   Valid Loss: 0.98824\n",
            "[ Epoch 3954/10000 ] Train Loss: 1.05099   Valid Loss: 0.98730\n",
            "[ Epoch 3955/10000 ] Train Loss: 1.05241   Valid Loss: 0.98504\n",
            "Early Stop Saving Model on Epoch 3955/10000\n",
            "[ Epoch 3956/10000 ] Train Loss: 1.05340   Valid Loss: 0.98723\n",
            "[ Epoch 3957/10000 ] Train Loss: 1.05676   Valid Loss: 0.98894\n",
            "[ Epoch 3958/10000 ] Train Loss: 1.05459   Valid Loss: 0.98539\n",
            "[ Epoch 3959/10000 ] Train Loss: 1.05101   Valid Loss: 0.98506\n",
            "[ Epoch 3960/10000 ] Train Loss: 1.05373   Valid Loss: 0.98861\n",
            "[ Epoch 3961/10000 ] Train Loss: 1.05401   Valid Loss: 0.98457\n",
            "Early Stop Saving Model on Epoch 3961/10000\n",
            "[ Epoch 3962/10000 ] Train Loss: 1.05361   Valid Loss: 0.98729\n",
            "[ Epoch 3963/10000 ] Train Loss: 1.05264   Valid Loss: 0.98678\n",
            "[ Epoch 3964/10000 ] Train Loss: 1.05309   Valid Loss: 0.98587\n",
            "[ Epoch 3965/10000 ] Train Loss: 1.05259   Valid Loss: 0.98719\n",
            "[ Epoch 3966/10000 ] Train Loss: 1.05398   Valid Loss: 0.98947\n",
            "[ Epoch 3967/10000 ] Train Loss: 1.05367   Valid Loss: 0.98465\n",
            "[ Epoch 3968/10000 ] Train Loss: 1.05359   Valid Loss: 0.98868\n",
            "[ Epoch 3969/10000 ] Train Loss: 1.05169   Valid Loss: 0.98867\n",
            "[ Epoch 3970/10000 ] Train Loss: 1.05163   Valid Loss: 0.98605\n",
            "[ Epoch 3971/10000 ] Train Loss: 1.05292   Valid Loss: 0.98574\n",
            "[ Epoch 3972/10000 ] Train Loss: 1.05178   Valid Loss: 0.98462\n",
            "[ Epoch 3973/10000 ] Train Loss: 1.05414   Valid Loss: 0.98661\n",
            "[ Epoch 3974/10000 ] Train Loss: 1.05254   Valid Loss: 0.98689\n",
            "[ Epoch 3975/10000 ] Train Loss: 1.05124   Valid Loss: 0.98553\n",
            "[ Epoch 3976/10000 ] Train Loss: 1.05370   Valid Loss: 0.98533\n",
            "[ Epoch 3977/10000 ] Train Loss: 1.05221   Valid Loss: 0.98535\n",
            "[ Epoch 3978/10000 ] Train Loss: 1.05283   Valid Loss: 0.98590\n",
            "[ Epoch 3979/10000 ] Train Loss: 1.05545   Valid Loss: 0.98689\n",
            "[ Epoch 3980/10000 ] Train Loss: 1.05260   Valid Loss: 0.98616\n",
            "[ Epoch 3981/10000 ] Train Loss: 1.05157   Valid Loss: 0.98573\n",
            "[ Epoch 3982/10000 ] Train Loss: 1.05574   Valid Loss: 0.98594\n",
            "[ Epoch 3983/10000 ] Train Loss: 1.05190   Valid Loss: 0.98494\n",
            "[ Epoch 3984/10000 ] Train Loss: 1.05187   Valid Loss: 0.98508\n",
            "[ Epoch 3985/10000 ] Train Loss: 1.05181   Valid Loss: 0.98608\n",
            "[ Epoch 3986/10000 ] Train Loss: 1.05250   Valid Loss: 0.98560\n",
            "[ Epoch 3987/10000 ] Train Loss: 1.05180   Valid Loss: 0.98517\n",
            "[ Epoch 3988/10000 ] Train Loss: 1.05179   Valid Loss: 0.98626\n",
            "[ Epoch 3989/10000 ] Train Loss: 1.05211   Valid Loss: 0.98652\n",
            "[ Epoch 3990/10000 ] Train Loss: 1.05098   Valid Loss: 0.99305\n",
            "[ Epoch 3991/10000 ] Train Loss: 1.05556   Valid Loss: 0.98725\n",
            "[ Epoch 3992/10000 ] Train Loss: 1.05371   Valid Loss: 0.98480\n",
            "[ Epoch 3993/10000 ] Train Loss: 1.05119   Valid Loss: 0.98507\n",
            "[ Epoch 3994/10000 ] Train Loss: 1.05286   Valid Loss: 0.98823\n",
            "[ Epoch 3995/10000 ] Train Loss: 1.05174   Valid Loss: 0.98755\n",
            "[ Epoch 3996/10000 ] Train Loss: 1.05352   Valid Loss: 0.99264\n",
            "[ Epoch 3997/10000 ] Train Loss: 1.05467   Valid Loss: 0.98657\n",
            "[ Epoch 3998/10000 ] Train Loss: 1.05277   Valid Loss: 0.98459\n",
            "[ Epoch 3999/10000 ] Train Loss: 1.05224   Valid Loss: 0.98600\n",
            "[ Epoch 4000/10000 ] Train Loss: 1.05060   Valid Loss: 0.98521\n",
            "[ Epoch 4001/10000 ] Train Loss: 1.05405   Valid Loss: 0.98802\n",
            "[ Epoch 4002/10000 ] Train Loss: 1.05463   Valid Loss: 0.98856\n",
            "[ Epoch 4003/10000 ] Train Loss: 1.05051   Valid Loss: 0.98523\n",
            "[ Epoch 4004/10000 ] Train Loss: 1.05142   Valid Loss: 0.98631\n",
            "[ Epoch 4005/10000 ] Train Loss: 1.05189   Valid Loss: 0.98374\n",
            "Early Stop Saving Model on Epoch 4005/10000\n",
            "[ Epoch 4006/10000 ] Train Loss: 1.05093   Valid Loss: 0.98626\n",
            "[ Epoch 4007/10000 ] Train Loss: 1.05133   Valid Loss: 0.98604\n",
            "[ Epoch 4008/10000 ] Train Loss: 1.05153   Valid Loss: 0.98504\n",
            "[ Epoch 4009/10000 ] Train Loss: 1.05156   Valid Loss: 0.98399\n",
            "[ Epoch 4010/10000 ] Train Loss: 1.04939   Valid Loss: 0.98495\n",
            "[ Epoch 4011/10000 ] Train Loss: 1.05188   Valid Loss: 0.98645\n",
            "[ Epoch 4012/10000 ] Train Loss: 1.05357   Valid Loss: 0.98426\n",
            "[ Epoch 4013/10000 ] Train Loss: 1.05084   Valid Loss: 0.98530\n",
            "[ Epoch 4014/10000 ] Train Loss: 1.05226   Valid Loss: 0.98510\n",
            "[ Epoch 4015/10000 ] Train Loss: 1.05017   Valid Loss: 0.98588\n",
            "[ Epoch 4016/10000 ] Train Loss: 1.05221   Valid Loss: 0.98474\n",
            "[ Epoch 4017/10000 ] Train Loss: 1.05149   Valid Loss: 0.98626\n",
            "[ Epoch 4018/10000 ] Train Loss: 1.05374   Valid Loss: 0.98430\n",
            "[ Epoch 4019/10000 ] Train Loss: 1.05043   Valid Loss: 0.98443\n",
            "[ Epoch 4020/10000 ] Train Loss: 1.05140   Valid Loss: 0.98412\n",
            "[ Epoch 4021/10000 ] Train Loss: 1.05150   Valid Loss: 0.98415\n",
            "[ Epoch 4022/10000 ] Train Loss: 1.05203   Valid Loss: 0.98380\n",
            "[ Epoch 4023/10000 ] Train Loss: 1.05132   Valid Loss: 0.98618\n",
            "[ Epoch 4024/10000 ] Train Loss: 1.04989   Valid Loss: 0.98593\n",
            "[ Epoch 4025/10000 ] Train Loss: 1.04993   Valid Loss: 0.98839\n",
            "[ Epoch 4026/10000 ] Train Loss: 1.05150   Valid Loss: 0.98366\n",
            "Early Stop Saving Model on Epoch 4026/10000\n",
            "[ Epoch 4027/10000 ] Train Loss: 1.05160   Valid Loss: 0.98464\n",
            "[ Epoch 4028/10000 ] Train Loss: 1.05186   Valid Loss: 0.98649\n",
            "[ Epoch 4029/10000 ] Train Loss: 1.05062   Valid Loss: 0.98355\n",
            "Early Stop Saving Model on Epoch 4029/10000\n",
            "[ Epoch 4030/10000 ] Train Loss: 1.05297   Valid Loss: 0.98444\n",
            "[ Epoch 4031/10000 ] Train Loss: 1.05062   Valid Loss: 0.98606\n",
            "[ Epoch 4032/10000 ] Train Loss: 1.04907   Valid Loss: 0.98461\n",
            "[ Epoch 4033/10000 ] Train Loss: 1.05079   Valid Loss: 0.98326\n",
            "Early Stop Saving Model on Epoch 4033/10000\n",
            "[ Epoch 4034/10000 ] Train Loss: 1.05079   Valid Loss: 0.98361\n",
            "[ Epoch 4035/10000 ] Train Loss: 1.05071   Valid Loss: 0.98487\n",
            "[ Epoch 4036/10000 ] Train Loss: 1.04972   Valid Loss: 0.98563\n",
            "[ Epoch 4037/10000 ] Train Loss: 1.05085   Valid Loss: 0.98426\n",
            "[ Epoch 4038/10000 ] Train Loss: 1.04992   Valid Loss: 0.98632\n",
            "[ Epoch 4039/10000 ] Train Loss: 1.05258   Valid Loss: 0.98381\n",
            "[ Epoch 4040/10000 ] Train Loss: 1.05102   Valid Loss: 0.98351\n",
            "[ Epoch 4041/10000 ] Train Loss: 1.05173   Valid Loss: 0.98692\n",
            "[ Epoch 4042/10000 ] Train Loss: 1.05073   Valid Loss: 0.98427\n",
            "[ Epoch 4043/10000 ] Train Loss: 1.05202   Valid Loss: 0.98409\n",
            "[ Epoch 4044/10000 ] Train Loss: 1.05000   Valid Loss: 0.98431\n",
            "[ Epoch 4045/10000 ] Train Loss: 1.05206   Valid Loss: 0.98296\n",
            "Early Stop Saving Model on Epoch 4045/10000\n",
            "[ Epoch 4046/10000 ] Train Loss: 1.04949   Valid Loss: 0.98394\n",
            "[ Epoch 4047/10000 ] Train Loss: 1.05139   Valid Loss: 0.98227\n",
            "Early Stop Saving Model on Epoch 4047/10000\n",
            "[ Epoch 4048/10000 ] Train Loss: 1.04971   Valid Loss: 0.98448\n",
            "[ Epoch 4049/10000 ] Train Loss: 1.05193   Valid Loss: 0.98344\n",
            "[ Epoch 4050/10000 ] Train Loss: 1.05390   Valid Loss: 0.98846\n",
            "[ Epoch 4051/10000 ] Train Loss: 1.05127   Valid Loss: 0.98707\n",
            "[ Epoch 4052/10000 ] Train Loss: 1.05213   Valid Loss: 0.98398\n",
            "[ Epoch 4053/10000 ] Train Loss: 1.05257   Valid Loss: 0.98540\n",
            "[ Epoch 4054/10000 ] Train Loss: 1.04814   Valid Loss: 0.98457\n",
            "[ Epoch 4055/10000 ] Train Loss: 1.05189   Valid Loss: 0.98338\n",
            "[ Epoch 4056/10000 ] Train Loss: 1.05077   Valid Loss: 0.98360\n",
            "[ Epoch 4057/10000 ] Train Loss: 1.04996   Valid Loss: 0.98406\n",
            "[ Epoch 4058/10000 ] Train Loss: 1.05129   Valid Loss: 0.98844\n",
            "[ Epoch 4059/10000 ] Train Loss: 1.05409   Valid Loss: 0.99353\n",
            "[ Epoch 4060/10000 ] Train Loss: 1.05811   Valid Loss: 0.98397\n",
            "[ Epoch 4061/10000 ] Train Loss: 1.05232   Valid Loss: 0.98539\n",
            "[ Epoch 4062/10000 ] Train Loss: 1.05545   Valid Loss: 0.98603\n",
            "[ Epoch 4063/10000 ] Train Loss: 1.05087   Valid Loss: 0.98287\n",
            "[ Epoch 4064/10000 ] Train Loss: 1.04980   Valid Loss: 0.98329\n",
            "[ Epoch 4065/10000 ] Train Loss: 1.05015   Valid Loss: 0.98372\n",
            "[ Epoch 4066/10000 ] Train Loss: 1.05050   Valid Loss: 0.98419\n",
            "[ Epoch 4067/10000 ] Train Loss: 1.04977   Valid Loss: 0.98282\n",
            "[ Epoch 4068/10000 ] Train Loss: 1.05054   Valid Loss: 0.98453\n",
            "[ Epoch 4069/10000 ] Train Loss: 1.05058   Valid Loss: 0.98405\n",
            "[ Epoch 4070/10000 ] Train Loss: 1.05030   Valid Loss: 0.98742\n",
            "[ Epoch 4071/10000 ] Train Loss: 1.04963   Valid Loss: 0.98625\n",
            "[ Epoch 4072/10000 ] Train Loss: 1.04907   Valid Loss: 0.98401\n",
            "[ Epoch 4073/10000 ] Train Loss: 1.05117   Valid Loss: 0.98563\n",
            "[ Epoch 4074/10000 ] Train Loss: 1.05213   Valid Loss: 0.98209\n",
            "Early Stop Saving Model on Epoch 4074/10000\n",
            "[ Epoch 4075/10000 ] Train Loss: 1.04931   Valid Loss: 0.98369\n",
            "[ Epoch 4076/10000 ] Train Loss: 1.04919   Valid Loss: 0.98563\n",
            "[ Epoch 4077/10000 ] Train Loss: 1.05103   Valid Loss: 0.98645\n",
            "[ Epoch 4078/10000 ] Train Loss: 1.05209   Valid Loss: 0.98425\n",
            "[ Epoch 4079/10000 ] Train Loss: 1.04991   Valid Loss: 0.98286\n",
            "[ Epoch 4080/10000 ] Train Loss: 1.05064   Valid Loss: 0.98314\n",
            "[ Epoch 4081/10000 ] Train Loss: 1.05050   Valid Loss: 0.98360\n",
            "[ Epoch 4082/10000 ] Train Loss: 1.05174   Valid Loss: 0.98456\n",
            "[ Epoch 4083/10000 ] Train Loss: 1.05253   Valid Loss: 0.98468\n",
            "[ Epoch 4084/10000 ] Train Loss: 1.05082   Valid Loss: 0.98443\n",
            "[ Epoch 4085/10000 ] Train Loss: 1.05047   Valid Loss: 0.98338\n",
            "[ Epoch 4086/10000 ] Train Loss: 1.04901   Valid Loss: 0.98309\n",
            "[ Epoch 4087/10000 ] Train Loss: 1.04814   Valid Loss: 0.98295\n",
            "[ Epoch 4088/10000 ] Train Loss: 1.05062   Valid Loss: 0.98120\n",
            "Early Stop Saving Model on Epoch 4088/10000\n",
            "[ Epoch 4089/10000 ] Train Loss: 1.04968   Valid Loss: 0.98438\n",
            "[ Epoch 4090/10000 ] Train Loss: 1.04746   Valid Loss: 0.98242\n",
            "[ Epoch 4091/10000 ] Train Loss: 1.05192   Valid Loss: 0.98579\n",
            "[ Epoch 4092/10000 ] Train Loss: 1.05436   Valid Loss: 0.98550\n",
            "[ Epoch 4093/10000 ] Train Loss: 1.05009   Valid Loss: 0.98308\n",
            "[ Epoch 4094/10000 ] Train Loss: 1.05000   Valid Loss: 0.98164\n",
            "[ Epoch 4095/10000 ] Train Loss: 1.04736   Valid Loss: 0.98221\n",
            "[ Epoch 4096/10000 ] Train Loss: 1.05069   Valid Loss: 0.98362\n",
            "[ Epoch 4097/10000 ] Train Loss: 1.04957   Valid Loss: 0.98574\n",
            "[ Epoch 4098/10000 ] Train Loss: 1.04989   Valid Loss: 0.98247\n",
            "[ Epoch 4099/10000 ] Train Loss: 1.05020   Valid Loss: 0.98137\n",
            "[ Epoch 4100/10000 ] Train Loss: 1.04990   Valid Loss: 0.98484\n",
            "[ Epoch 4101/10000 ] Train Loss: 1.05005   Valid Loss: 0.98187\n",
            "[ Epoch 4102/10000 ] Train Loss: 1.04903   Valid Loss: 0.98352\n",
            "[ Epoch 4103/10000 ] Train Loss: 1.04939   Valid Loss: 0.98289\n",
            "[ Epoch 4104/10000 ] Train Loss: 1.04927   Valid Loss: 0.98217\n",
            "[ Epoch 4105/10000 ] Train Loss: 1.04997   Valid Loss: 0.98360\n",
            "[ Epoch 4106/10000 ] Train Loss: 1.05027   Valid Loss: 0.98223\n",
            "[ Epoch 4107/10000 ] Train Loss: 1.04930   Valid Loss: 0.98112\n",
            "Early Stop Saving Model on Epoch 4107/10000\n",
            "[ Epoch 4108/10000 ] Train Loss: 1.04983   Valid Loss: 0.98266\n",
            "[ Epoch 4109/10000 ] Train Loss: 1.04845   Valid Loss: 0.98535\n",
            "[ Epoch 4110/10000 ] Train Loss: 1.04970   Valid Loss: 0.98954\n",
            "[ Epoch 4111/10000 ] Train Loss: 1.05235   Valid Loss: 0.98376\n",
            "[ Epoch 4112/10000 ] Train Loss: 1.04933   Valid Loss: 0.98396\n",
            "[ Epoch 4113/10000 ] Train Loss: 1.04841   Valid Loss: 0.98170\n",
            "[ Epoch 4114/10000 ] Train Loss: 1.05069   Valid Loss: 0.98305\n",
            "[ Epoch 4115/10000 ] Train Loss: 1.04859   Valid Loss: 0.98253\n",
            "[ Epoch 4116/10000 ] Train Loss: 1.05054   Valid Loss: 0.98297\n",
            "[ Epoch 4117/10000 ] Train Loss: 1.05030   Valid Loss: 0.98404\n",
            "[ Epoch 4118/10000 ] Train Loss: 1.04767   Valid Loss: 0.98408\n",
            "[ Epoch 4119/10000 ] Train Loss: 1.05018   Valid Loss: 0.98215\n",
            "[ Epoch 4120/10000 ] Train Loss: 1.05123   Valid Loss: 0.98429\n",
            "[ Epoch 4121/10000 ] Train Loss: 1.05083   Valid Loss: 0.98044\n",
            "Early Stop Saving Model on Epoch 4121/10000\n",
            "[ Epoch 4122/10000 ] Train Loss: 1.04774   Valid Loss: 0.98191\n",
            "[ Epoch 4123/10000 ] Train Loss: 1.04704   Valid Loss: 0.98368\n",
            "[ Epoch 4124/10000 ] Train Loss: 1.04944   Valid Loss: 0.98306\n",
            "[ Epoch 4125/10000 ] Train Loss: 1.04941   Valid Loss: 0.98090\n",
            "[ Epoch 4126/10000 ] Train Loss: 1.04849   Valid Loss: 0.98401\n",
            "[ Epoch 4127/10000 ] Train Loss: 1.04964   Valid Loss: 0.98194\n",
            "[ Epoch 4128/10000 ] Train Loss: 1.04835   Valid Loss: 0.98132\n",
            "[ Epoch 4129/10000 ] Train Loss: 1.04775   Valid Loss: 0.98118\n",
            "[ Epoch 4130/10000 ] Train Loss: 1.04733   Valid Loss: 0.98546\n",
            "[ Epoch 4131/10000 ] Train Loss: 1.04950   Valid Loss: 0.98327\n",
            "[ Epoch 4132/10000 ] Train Loss: 1.05076   Valid Loss: 0.98064\n",
            "[ Epoch 4133/10000 ] Train Loss: 1.04889   Valid Loss: 0.98299\n",
            "[ Epoch 4134/10000 ] Train Loss: 1.04762   Valid Loss: 0.98122\n",
            "[ Epoch 4135/10000 ] Train Loss: 1.04814   Valid Loss: 0.98306\n",
            "[ Epoch 4136/10000 ] Train Loss: 1.05092   Valid Loss: 0.98504\n",
            "[ Epoch 4137/10000 ] Train Loss: 1.04771   Valid Loss: 0.98069\n",
            "[ Epoch 4138/10000 ] Train Loss: 1.04923   Valid Loss: 0.98114\n",
            "[ Epoch 4139/10000 ] Train Loss: 1.05155   Valid Loss: 0.98486\n",
            "[ Epoch 4140/10000 ] Train Loss: 1.06013   Valid Loss: 0.98712\n",
            "[ Epoch 4141/10000 ] Train Loss: 1.04717   Valid Loss: 0.98933\n",
            "[ Epoch 4142/10000 ] Train Loss: 1.05018   Valid Loss: 0.98106\n",
            "[ Epoch 4143/10000 ] Train Loss: 1.04968   Valid Loss: 0.98158\n",
            "[ Epoch 4144/10000 ] Train Loss: 1.04848   Valid Loss: 0.98107\n",
            "[ Epoch 4145/10000 ] Train Loss: 1.04696   Valid Loss: 0.98145\n",
            "[ Epoch 4146/10000 ] Train Loss: 1.04877   Valid Loss: 0.98129\n",
            "[ Epoch 4147/10000 ] Train Loss: 1.04911   Valid Loss: 0.98091\n",
            "[ Epoch 4148/10000 ] Train Loss: 1.04925   Valid Loss: 0.98114\n",
            "[ Epoch 4149/10000 ] Train Loss: 1.04778   Valid Loss: 0.98184\n",
            "[ Epoch 4150/10000 ] Train Loss: 1.04825   Valid Loss: 0.98140\n",
            "[ Epoch 4151/10000 ] Train Loss: 1.04843   Valid Loss: 0.98161\n",
            "[ Epoch 4152/10000 ] Train Loss: 1.04756   Valid Loss: 0.98040\n",
            "Early Stop Saving Model on Epoch 4152/10000\n",
            "[ Epoch 4153/10000 ] Train Loss: 1.04861   Valid Loss: 0.98160\n",
            "[ Epoch 4154/10000 ] Train Loss: 1.04812   Valid Loss: 0.97967\n",
            "Early Stop Saving Model on Epoch 4154/10000\n",
            "[ Epoch 4155/10000 ] Train Loss: 1.05133   Valid Loss: 0.98259\n",
            "[ Epoch 4156/10000 ] Train Loss: 1.04781   Valid Loss: 0.98177\n",
            "[ Epoch 4157/10000 ] Train Loss: 1.04836   Valid Loss: 0.98079\n",
            "[ Epoch 4158/10000 ] Train Loss: 1.04771   Valid Loss: 0.97947\n",
            "Early Stop Saving Model on Epoch 4158/10000\n",
            "[ Epoch 4159/10000 ] Train Loss: 1.04746   Valid Loss: 0.97933\n",
            "Early Stop Saving Model on Epoch 4159/10000\n",
            "[ Epoch 4160/10000 ] Train Loss: 1.04973   Valid Loss: 0.98248\n",
            "[ Epoch 4161/10000 ] Train Loss: 1.04907   Valid Loss: 0.98053\n",
            "[ Epoch 4162/10000 ] Train Loss: 1.04838   Valid Loss: 0.98052\n",
            "[ Epoch 4163/10000 ] Train Loss: 1.04743   Valid Loss: 0.98164\n",
            "[ Epoch 4164/10000 ] Train Loss: 1.04806   Valid Loss: 0.98052\n",
            "[ Epoch 4165/10000 ] Train Loss: 1.04772   Valid Loss: 0.97990\n",
            "[ Epoch 4166/10000 ] Train Loss: 1.04817   Valid Loss: 0.98179\n",
            "[ Epoch 4167/10000 ] Train Loss: 1.05001   Valid Loss: 0.98573\n",
            "[ Epoch 4168/10000 ] Train Loss: 1.05049   Valid Loss: 0.97939\n",
            "[ Epoch 4169/10000 ] Train Loss: 1.04778   Valid Loss: 0.98007\n",
            "[ Epoch 4170/10000 ] Train Loss: 1.04793   Valid Loss: 0.98232\n",
            "[ Epoch 4171/10000 ] Train Loss: 1.04820   Valid Loss: 0.98055\n",
            "[ Epoch 4172/10000 ] Train Loss: 1.04847   Valid Loss: 0.98283\n",
            "[ Epoch 4173/10000 ] Train Loss: 1.04992   Valid Loss: 0.97977\n",
            "[ Epoch 4174/10000 ] Train Loss: 1.04785   Valid Loss: 0.98187\n",
            "[ Epoch 4175/10000 ] Train Loss: 1.04772   Valid Loss: 0.98004\n",
            "[ Epoch 4176/10000 ] Train Loss: 1.04632   Valid Loss: 0.98036\n",
            "[ Epoch 4177/10000 ] Train Loss: 1.04949   Valid Loss: 0.98280\n",
            "[ Epoch 4178/10000 ] Train Loss: 1.05125   Valid Loss: 0.98199\n",
            "[ Epoch 4179/10000 ] Train Loss: 1.04915   Valid Loss: 0.98301\n",
            "[ Epoch 4180/10000 ] Train Loss: 1.04909   Valid Loss: 0.97913\n",
            "Early Stop Saving Model on Epoch 4180/10000\n",
            "[ Epoch 4181/10000 ] Train Loss: 1.04674   Valid Loss: 0.98104\n",
            "[ Epoch 4182/10000 ] Train Loss: 1.04597   Valid Loss: 0.97980\n",
            "[ Epoch 4183/10000 ] Train Loss: 1.04809   Valid Loss: 0.98079\n",
            "[ Epoch 4184/10000 ] Train Loss: 1.04858   Valid Loss: 0.98442\n",
            "[ Epoch 4185/10000 ] Train Loss: 1.04712   Valid Loss: 0.98019\n",
            "[ Epoch 4186/10000 ] Train Loss: 1.04869   Valid Loss: 0.98078\n",
            "[ Epoch 4187/10000 ] Train Loss: 1.04599   Valid Loss: 0.98012\n",
            "[ Epoch 4188/10000 ] Train Loss: 1.04879   Valid Loss: 0.98029\n",
            "[ Epoch 4189/10000 ] Train Loss: 1.04750   Valid Loss: 0.98323\n",
            "[ Epoch 4190/10000 ] Train Loss: 1.05027   Valid Loss: 0.98007\n",
            "[ Epoch 4191/10000 ] Train Loss: 1.05250   Valid Loss: 0.98678\n",
            "[ Epoch 4192/10000 ] Train Loss: 1.04874   Valid Loss: 0.98137\n",
            "[ Epoch 4193/10000 ] Train Loss: 1.04762   Valid Loss: 0.97967\n",
            "[ Epoch 4194/10000 ] Train Loss: 1.04494   Valid Loss: 0.97935\n",
            "[ Epoch 4195/10000 ] Train Loss: 1.04701   Valid Loss: 0.97919\n",
            "[ Epoch 4196/10000 ] Train Loss: 1.04596   Valid Loss: 0.98016\n",
            "[ Epoch 4197/10000 ] Train Loss: 1.04833   Valid Loss: 0.98040\n",
            "[ Epoch 4198/10000 ] Train Loss: 1.04809   Valid Loss: 0.97970\n",
            "[ Epoch 4199/10000 ] Train Loss: 1.04894   Valid Loss: 0.98256\n",
            "[ Epoch 4200/10000 ] Train Loss: 1.04774   Valid Loss: 0.97944\n",
            "[ Epoch 4201/10000 ] Train Loss: 1.04715   Valid Loss: 0.98209\n",
            "[ Epoch 4202/10000 ] Train Loss: 1.04763   Valid Loss: 0.98080\n",
            "[ Epoch 4203/10000 ] Train Loss: 1.04445   Valid Loss: 0.97997\n",
            "[ Epoch 4204/10000 ] Train Loss: 1.04884   Valid Loss: 0.98020\n",
            "[ Epoch 4205/10000 ] Train Loss: 1.04830   Valid Loss: 0.97963\n",
            "[ Epoch 4206/10000 ] Train Loss: 1.04533   Valid Loss: 0.97945\n",
            "[ Epoch 4207/10000 ] Train Loss: 1.04617   Valid Loss: 0.98068\n",
            "[ Epoch 4208/10000 ] Train Loss: 1.04660   Valid Loss: 0.97957\n",
            "[ Epoch 4209/10000 ] Train Loss: 1.04719   Valid Loss: 0.97922\n",
            "[ Epoch 4210/10000 ] Train Loss: 1.04670   Valid Loss: 0.98196\n",
            "[ Epoch 4211/10000 ] Train Loss: 1.04985   Valid Loss: 0.98310\n",
            "[ Epoch 4212/10000 ] Train Loss: 1.05142   Valid Loss: 0.98291\n",
            "[ Epoch 4213/10000 ] Train Loss: 1.04800   Valid Loss: 0.98002\n",
            "[ Epoch 4214/10000 ] Train Loss: 1.04693   Valid Loss: 0.98145\n",
            "[ Epoch 4215/10000 ] Train Loss: 1.04664   Valid Loss: 0.97736\n",
            "Early Stop Saving Model on Epoch 4215/10000\n",
            "[ Epoch 4216/10000 ] Train Loss: 1.04687   Valid Loss: 0.98019\n",
            "[ Epoch 4217/10000 ] Train Loss: 1.04659   Valid Loss: 0.98776\n",
            "[ Epoch 4218/10000 ] Train Loss: 1.05243   Valid Loss: 0.98909\n",
            "[ Epoch 4219/10000 ] Train Loss: 1.04830   Valid Loss: 0.98193\n",
            "[ Epoch 4220/10000 ] Train Loss: 1.04564   Valid Loss: 0.97940\n",
            "[ Epoch 4221/10000 ] Train Loss: 1.04647   Valid Loss: 0.98047\n",
            "[ Epoch 4222/10000 ] Train Loss: 1.04725   Valid Loss: 0.97997\n",
            "[ Epoch 4223/10000 ] Train Loss: 1.04717   Valid Loss: 0.97853\n",
            "[ Epoch 4224/10000 ] Train Loss: 1.04605   Valid Loss: 0.98022\n",
            "[ Epoch 4225/10000 ] Train Loss: 1.04693   Valid Loss: 0.97946\n",
            "[ Epoch 4226/10000 ] Train Loss: 1.04666   Valid Loss: 0.98175\n",
            "[ Epoch 4227/10000 ] Train Loss: 1.04674   Valid Loss: 0.97986\n",
            "[ Epoch 4228/10000 ] Train Loss: 1.04745   Valid Loss: 0.97935\n",
            "[ Epoch 4229/10000 ] Train Loss: 1.04569   Valid Loss: 0.97882\n",
            "[ Epoch 4230/10000 ] Train Loss: 1.04721   Valid Loss: 0.98113\n",
            "[ Epoch 4231/10000 ] Train Loss: 1.04960   Valid Loss: 0.98187\n",
            "[ Epoch 4232/10000 ] Train Loss: 1.04916   Valid Loss: 0.98050\n",
            "[ Epoch 4233/10000 ] Train Loss: 1.04759   Valid Loss: 0.97976\n",
            "[ Epoch 4234/10000 ] Train Loss: 1.04851   Valid Loss: 0.97993\n",
            "[ Epoch 4235/10000 ] Train Loss: 1.04568   Valid Loss: 0.97898\n",
            "[ Epoch 4236/10000 ] Train Loss: 1.04609   Valid Loss: 0.97810\n",
            "[ Epoch 4237/10000 ] Train Loss: 1.04566   Valid Loss: 0.97989\n",
            "[ Epoch 4238/10000 ] Train Loss: 1.04637   Valid Loss: 0.97900\n",
            "[ Epoch 4239/10000 ] Train Loss: 1.04630   Valid Loss: 0.97816\n",
            "[ Epoch 4240/10000 ] Train Loss: 1.04735   Valid Loss: 0.97947\n",
            "[ Epoch 4241/10000 ] Train Loss: 1.04544   Valid Loss: 0.97843\n",
            "[ Epoch 4242/10000 ] Train Loss: 1.04714   Valid Loss: 0.97943\n",
            "[ Epoch 4243/10000 ] Train Loss: 1.04516   Valid Loss: 0.97993\n",
            "[ Epoch 4244/10000 ] Train Loss: 1.04735   Valid Loss: 0.98020\n",
            "[ Epoch 4245/10000 ] Train Loss: 1.04702   Valid Loss: 0.97979\n",
            "[ Epoch 4246/10000 ] Train Loss: 1.04681   Valid Loss: 0.98097\n",
            "[ Epoch 4247/10000 ] Train Loss: 1.04682   Valid Loss: 0.97771\n",
            "[ Epoch 4248/10000 ] Train Loss: 1.04589   Valid Loss: 0.97781\n",
            "[ Epoch 4249/10000 ] Train Loss: 1.04454   Valid Loss: 0.97792\n",
            "[ Epoch 4250/10000 ] Train Loss: 1.04757   Valid Loss: 0.97849\n",
            "[ Epoch 4251/10000 ] Train Loss: 1.04832   Valid Loss: 0.97795\n",
            "[ Epoch 4252/10000 ] Train Loss: 1.04650   Valid Loss: 0.97870\n",
            "[ Epoch 4253/10000 ] Train Loss: 1.04571   Valid Loss: 0.97881\n",
            "[ Epoch 4254/10000 ] Train Loss: 1.04690   Valid Loss: 0.97827\n",
            "[ Epoch 4255/10000 ] Train Loss: 1.04571   Valid Loss: 0.97761\n",
            "[ Epoch 4256/10000 ] Train Loss: 1.04338   Valid Loss: 0.97964\n",
            "[ Epoch 4257/10000 ] Train Loss: 1.04298   Valid Loss: 0.97983\n",
            "[ Epoch 4258/10000 ] Train Loss: 1.04637   Valid Loss: 0.98244\n",
            "[ Epoch 4259/10000 ] Train Loss: 1.04682   Valid Loss: 0.97856\n",
            "[ Epoch 4260/10000 ] Train Loss: 1.04848   Valid Loss: 0.98323\n",
            "[ Epoch 4261/10000 ] Train Loss: 1.04942   Valid Loss: 0.99082\n",
            "[ Epoch 4262/10000 ] Train Loss: 1.05046   Valid Loss: 0.98068\n",
            "[ Epoch 4263/10000 ] Train Loss: 1.04383   Valid Loss: 0.97913\n",
            "[ Epoch 4264/10000 ] Train Loss: 1.04430   Valid Loss: 0.97779\n",
            "[ Epoch 4265/10000 ] Train Loss: 1.04526   Valid Loss: 0.97770\n",
            "[ Epoch 4266/10000 ] Train Loss: 1.04641   Valid Loss: 0.98016\n",
            "[ Epoch 4267/10000 ] Train Loss: 1.04585   Valid Loss: 0.97808\n",
            "[ Epoch 4268/10000 ] Train Loss: 1.04603   Valid Loss: 0.97982\n",
            "[ Epoch 4269/10000 ] Train Loss: 1.04662   Valid Loss: 0.97847\n",
            "[ Epoch 4270/10000 ] Train Loss: 1.04703   Valid Loss: 0.98096\n",
            "[ Epoch 4271/10000 ] Train Loss: 1.04789   Valid Loss: 0.97930\n",
            "[ Epoch 4272/10000 ] Train Loss: 1.04694   Valid Loss: 0.97930\n",
            "[ Epoch 4273/10000 ] Train Loss: 1.04733   Valid Loss: 0.98236\n",
            "[ Epoch 4274/10000 ] Train Loss: 1.04560   Valid Loss: 0.98191\n",
            "[ Epoch 4275/10000 ] Train Loss: 1.04858   Valid Loss: 0.97834\n",
            "[ Epoch 4276/10000 ] Train Loss: 1.04612   Valid Loss: 0.97842\n",
            "[ Epoch 4277/10000 ] Train Loss: 1.04657   Valid Loss: 0.97952\n",
            "[ Epoch 4278/10000 ] Train Loss: 1.04532   Valid Loss: 0.98095\n",
            "[ Epoch 4279/10000 ] Train Loss: 1.04667   Valid Loss: 0.98435\n",
            "[ Epoch 4280/10000 ] Train Loss: 1.04913   Valid Loss: 0.98498\n",
            "[ Epoch 4281/10000 ] Train Loss: 1.04942   Valid Loss: 0.97873\n",
            "[ Epoch 4282/10000 ] Train Loss: 1.04688   Valid Loss: 0.97981\n",
            "[ Epoch 4283/10000 ] Train Loss: 1.04557   Valid Loss: 0.97715\n",
            "Early Stop Saving Model on Epoch 4283/10000\n",
            "[ Epoch 4284/10000 ] Train Loss: 1.04475   Valid Loss: 0.98121\n",
            "[ Epoch 4285/10000 ] Train Loss: 1.04697   Valid Loss: 0.98100\n",
            "[ Epoch 4286/10000 ] Train Loss: 1.04776   Valid Loss: 0.97864\n",
            "[ Epoch 4287/10000 ] Train Loss: 1.04669   Valid Loss: 0.98112\n",
            "[ Epoch 4288/10000 ] Train Loss: 1.04558   Valid Loss: 0.97837\n",
            "[ Epoch 4289/10000 ] Train Loss: 1.04479   Valid Loss: 0.97823\n",
            "[ Epoch 4290/10000 ] Train Loss: 1.04390   Valid Loss: 0.97937\n",
            "[ Epoch 4291/10000 ] Train Loss: 1.04700   Valid Loss: 0.97796\n",
            "[ Epoch 4292/10000 ] Train Loss: 1.04802   Valid Loss: 0.97983\n",
            "[ Epoch 4293/10000 ] Train Loss: 1.04647   Valid Loss: 0.97853\n",
            "[ Epoch 4294/10000 ] Train Loss: 1.04392   Valid Loss: 0.97770\n",
            "[ Epoch 4295/10000 ] Train Loss: 1.04533   Valid Loss: 0.97775\n",
            "[ Epoch 4296/10000 ] Train Loss: 1.04410   Valid Loss: 0.97861\n",
            "[ Epoch 4297/10000 ] Train Loss: 1.04871   Valid Loss: 0.98124\n",
            "[ Epoch 4298/10000 ] Train Loss: 1.04637   Valid Loss: 0.97767\n",
            "[ Epoch 4299/10000 ] Train Loss: 1.04586   Valid Loss: 0.97795\n",
            "[ Epoch 4300/10000 ] Train Loss: 1.04657   Valid Loss: 0.97790\n",
            "[ Epoch 4301/10000 ] Train Loss: 1.04520   Valid Loss: 0.97881\n",
            "[ Epoch 4302/10000 ] Train Loss: 1.04419   Valid Loss: 0.97824\n",
            "[ Epoch 4303/10000 ] Train Loss: 1.04612   Valid Loss: 0.97907\n",
            "[ Epoch 4304/10000 ] Train Loss: 1.04679   Valid Loss: 0.98394\n",
            "[ Epoch 4305/10000 ] Train Loss: 1.04560   Valid Loss: 0.98115\n",
            "[ Epoch 4306/10000 ] Train Loss: 1.04758   Valid Loss: 0.98206\n",
            "[ Epoch 4307/10000 ] Train Loss: 1.04804   Valid Loss: 0.97780\n",
            "[ Epoch 4308/10000 ] Train Loss: 1.04610   Valid Loss: 0.98017\n",
            "[ Epoch 4309/10000 ] Train Loss: 1.04557   Valid Loss: 0.98250\n",
            "[ Epoch 4310/10000 ] Train Loss: 1.05149   Valid Loss: 0.97898\n",
            "[ Epoch 4311/10000 ] Train Loss: 1.04855   Valid Loss: 0.98029\n",
            "[ Epoch 4312/10000 ] Train Loss: 1.05237   Valid Loss: 0.98492\n",
            "[ Epoch 4313/10000 ] Train Loss: 1.04802   Valid Loss: 0.97789\n",
            "[ Epoch 4314/10000 ] Train Loss: 1.04631   Valid Loss: 0.97863\n",
            "[ Epoch 4315/10000 ] Train Loss: 1.04590   Valid Loss: 0.98319\n",
            "[ Epoch 4316/10000 ] Train Loss: 1.04687   Valid Loss: 0.98234\n",
            "[ Epoch 4317/10000 ] Train Loss: 1.04491   Valid Loss: 0.97863\n",
            "[ Epoch 4318/10000 ] Train Loss: 1.04715   Valid Loss: 0.97873\n",
            "[ Epoch 4319/10000 ] Train Loss: 1.04561   Valid Loss: 0.97693\n",
            "Early Stop Saving Model on Epoch 4319/10000\n",
            "[ Epoch 4320/10000 ] Train Loss: 1.04601   Valid Loss: 0.97805\n",
            "[ Epoch 4321/10000 ] Train Loss: 1.04457   Valid Loss: 0.98109\n",
            "[ Epoch 4322/10000 ] Train Loss: 1.04484   Valid Loss: 0.97640\n",
            "Early Stop Saving Model on Epoch 4322/10000\n",
            "[ Epoch 4323/10000 ] Train Loss: 1.04529   Valid Loss: 0.97774\n",
            "[ Epoch 4324/10000 ] Train Loss: 1.04388   Valid Loss: 0.97893\n",
            "[ Epoch 4325/10000 ] Train Loss: 1.04545   Valid Loss: 0.97727\n",
            "[ Epoch 4326/10000 ] Train Loss: 1.04538   Valid Loss: 0.97738\n",
            "[ Epoch 4327/10000 ] Train Loss: 1.04459   Valid Loss: 0.98099\n",
            "[ Epoch 4328/10000 ] Train Loss: 1.04748   Valid Loss: 0.97651\n",
            "[ Epoch 4329/10000 ] Train Loss: 1.04338   Valid Loss: 0.97834\n",
            "[ Epoch 4330/10000 ] Train Loss: 1.04441   Valid Loss: 0.97741\n",
            "[ Epoch 4331/10000 ] Train Loss: 1.04643   Valid Loss: 0.97770\n",
            "[ Epoch 4332/10000 ] Train Loss: 1.04521   Valid Loss: 0.97785\n",
            "[ Epoch 4333/10000 ] Train Loss: 1.04760   Valid Loss: 0.98153\n",
            "[ Epoch 4334/10000 ] Train Loss: 1.04869   Valid Loss: 0.97844\n",
            "[ Epoch 4335/10000 ] Train Loss: 1.04510   Valid Loss: 0.97718\n",
            "[ Epoch 4336/10000 ] Train Loss: 1.04529   Valid Loss: 0.97755\n",
            "[ Epoch 4337/10000 ] Train Loss: 1.04648   Valid Loss: 0.98348\n",
            "[ Epoch 4338/10000 ] Train Loss: 1.04785   Valid Loss: 0.97965\n",
            "[ Epoch 4339/10000 ] Train Loss: 1.04387   Valid Loss: 0.97772\n",
            "[ Epoch 4340/10000 ] Train Loss: 1.04475   Valid Loss: 0.97707\n",
            "[ Epoch 4341/10000 ] Train Loss: 1.04467   Valid Loss: 0.97716\n",
            "[ Epoch 4342/10000 ] Train Loss: 1.04573   Valid Loss: 0.97917\n",
            "[ Epoch 4343/10000 ] Train Loss: 1.04488   Valid Loss: 0.97810\n",
            "[ Epoch 4344/10000 ] Train Loss: 1.04557   Valid Loss: 0.97734\n",
            "[ Epoch 4345/10000 ] Train Loss: 1.04286   Valid Loss: 0.97861\n",
            "[ Epoch 4346/10000 ] Train Loss: 1.04419   Valid Loss: 0.97765\n",
            "[ Epoch 4347/10000 ] Train Loss: 1.04672   Valid Loss: 0.97771\n",
            "[ Epoch 4348/10000 ] Train Loss: 1.04454   Valid Loss: 0.97890\n",
            "[ Epoch 4349/10000 ] Train Loss: 1.04519   Valid Loss: 0.98020\n",
            "[ Epoch 4350/10000 ] Train Loss: 1.04597   Valid Loss: 0.97615\n",
            "Early Stop Saving Model on Epoch 4350/10000\n",
            "[ Epoch 4351/10000 ] Train Loss: 1.04441   Valid Loss: 0.97795\n",
            "[ Epoch 4352/10000 ] Train Loss: 1.04751   Valid Loss: 0.97923\n",
            "[ Epoch 4353/10000 ] Train Loss: 1.04766   Valid Loss: 0.97794\n",
            "[ Epoch 4354/10000 ] Train Loss: 1.04561   Valid Loss: 0.98253\n",
            "[ Epoch 4355/10000 ] Train Loss: 1.04795   Valid Loss: 0.98260\n",
            "[ Epoch 4356/10000 ] Train Loss: 1.04868   Valid Loss: 0.97676\n",
            "[ Epoch 4357/10000 ] Train Loss: 1.04818   Valid Loss: 0.98257\n",
            "[ Epoch 4358/10000 ] Train Loss: 1.04792   Valid Loss: 0.98052\n",
            "[ Epoch 4359/10000 ] Train Loss: 1.04839   Valid Loss: 0.97756\n",
            "[ Epoch 4360/10000 ] Train Loss: 1.04684   Valid Loss: 0.97799\n",
            "[ Epoch 4361/10000 ] Train Loss: 1.04280   Valid Loss: 0.97668\n",
            "[ Epoch 4362/10000 ] Train Loss: 1.04540   Valid Loss: 0.97793\n",
            "[ Epoch 4363/10000 ] Train Loss: 1.04372   Valid Loss: 0.97776\n",
            "[ Epoch 4364/10000 ] Train Loss: 1.04267   Valid Loss: 0.97796\n",
            "[ Epoch 4365/10000 ] Train Loss: 1.04568   Valid Loss: 0.97676\n",
            "[ Epoch 4366/10000 ] Train Loss: 1.04662   Valid Loss: 0.97694\n",
            "[ Epoch 4367/10000 ] Train Loss: 1.04449   Valid Loss: 0.97696\n",
            "[ Epoch 4368/10000 ] Train Loss: 1.04373   Valid Loss: 0.97774\n",
            "[ Epoch 4369/10000 ] Train Loss: 1.04523   Valid Loss: 0.97700\n",
            "[ Epoch 4370/10000 ] Train Loss: 1.04211   Valid Loss: 0.97812\n",
            "[ Epoch 4371/10000 ] Train Loss: 1.04685   Valid Loss: 0.97758\n",
            "[ Epoch 4372/10000 ] Train Loss: 1.04455   Valid Loss: 0.97774\n",
            "[ Epoch 4373/10000 ] Train Loss: 1.04377   Valid Loss: 0.97602\n",
            "Early Stop Saving Model on Epoch 4373/10000\n",
            "[ Epoch 4374/10000 ] Train Loss: 1.04354   Valid Loss: 0.97703\n",
            "[ Epoch 4375/10000 ] Train Loss: 1.04431   Valid Loss: 0.97807\n",
            "[ Epoch 4376/10000 ] Train Loss: 1.04633   Valid Loss: 0.97641\n",
            "[ Epoch 4377/10000 ] Train Loss: 1.04610   Valid Loss: 0.98176\n",
            "[ Epoch 4378/10000 ] Train Loss: 1.05054   Valid Loss: 0.97625\n",
            "[ Epoch 4379/10000 ] Train Loss: 1.04652   Valid Loss: 0.97799\n",
            "[ Epoch 4380/10000 ] Train Loss: 1.04625   Valid Loss: 0.97695\n",
            "[ Epoch 4381/10000 ] Train Loss: 1.04446   Valid Loss: 0.97863\n",
            "[ Epoch 4382/10000 ] Train Loss: 1.04438   Valid Loss: 0.97636\n",
            "[ Epoch 4383/10000 ] Train Loss: 1.04466   Valid Loss: 0.98150\n",
            "[ Epoch 4384/10000 ] Train Loss: 1.04533   Valid Loss: 0.97837\n",
            "[ Epoch 4385/10000 ] Train Loss: 1.04384   Valid Loss: 0.97713\n",
            "[ Epoch 4386/10000 ] Train Loss: 1.04444   Valid Loss: 0.97800\n",
            "[ Epoch 4387/10000 ] Train Loss: 1.04423   Valid Loss: 0.97643\n",
            "[ Epoch 4388/10000 ] Train Loss: 1.04306   Valid Loss: 0.97737\n",
            "[ Epoch 4389/10000 ] Train Loss: 1.04451   Valid Loss: 0.97794\n",
            "[ Epoch 4390/10000 ] Train Loss: 1.04446   Valid Loss: 0.97646\n",
            "[ Epoch 4391/10000 ] Train Loss: 1.04479   Valid Loss: 0.97764\n",
            "[ Epoch 4392/10000 ] Train Loss: 1.04582   Valid Loss: 0.97606\n",
            "[ Epoch 4393/10000 ] Train Loss: 1.04369   Valid Loss: 0.97772\n",
            "[ Epoch 4394/10000 ] Train Loss: 1.04601   Valid Loss: 0.97944\n",
            "[ Epoch 4395/10000 ] Train Loss: 1.04618   Valid Loss: 0.97817\n",
            "[ Epoch 4396/10000 ] Train Loss: 1.04617   Valid Loss: 0.97677\n",
            "[ Epoch 4397/10000 ] Train Loss: 1.04418   Valid Loss: 0.97933\n",
            "[ Epoch 4398/10000 ] Train Loss: 1.04569   Valid Loss: 0.97748\n",
            "[ Epoch 4399/10000 ] Train Loss: 1.04506   Valid Loss: 0.97715\n",
            "[ Epoch 4400/10000 ] Train Loss: 1.04579   Valid Loss: 0.97743\n",
            "[ Epoch 4401/10000 ] Train Loss: 1.04384   Valid Loss: 0.97628\n",
            "[ Epoch 4402/10000 ] Train Loss: 1.04439   Valid Loss: 0.97638\n",
            "[ Epoch 4403/10000 ] Train Loss: 1.04578   Valid Loss: 0.97751\n",
            "[ Epoch 4404/10000 ] Train Loss: 1.04668   Valid Loss: 0.97874\n",
            "[ Epoch 4405/10000 ] Train Loss: 1.04467   Valid Loss: 0.97788\n",
            "[ Epoch 4406/10000 ] Train Loss: 1.04342   Valid Loss: 0.98011\n",
            "[ Epoch 4407/10000 ] Train Loss: 1.04600   Valid Loss: 0.98357\n",
            "[ Epoch 4408/10000 ] Train Loss: 1.04636   Valid Loss: 0.97927\n",
            "[ Epoch 4409/10000 ] Train Loss: 1.04237   Valid Loss: 0.97782\n",
            "[ Epoch 4410/10000 ] Train Loss: 1.04259   Valid Loss: 0.97728\n",
            "[ Epoch 4411/10000 ] Train Loss: 1.04086   Valid Loss: 0.97690\n",
            "[ Epoch 4412/10000 ] Train Loss: 1.04594   Valid Loss: 0.97488\n",
            "Early Stop Saving Model on Epoch 4412/10000\n",
            "[ Epoch 4413/10000 ] Train Loss: 1.04431   Valid Loss: 0.97874\n",
            "[ Epoch 4414/10000 ] Train Loss: 1.04405   Valid Loss: 0.97671\n",
            "[ Epoch 4415/10000 ] Train Loss: 1.04761   Valid Loss: 0.98785\n",
            "[ Epoch 4416/10000 ] Train Loss: 1.04971   Valid Loss: 0.98383\n",
            "[ Epoch 4417/10000 ] Train Loss: 1.04388   Valid Loss: 0.97846\n",
            "[ Epoch 4418/10000 ] Train Loss: 1.04408   Valid Loss: 0.98055\n",
            "[ Epoch 4419/10000 ] Train Loss: 1.04559   Valid Loss: 0.98039\n",
            "[ Epoch 4420/10000 ] Train Loss: 1.04449   Valid Loss: 0.97772\n",
            "[ Epoch 4421/10000 ] Train Loss: 1.04369   Valid Loss: 0.97710\n",
            "[ Epoch 4422/10000 ] Train Loss: 1.04536   Valid Loss: 0.97642\n",
            "[ Epoch 4423/10000 ] Train Loss: 1.04419   Valid Loss: 0.97670\n",
            "[ Epoch 4424/10000 ] Train Loss: 1.04317   Valid Loss: 0.97885\n",
            "[ Epoch 4425/10000 ] Train Loss: 1.04488   Valid Loss: 0.98194\n",
            "[ Epoch 4426/10000 ] Train Loss: 1.04364   Valid Loss: 0.98124\n",
            "[ Epoch 4427/10000 ] Train Loss: 1.05129   Valid Loss: 0.97999\n",
            "[ Epoch 4428/10000 ] Train Loss: 1.04564   Valid Loss: 0.97965\n",
            "[ Epoch 4429/10000 ] Train Loss: 1.04446   Valid Loss: 0.97735\n",
            "[ Epoch 4430/10000 ] Train Loss: 1.04509   Valid Loss: 0.98151\n",
            "[ Epoch 4431/10000 ] Train Loss: 1.04864   Valid Loss: 0.97642\n",
            "[ Epoch 4432/10000 ] Train Loss: 1.04538   Valid Loss: 0.97859\n",
            "[ Epoch 4433/10000 ] Train Loss: 1.04340   Valid Loss: 0.97826\n",
            "[ Epoch 4434/10000 ] Train Loss: 1.04441   Valid Loss: 0.97559\n",
            "[ Epoch 4435/10000 ] Train Loss: 1.04625   Valid Loss: 0.97676\n",
            "[ Epoch 4436/10000 ] Train Loss: 1.04644   Valid Loss: 0.97717\n",
            "[ Epoch 4437/10000 ] Train Loss: 1.04551   Valid Loss: 0.97648\n",
            "[ Epoch 4438/10000 ] Train Loss: 1.04219   Valid Loss: 0.97632\n",
            "[ Epoch 4439/10000 ] Train Loss: 1.04621   Valid Loss: 0.97831\n",
            "[ Epoch 4440/10000 ] Train Loss: 1.04385   Valid Loss: 0.97614\n",
            "[ Epoch 4441/10000 ] Train Loss: 1.04554   Valid Loss: 0.98247\n",
            "[ Epoch 4442/10000 ] Train Loss: 1.04866   Valid Loss: 0.98149\n",
            "[ Epoch 4443/10000 ] Train Loss: 1.04476   Valid Loss: 0.97946\n",
            "[ Epoch 4444/10000 ] Train Loss: 1.04486   Valid Loss: 0.97538\n",
            "[ Epoch 4445/10000 ] Train Loss: 1.04443   Valid Loss: 0.98010\n",
            "[ Epoch 4446/10000 ] Train Loss: 1.04478   Valid Loss: 0.97632\n",
            "[ Epoch 4447/10000 ] Train Loss: 1.04345   Valid Loss: 0.97642\n",
            "[ Epoch 4448/10000 ] Train Loss: 1.04466   Valid Loss: 0.97688\n",
            "[ Epoch 4449/10000 ] Train Loss: 1.04589   Valid Loss: 0.97736\n",
            "[ Epoch 4450/10000 ] Train Loss: 1.04359   Valid Loss: 0.97792\n",
            "[ Epoch 4451/10000 ] Train Loss: 1.04101   Valid Loss: 0.97698\n",
            "[ Epoch 4452/10000 ] Train Loss: 1.04434   Valid Loss: 0.97578\n",
            "[ Epoch 4453/10000 ] Train Loss: 1.04358   Valid Loss: 0.97719\n",
            "[ Epoch 4454/10000 ] Train Loss: 1.04632   Valid Loss: 0.98520\n",
            "[ Epoch 4455/10000 ] Train Loss: 1.05203   Valid Loss: 0.98046\n",
            "[ Epoch 4456/10000 ] Train Loss: 1.04628   Valid Loss: 0.97600\n",
            "[ Epoch 4457/10000 ] Train Loss: 1.04513   Valid Loss: 0.97614\n",
            "[ Epoch 4458/10000 ] Train Loss: 1.04348   Valid Loss: 0.97732\n",
            "[ Epoch 4459/10000 ] Train Loss: 1.04415   Valid Loss: 0.97720\n",
            "[ Epoch 4460/10000 ] Train Loss: 1.04174   Valid Loss: 0.97668\n",
            "[ Epoch 4461/10000 ] Train Loss: 1.04388   Valid Loss: 0.97803\n",
            "[ Epoch 4462/10000 ] Train Loss: 1.04552   Valid Loss: 0.98359\n",
            "[ Epoch 4463/10000 ] Train Loss: 1.04951   Valid Loss: 0.97665\n",
            "[ Epoch 4464/10000 ] Train Loss: 1.04392   Valid Loss: 0.97784\n",
            "[ Epoch 4465/10000 ] Train Loss: 1.04549   Valid Loss: 0.97814\n",
            "[ Epoch 4466/10000 ] Train Loss: 1.04569   Valid Loss: 0.97567\n",
            "[ Epoch 4467/10000 ] Train Loss: 1.04359   Valid Loss: 0.97901\n",
            "[ Epoch 4468/10000 ] Train Loss: 1.04495   Valid Loss: 0.97553\n",
            "[ Epoch 4469/10000 ] Train Loss: 1.04454   Valid Loss: 0.97707\n",
            "[ Epoch 4470/10000 ] Train Loss: 1.04441   Valid Loss: 0.97644\n",
            "[ Epoch 4471/10000 ] Train Loss: 1.04218   Valid Loss: 0.97811\n",
            "[ Epoch 4472/10000 ] Train Loss: 1.04631   Valid Loss: 0.97586\n",
            "[ Epoch 4473/10000 ] Train Loss: 1.04453   Valid Loss: 0.97666\n",
            "[ Epoch 4474/10000 ] Train Loss: 1.04326   Valid Loss: 0.97689\n",
            "[ Epoch 4475/10000 ] Train Loss: 1.04341   Valid Loss: 0.97660\n",
            "[ Epoch 4476/10000 ] Train Loss: 1.04066   Valid Loss: 0.97556\n",
            "[ Epoch 4477/10000 ] Train Loss: 1.04103   Valid Loss: 0.97639\n",
            "[ Epoch 4478/10000 ] Train Loss: 1.04483   Valid Loss: 0.98166\n",
            "[ Epoch 4479/10000 ] Train Loss: 1.05068   Valid Loss: 0.98306\n",
            "[ Epoch 4480/10000 ] Train Loss: 1.04676   Valid Loss: 0.97845\n",
            "[ Epoch 4481/10000 ] Train Loss: 1.04177   Valid Loss: 0.97816\n",
            "[ Epoch 4482/10000 ] Train Loss: 1.04513   Valid Loss: 0.97573\n",
            "[ Epoch 4483/10000 ] Train Loss: 1.04321   Valid Loss: 0.97665\n",
            "[ Epoch 4484/10000 ] Train Loss: 1.04455   Valid Loss: 0.98073\n",
            "[ Epoch 4485/10000 ] Train Loss: 1.04750   Valid Loss: 0.97628\n",
            "[ Epoch 4486/10000 ] Train Loss: 1.04692   Valid Loss: 0.97608\n",
            "[ Epoch 4487/10000 ] Train Loss: 1.04368   Valid Loss: 0.97747\n",
            "[ Epoch 4488/10000 ] Train Loss: 1.04511   Valid Loss: 0.98221\n",
            "[ Epoch 4489/10000 ] Train Loss: 1.04785   Valid Loss: 0.97545\n",
            "[ Epoch 4490/10000 ] Train Loss: 1.04301   Valid Loss: 0.97627\n",
            "[ Epoch 4491/10000 ] Train Loss: 1.04429   Valid Loss: 0.97544\n",
            "[ Epoch 4492/10000 ] Train Loss: 1.04133   Valid Loss: 0.97694\n",
            "[ Epoch 4493/10000 ] Train Loss: 1.04182   Valid Loss: 0.97572\n",
            "[ Epoch 4494/10000 ] Train Loss: 1.04300   Valid Loss: 0.97599\n",
            "[ Epoch 4495/10000 ] Train Loss: 1.04294   Valid Loss: 0.97873\n",
            "[ Epoch 4496/10000 ] Train Loss: 1.04319   Valid Loss: 0.97913\n",
            "[ Epoch 4497/10000 ] Train Loss: 1.04608   Valid Loss: 0.97730\n",
            "[ Epoch 4498/10000 ] Train Loss: 1.04264   Valid Loss: 0.97451\n",
            "Early Stop Saving Model on Epoch 4498/10000\n",
            "[ Epoch 4499/10000 ] Train Loss: 1.04317   Valid Loss: 0.97875\n",
            "[ Epoch 4500/10000 ] Train Loss: 1.04321   Valid Loss: 0.97806\n",
            "[ Epoch 4501/10000 ] Train Loss: 1.04201   Valid Loss: 0.97695\n",
            "[ Epoch 4502/10000 ] Train Loss: 1.04384   Valid Loss: 0.97552\n",
            "[ Epoch 4503/10000 ] Train Loss: 1.04323   Valid Loss: 0.97601\n",
            "[ Epoch 4504/10000 ] Train Loss: 1.04317   Valid Loss: 0.97806\n",
            "[ Epoch 4505/10000 ] Train Loss: 1.04532   Valid Loss: 0.98134\n",
            "[ Epoch 4506/10000 ] Train Loss: 1.04698   Valid Loss: 0.97744\n",
            "[ Epoch 4507/10000 ] Train Loss: 1.04448   Valid Loss: 0.97495\n",
            "[ Epoch 4508/10000 ] Train Loss: 1.04297   Valid Loss: 0.97637\n",
            "[ Epoch 4509/10000 ] Train Loss: 1.04348   Valid Loss: 0.97525\n",
            "[ Epoch 4510/10000 ] Train Loss: 1.04249   Valid Loss: 0.97762\n",
            "[ Epoch 4511/10000 ] Train Loss: 1.04586   Valid Loss: 0.97641\n",
            "[ Epoch 4512/10000 ] Train Loss: 1.04331   Valid Loss: 0.97646\n",
            "[ Epoch 4513/10000 ] Train Loss: 1.04216   Valid Loss: 0.97492\n",
            "[ Epoch 4514/10000 ] Train Loss: 1.04279   Valid Loss: 0.97899\n",
            "[ Epoch 4515/10000 ] Train Loss: 1.04311   Valid Loss: 0.97746\n",
            "[ Epoch 4516/10000 ] Train Loss: 1.04325   Valid Loss: 0.97513\n",
            "[ Epoch 4517/10000 ] Train Loss: 1.04338   Valid Loss: 0.97601\n",
            "[ Epoch 4518/10000 ] Train Loss: 1.04355   Valid Loss: 0.97776\n",
            "[ Epoch 4519/10000 ] Train Loss: 1.04310   Valid Loss: 0.97687\n",
            "[ Epoch 4520/10000 ] Train Loss: 1.04263   Valid Loss: 0.97716\n",
            "[ Epoch 4521/10000 ] Train Loss: 1.04325   Valid Loss: 0.97543\n",
            "[ Epoch 4522/10000 ] Train Loss: 1.04215   Valid Loss: 0.97507\n",
            "[ Epoch 4523/10000 ] Train Loss: 1.04314   Valid Loss: 0.97498\n",
            "[ Epoch 4524/10000 ] Train Loss: 1.04243   Valid Loss: 0.97621\n",
            "[ Epoch 4525/10000 ] Train Loss: 1.04288   Valid Loss: 0.97779\n",
            "[ Epoch 4526/10000 ] Train Loss: 1.04361   Valid Loss: 0.97918\n",
            "[ Epoch 4527/10000 ] Train Loss: 1.04673   Valid Loss: 0.97419\n",
            "Early Stop Saving Model on Epoch 4527/10000\n",
            "[ Epoch 4528/10000 ] Train Loss: 1.04478   Valid Loss: 0.97862\n",
            "[ Epoch 4529/10000 ] Train Loss: 1.04468   Valid Loss: 0.97497\n",
            "[ Epoch 4530/10000 ] Train Loss: 1.04218   Valid Loss: 0.97684\n",
            "[ Epoch 4531/10000 ] Train Loss: 1.04730   Valid Loss: 0.98036\n",
            "[ Epoch 4532/10000 ] Train Loss: 1.04940   Valid Loss: 0.98227\n",
            "[ Epoch 4533/10000 ] Train Loss: 1.04497   Valid Loss: 0.97475\n",
            "[ Epoch 4534/10000 ] Train Loss: 1.04112   Valid Loss: 0.97745\n",
            "[ Epoch 4535/10000 ] Train Loss: 1.04706   Valid Loss: 0.97739\n",
            "[ Epoch 4536/10000 ] Train Loss: 1.04366   Valid Loss: 0.97497\n",
            "[ Epoch 4537/10000 ] Train Loss: 1.04322   Valid Loss: 0.97469\n",
            "[ Epoch 4538/10000 ] Train Loss: 1.04308   Valid Loss: 0.97499\n",
            "[ Epoch 4539/10000 ] Train Loss: 1.04316   Valid Loss: 0.97604\n",
            "[ Epoch 4540/10000 ] Train Loss: 1.04244   Valid Loss: 0.97579\n",
            "[ Epoch 4541/10000 ] Train Loss: 1.04174   Valid Loss: 0.97474\n",
            "[ Epoch 4542/10000 ] Train Loss: 1.04220   Valid Loss: 0.97538\n",
            "[ Epoch 4543/10000 ] Train Loss: 1.04209   Valid Loss: 0.97568\n",
            "[ Epoch 4544/10000 ] Train Loss: 1.04270   Valid Loss: 0.97721\n",
            "[ Epoch 4545/10000 ] Train Loss: 1.04043   Valid Loss: 0.97779\n",
            "[ Epoch 4546/10000 ] Train Loss: 1.04424   Valid Loss: 0.98023\n",
            "[ Epoch 4547/10000 ] Train Loss: 1.04667   Valid Loss: 0.98002\n",
            "[ Epoch 4548/10000 ] Train Loss: 1.04397   Valid Loss: 0.97676\n",
            "[ Epoch 4549/10000 ] Train Loss: 1.04305   Valid Loss: 0.97635\n",
            "[ Epoch 4550/10000 ] Train Loss: 1.04334   Valid Loss: 0.97453\n",
            "[ Epoch 4551/10000 ] Train Loss: 1.04365   Valid Loss: 0.97699\n",
            "[ Epoch 4552/10000 ] Train Loss: 1.04134   Valid Loss: 0.97406\n",
            "Early Stop Saving Model on Epoch 4552/10000\n",
            "[ Epoch 4553/10000 ] Train Loss: 1.04186   Valid Loss: 0.97536\n",
            "[ Epoch 4554/10000 ] Train Loss: 1.04208   Valid Loss: 0.97547\n",
            "[ Epoch 4555/10000 ] Train Loss: 1.04178   Valid Loss: 0.97525\n",
            "[ Epoch 4556/10000 ] Train Loss: 1.04319   Valid Loss: 0.97432\n",
            "[ Epoch 4557/10000 ] Train Loss: 1.04219   Valid Loss: 0.97654\n",
            "[ Epoch 4558/10000 ] Train Loss: 1.04411   Valid Loss: 0.97773\n",
            "[ Epoch 4559/10000 ] Train Loss: 1.04611   Valid Loss: 0.97433\n",
            "[ Epoch 4560/10000 ] Train Loss: 1.04480   Valid Loss: 0.97825\n",
            "[ Epoch 4561/10000 ] Train Loss: 1.04385   Valid Loss: 0.98183\n",
            "[ Epoch 4562/10000 ] Train Loss: 1.04394   Valid Loss: 0.97592\n",
            "[ Epoch 4563/10000 ] Train Loss: 1.04291   Valid Loss: 0.97517\n",
            "[ Epoch 4564/10000 ] Train Loss: 1.04250   Valid Loss: 0.97454\n",
            "[ Epoch 4565/10000 ] Train Loss: 1.04444   Valid Loss: 0.97656\n",
            "[ Epoch 4566/10000 ] Train Loss: 1.04273   Valid Loss: 0.97487\n",
            "[ Epoch 4567/10000 ] Train Loss: 1.04424   Valid Loss: 0.98252\n",
            "[ Epoch 4568/10000 ] Train Loss: 1.04980   Valid Loss: 0.97533\n",
            "[ Epoch 4569/10000 ] Train Loss: 1.04645   Valid Loss: 0.97746\n",
            "[ Epoch 4570/10000 ] Train Loss: 1.04521   Valid Loss: 0.97434\n",
            "[ Epoch 4571/10000 ] Train Loss: 1.04174   Valid Loss: 0.97524\n",
            "[ Epoch 4572/10000 ] Train Loss: 1.04237   Valid Loss: 0.97412\n",
            "[ Epoch 4573/10000 ] Train Loss: 1.04141   Valid Loss: 0.97530\n",
            "[ Epoch 4574/10000 ] Train Loss: 1.04266   Valid Loss: 0.97582\n",
            "[ Epoch 4575/10000 ] Train Loss: 1.04240   Valid Loss: 0.97466\n",
            "[ Epoch 4576/10000 ] Train Loss: 1.04246   Valid Loss: 0.97785\n",
            "[ Epoch 4577/10000 ] Train Loss: 1.04479   Valid Loss: 0.97547\n",
            "[ Epoch 4578/10000 ] Train Loss: 1.04210   Valid Loss: 0.97509\n",
            "[ Epoch 4579/10000 ] Train Loss: 1.04623   Valid Loss: 0.97844\n",
            "[ Epoch 4580/10000 ] Train Loss: 1.04318   Valid Loss: 0.97570\n",
            "[ Epoch 4581/10000 ] Train Loss: 1.04388   Valid Loss: 0.97626\n",
            "[ Epoch 4582/10000 ] Train Loss: 1.04400   Valid Loss: 0.98016\n",
            "[ Epoch 4583/10000 ] Train Loss: 1.04426   Valid Loss: 0.97522\n",
            "[ Epoch 4584/10000 ] Train Loss: 1.04391   Valid Loss: 0.97689\n",
            "[ Epoch 4585/10000 ] Train Loss: 1.04376   Valid Loss: 0.97467\n",
            "[ Epoch 4586/10000 ] Train Loss: 1.04266   Valid Loss: 0.97561\n",
            "[ Epoch 4587/10000 ] Train Loss: 1.04055   Valid Loss: 0.97603\n",
            "[ Epoch 4588/10000 ] Train Loss: 1.04422   Valid Loss: 0.97398\n",
            "Early Stop Saving Model on Epoch 4588/10000\n",
            "[ Epoch 4589/10000 ] Train Loss: 1.04249   Valid Loss: 0.97563\n",
            "[ Epoch 4590/10000 ] Train Loss: 1.04111   Valid Loss: 0.97512\n",
            "[ Epoch 4591/10000 ] Train Loss: 1.04296   Valid Loss: 0.97495\n",
            "[ Epoch 4592/10000 ] Train Loss: 1.04204   Valid Loss: 0.97489\n",
            "[ Epoch 4593/10000 ] Train Loss: 1.04231   Valid Loss: 0.97527\n",
            "[ Epoch 4594/10000 ] Train Loss: 1.04217   Valid Loss: 0.97568\n",
            "[ Epoch 4595/10000 ] Train Loss: 1.04205   Valid Loss: 0.97387\n",
            "Early Stop Saving Model on Epoch 4595/10000\n",
            "[ Epoch 4596/10000 ] Train Loss: 1.04186   Valid Loss: 0.97437\n",
            "[ Epoch 4597/10000 ] Train Loss: 1.04213   Valid Loss: 0.97626\n",
            "[ Epoch 4598/10000 ] Train Loss: 1.04203   Valid Loss: 0.97379\n",
            "Early Stop Saving Model on Epoch 4598/10000\n",
            "[ Epoch 4599/10000 ] Train Loss: 1.04184   Valid Loss: 0.97496\n",
            "[ Epoch 4600/10000 ] Train Loss: 1.04187   Valid Loss: 0.97452\n",
            "[ Epoch 4601/10000 ] Train Loss: 1.04233   Valid Loss: 0.97547\n",
            "[ Epoch 4602/10000 ] Train Loss: 1.04230   Valid Loss: 0.97636\n",
            "[ Epoch 4603/10000 ] Train Loss: 1.04420   Valid Loss: 0.97416\n",
            "[ Epoch 4604/10000 ] Train Loss: 1.04525   Valid Loss: 0.97642\n",
            "[ Epoch 4605/10000 ] Train Loss: 1.04379   Valid Loss: 0.97459\n",
            "[ Epoch 4606/10000 ] Train Loss: 1.04141   Valid Loss: 0.97640\n",
            "[ Epoch 4607/10000 ] Train Loss: 1.04203   Valid Loss: 0.97500\n",
            "[ Epoch 4608/10000 ] Train Loss: 1.04418   Valid Loss: 0.97693\n",
            "[ Epoch 4609/10000 ] Train Loss: 1.04637   Valid Loss: 0.97562\n",
            "[ Epoch 4610/10000 ] Train Loss: 1.04395   Valid Loss: 0.97415\n",
            "[ Epoch 4611/10000 ] Train Loss: 1.04273   Valid Loss: 0.97405\n",
            "[ Epoch 4612/10000 ] Train Loss: 1.04182   Valid Loss: 0.97637\n",
            "[ Epoch 4613/10000 ] Train Loss: 1.04339   Valid Loss: 0.97432\n",
            "[ Epoch 4614/10000 ] Train Loss: 1.03998   Valid Loss: 0.97356\n",
            "Early Stop Saving Model on Epoch 4614/10000\n",
            "[ Epoch 4615/10000 ] Train Loss: 1.04146   Valid Loss: 0.97899\n",
            "[ Epoch 4616/10000 ] Train Loss: 1.04541   Valid Loss: 0.98050\n",
            "[ Epoch 4617/10000 ] Train Loss: 1.04550   Valid Loss: 0.97633\n",
            "[ Epoch 4618/10000 ] Train Loss: 1.04424   Valid Loss: 0.97605\n",
            "[ Epoch 4619/10000 ] Train Loss: 1.04381   Valid Loss: 0.97576\n",
            "[ Epoch 4620/10000 ] Train Loss: 1.04383   Valid Loss: 0.97606\n",
            "[ Epoch 4621/10000 ] Train Loss: 1.04251   Valid Loss: 0.97533\n",
            "[ Epoch 4622/10000 ] Train Loss: 1.03991   Valid Loss: 0.97411\n",
            "[ Epoch 4623/10000 ] Train Loss: 1.04296   Valid Loss: 0.97686\n",
            "[ Epoch 4624/10000 ] Train Loss: 1.04406   Valid Loss: 0.97299\n",
            "Early Stop Saving Model on Epoch 4624/10000\n",
            "[ Epoch 4625/10000 ] Train Loss: 1.04170   Valid Loss: 0.97755\n",
            "[ Epoch 4626/10000 ] Train Loss: 1.04367   Valid Loss: 0.97870\n",
            "[ Epoch 4627/10000 ] Train Loss: 1.04361   Valid Loss: 0.97437\n",
            "[ Epoch 4628/10000 ] Train Loss: 1.04168   Valid Loss: 0.97571\n",
            "[ Epoch 4629/10000 ] Train Loss: 1.04056   Valid Loss: 0.97304\n",
            "[ Epoch 4630/10000 ] Train Loss: 1.04119   Valid Loss: 0.97452\n",
            "[ Epoch 4631/10000 ] Train Loss: 1.04273   Valid Loss: 0.97374\n",
            "[ Epoch 4632/10000 ] Train Loss: 1.04177   Valid Loss: 0.97684\n",
            "[ Epoch 4633/10000 ] Train Loss: 1.04269   Valid Loss: 0.97508\n",
            "[ Epoch 4634/10000 ] Train Loss: 1.04146   Valid Loss: 0.97561\n",
            "[ Epoch 4635/10000 ] Train Loss: 1.04049   Valid Loss: 0.97355\n",
            "[ Epoch 4636/10000 ] Train Loss: 1.04119   Valid Loss: 0.98013\n",
            "[ Epoch 4637/10000 ] Train Loss: 1.04382   Valid Loss: 0.98387\n",
            "[ Epoch 4638/10000 ] Train Loss: 1.04501   Valid Loss: 0.98287\n",
            "[ Epoch 4639/10000 ] Train Loss: 1.04358   Valid Loss: 0.97348\n",
            "[ Epoch 4640/10000 ] Train Loss: 1.04065   Valid Loss: 0.97507\n",
            "[ Epoch 4641/10000 ] Train Loss: 1.04200   Valid Loss: 0.97491\n",
            "[ Epoch 4642/10000 ] Train Loss: 1.04164   Valid Loss: 0.97608\n",
            "[ Epoch 4643/10000 ] Train Loss: 1.04112   Valid Loss: 0.97481\n",
            "[ Epoch 4644/10000 ] Train Loss: 1.04250   Valid Loss: 0.97403\n",
            "[ Epoch 4645/10000 ] Train Loss: 1.03980   Valid Loss: 0.97396\n",
            "[ Epoch 4646/10000 ] Train Loss: 1.04176   Valid Loss: 0.97464\n",
            "[ Epoch 4647/10000 ] Train Loss: 1.04143   Valid Loss: 0.97510\n",
            "[ Epoch 4648/10000 ] Train Loss: 1.03969   Valid Loss: 0.97790\n",
            "[ Epoch 4649/10000 ] Train Loss: 1.04248   Valid Loss: 0.97478\n",
            "[ Epoch 4650/10000 ] Train Loss: 1.03982   Valid Loss: 0.97517\n",
            "[ Epoch 4651/10000 ] Train Loss: 1.04261   Valid Loss: 0.97392\n",
            "[ Epoch 4652/10000 ] Train Loss: 1.04114   Valid Loss: 0.97344\n",
            "[ Epoch 4653/10000 ] Train Loss: 1.04091   Valid Loss: 0.97533\n",
            "[ Epoch 4654/10000 ] Train Loss: 1.04176   Valid Loss: 0.97551\n",
            "[ Epoch 4655/10000 ] Train Loss: 1.04472   Valid Loss: 0.97984\n",
            "[ Epoch 4656/10000 ] Train Loss: 1.04394   Valid Loss: 0.97501\n",
            "[ Epoch 4657/10000 ] Train Loss: 1.04234   Valid Loss: 0.97697\n",
            "[ Epoch 4658/10000 ] Train Loss: 1.04273   Valid Loss: 0.97446\n",
            "[ Epoch 4659/10000 ] Train Loss: 1.04145   Valid Loss: 0.97364\n",
            "[ Epoch 4660/10000 ] Train Loss: 1.04260   Valid Loss: 0.97506\n",
            "[ Epoch 4661/10000 ] Train Loss: 1.04074   Valid Loss: 0.97364\n",
            "[ Epoch 4662/10000 ] Train Loss: 1.04144   Valid Loss: 0.97587\n",
            "[ Epoch 4663/10000 ] Train Loss: 1.03971   Valid Loss: 0.97310\n",
            "[ Epoch 4664/10000 ] Train Loss: 1.04102   Valid Loss: 0.97507\n",
            "[ Epoch 4665/10000 ] Train Loss: 1.04115   Valid Loss: 0.97441\n",
            "[ Epoch 4666/10000 ] Train Loss: 1.04117   Valid Loss: 0.97460\n",
            "[ Epoch 4667/10000 ] Train Loss: 1.04146   Valid Loss: 0.97448\n",
            "[ Epoch 4668/10000 ] Train Loss: 1.03991   Valid Loss: 0.97246\n",
            "Early Stop Saving Model on Epoch 4668/10000\n",
            "[ Epoch 4669/10000 ] Train Loss: 1.04095   Valid Loss: 0.97569\n",
            "[ Epoch 4670/10000 ] Train Loss: 1.04075   Valid Loss: 0.97353\n",
            "[ Epoch 4671/10000 ] Train Loss: 1.04173   Valid Loss: 0.97747\n",
            "[ Epoch 4672/10000 ] Train Loss: 1.04383   Valid Loss: 0.97974\n",
            "[ Epoch 4673/10000 ] Train Loss: 1.04195   Valid Loss: 0.97942\n",
            "[ Epoch 4674/10000 ] Train Loss: 1.04226   Valid Loss: 0.97384\n",
            "[ Epoch 4675/10000 ] Train Loss: 1.04176   Valid Loss: 0.97669\n",
            "[ Epoch 4676/10000 ] Train Loss: 1.04254   Valid Loss: 0.97345\n",
            "[ Epoch 4677/10000 ] Train Loss: 1.04412   Valid Loss: 0.97353\n",
            "[ Epoch 4678/10000 ] Train Loss: 1.04354   Valid Loss: 0.97735\n",
            "[ Epoch 4679/10000 ] Train Loss: 1.04457   Valid Loss: 0.98174\n",
            "[ Epoch 4680/10000 ] Train Loss: 1.04479   Valid Loss: 0.97296\n",
            "[ Epoch 4681/10000 ] Train Loss: 1.04109   Valid Loss: 0.97377\n",
            "[ Epoch 4682/10000 ] Train Loss: 1.04089   Valid Loss: 0.97537\n",
            "[ Epoch 4683/10000 ] Train Loss: 1.04153   Valid Loss: 0.97278\n",
            "[ Epoch 4684/10000 ] Train Loss: 1.04084   Valid Loss: 0.97422\n",
            "[ Epoch 4685/10000 ] Train Loss: 1.04043   Valid Loss: 0.97367\n",
            "[ Epoch 4686/10000 ] Train Loss: 1.04001   Valid Loss: 0.97275\n",
            "[ Epoch 4687/10000 ] Train Loss: 1.04043   Valid Loss: 0.97402\n",
            "[ Epoch 4688/10000 ] Train Loss: 1.04046   Valid Loss: 0.97469\n",
            "[ Epoch 4689/10000 ] Train Loss: 1.04120   Valid Loss: 0.97345\n",
            "[ Epoch 4690/10000 ] Train Loss: 1.04058   Valid Loss: 0.97262\n",
            "[ Epoch 4691/10000 ] Train Loss: 1.04137   Valid Loss: 0.97680\n",
            "[ Epoch 4692/10000 ] Train Loss: 1.04080   Valid Loss: 0.97362\n",
            "[ Epoch 4693/10000 ] Train Loss: 1.04118   Valid Loss: 0.97355\n",
            "[ Epoch 4694/10000 ] Train Loss: 1.03872   Valid Loss: 0.97463\n",
            "[ Epoch 4695/10000 ] Train Loss: 1.03827   Valid Loss: 0.97265\n",
            "[ Epoch 4696/10000 ] Train Loss: 1.04023   Valid Loss: 0.97723\n",
            "[ Epoch 4697/10000 ] Train Loss: 1.04032   Valid Loss: 0.97426\n",
            "[ Epoch 4698/10000 ] Train Loss: 1.04368   Valid Loss: 0.97520\n",
            "[ Epoch 4699/10000 ] Train Loss: 1.04236   Valid Loss: 0.98448\n",
            "[ Epoch 4700/10000 ] Train Loss: 1.04649   Valid Loss: 0.97905\n",
            "[ Epoch 4701/10000 ] Train Loss: 1.04533   Valid Loss: 0.97264\n",
            "[ Epoch 4702/10000 ] Train Loss: 1.04100   Valid Loss: 0.97524\n",
            "[ Epoch 4703/10000 ] Train Loss: 1.04112   Valid Loss: 0.97722\n",
            "[ Epoch 4704/10000 ] Train Loss: 1.04208   Valid Loss: 0.97628\n",
            "[ Epoch 4705/10000 ] Train Loss: 1.03786   Valid Loss: 0.97404\n",
            "[ Epoch 4706/10000 ] Train Loss: 1.04182   Valid Loss: 0.97903\n",
            "[ Epoch 4707/10000 ] Train Loss: 1.04262   Valid Loss: 0.97380\n",
            "[ Epoch 4708/10000 ] Train Loss: 1.04195   Valid Loss: 0.97306\n",
            "[ Epoch 4709/10000 ] Train Loss: 1.03922   Valid Loss: 0.97403\n",
            "[ Epoch 4710/10000 ] Train Loss: 1.04153   Valid Loss: 0.97444\n",
            "[ Epoch 4711/10000 ] Train Loss: 1.04109   Valid Loss: 0.97225\n",
            "Early Stop Saving Model on Epoch 4711/10000\n",
            "[ Epoch 4712/10000 ] Train Loss: 1.03885   Valid Loss: 0.97346\n",
            "[ Epoch 4713/10000 ] Train Loss: 1.04084   Valid Loss: 0.97428\n",
            "[ Epoch 4714/10000 ] Train Loss: 1.04391   Valid Loss: 0.97369\n",
            "[ Epoch 4715/10000 ] Train Loss: 1.04210   Valid Loss: 0.97344\n",
            "[ Epoch 4716/10000 ] Train Loss: 1.04485   Valid Loss: 0.97621\n",
            "[ Epoch 4717/10000 ] Train Loss: 1.04389   Valid Loss: 0.97362\n",
            "[ Epoch 4718/10000 ] Train Loss: 1.04341   Valid Loss: 0.97502\n",
            "[ Epoch 4719/10000 ] Train Loss: 1.03891   Valid Loss: 0.97380\n",
            "[ Epoch 4720/10000 ] Train Loss: 1.04159   Valid Loss: 0.97361\n",
            "[ Epoch 4721/10000 ] Train Loss: 1.04053   Valid Loss: 0.97314\n",
            "[ Epoch 4722/10000 ] Train Loss: 1.04053   Valid Loss: 0.97344\n",
            "[ Epoch 4723/10000 ] Train Loss: 1.04098   Valid Loss: 0.97295\n",
            "[ Epoch 4724/10000 ] Train Loss: 1.03936   Valid Loss: 0.97293\n",
            "[ Epoch 4725/10000 ] Train Loss: 1.04019   Valid Loss: 0.97271\n",
            "[ Epoch 4726/10000 ] Train Loss: 1.04015   Valid Loss: 0.97187\n",
            "Early Stop Saving Model on Epoch 4726/10000\n",
            "[ Epoch 4727/10000 ] Train Loss: 1.04005   Valid Loss: 0.97377\n",
            "[ Epoch 4728/10000 ] Train Loss: 1.03953   Valid Loss: 0.97377\n",
            "[ Epoch 4729/10000 ] Train Loss: 1.03927   Valid Loss: 0.97233\n",
            "[ Epoch 4730/10000 ] Train Loss: 1.04016   Valid Loss: 0.97429\n",
            "[ Epoch 4731/10000 ] Train Loss: 1.04199   Valid Loss: 0.97517\n",
            "[ Epoch 4732/10000 ] Train Loss: 1.04325   Valid Loss: 0.97445\n",
            "[ Epoch 4733/10000 ] Train Loss: 1.04132   Valid Loss: 0.97440\n",
            "[ Epoch 4734/10000 ] Train Loss: 1.04122   Valid Loss: 0.97207\n",
            "[ Epoch 4735/10000 ] Train Loss: 1.04118   Valid Loss: 0.97384\n",
            "[ Epoch 4736/10000 ] Train Loss: 1.04092   Valid Loss: 0.97761\n",
            "[ Epoch 4737/10000 ] Train Loss: 1.04307   Valid Loss: 0.97882\n",
            "[ Epoch 4738/10000 ] Train Loss: 1.04628   Valid Loss: 0.97338\n",
            "[ Epoch 4739/10000 ] Train Loss: 1.04401   Valid Loss: 0.97517\n",
            "[ Epoch 4740/10000 ] Train Loss: 1.04010   Valid Loss: 0.98017\n",
            "[ Epoch 4741/10000 ] Train Loss: 1.04456   Valid Loss: 0.97246\n",
            "[ Epoch 4742/10000 ] Train Loss: 1.04182   Valid Loss: 0.97268\n",
            "[ Epoch 4743/10000 ] Train Loss: 1.04038   Valid Loss: 0.97318\n",
            "[ Epoch 4744/10000 ] Train Loss: 1.04109   Valid Loss: 0.97226\n",
            "[ Epoch 4745/10000 ] Train Loss: 1.04052   Valid Loss: 0.97272\n",
            "[ Epoch 4746/10000 ] Train Loss: 1.04002   Valid Loss: 0.97717\n",
            "[ Epoch 4747/10000 ] Train Loss: 1.04501   Valid Loss: 0.97938\n",
            "[ Epoch 4748/10000 ] Train Loss: 1.04360   Valid Loss: 0.97256\n",
            "[ Epoch 4749/10000 ] Train Loss: 1.04220   Valid Loss: 0.97199\n",
            "[ Epoch 4750/10000 ] Train Loss: 1.04011   Valid Loss: 0.97320\n",
            "[ Epoch 4751/10000 ] Train Loss: 1.04357   Valid Loss: 0.97503\n",
            "[ Epoch 4752/10000 ] Train Loss: 1.04152   Valid Loss: 0.97317\n",
            "[ Epoch 4753/10000 ] Train Loss: 1.03950   Valid Loss: 0.97317\n",
            "[ Epoch 4754/10000 ] Train Loss: 1.03965   Valid Loss: 0.97155\n",
            "Early Stop Saving Model on Epoch 4754/10000\n",
            "[ Epoch 4755/10000 ] Train Loss: 1.04174   Valid Loss: 0.97232\n",
            "[ Epoch 4756/10000 ] Train Loss: 1.04219   Valid Loss: 0.97424\n",
            "[ Epoch 4757/10000 ] Train Loss: 1.04008   Valid Loss: 0.97167\n",
            "[ Epoch 4758/10000 ] Train Loss: 1.04025   Valid Loss: 0.97512\n",
            "[ Epoch 4759/10000 ] Train Loss: 1.04032   Valid Loss: 0.97149\n",
            "Early Stop Saving Model on Epoch 4759/10000\n",
            "[ Epoch 4760/10000 ] Train Loss: 1.04060   Valid Loss: 0.97307\n",
            "[ Epoch 4761/10000 ] Train Loss: 1.03986   Valid Loss: 0.97097\n",
            "Early Stop Saving Model on Epoch 4761/10000\n",
            "[ Epoch 4762/10000 ] Train Loss: 1.03983   Valid Loss: 0.97315\n",
            "[ Epoch 4763/10000 ] Train Loss: 1.04043   Valid Loss: 0.97159\n",
            "[ Epoch 4764/10000 ] Train Loss: 1.03922   Valid Loss: 0.97216\n",
            "[ Epoch 4765/10000 ] Train Loss: 1.04072   Valid Loss: 0.97303\n",
            "[ Epoch 4766/10000 ] Train Loss: 1.04204   Valid Loss: 0.97326\n",
            "[ Epoch 4767/10000 ] Train Loss: 1.03824   Valid Loss: 0.97353\n",
            "[ Epoch 4768/10000 ] Train Loss: 1.04197   Valid Loss: 0.97434\n",
            "[ Epoch 4769/10000 ] Train Loss: 1.04121   Valid Loss: 0.97295\n",
            "[ Epoch 4770/10000 ] Train Loss: 1.04025   Valid Loss: 0.97187\n",
            "[ Epoch 4771/10000 ] Train Loss: 1.03786   Valid Loss: 0.97235\n",
            "[ Epoch 4772/10000 ] Train Loss: 1.04180   Valid Loss: 0.97480\n",
            "[ Epoch 4773/10000 ] Train Loss: 1.03907   Valid Loss: 0.97135\n",
            "[ Epoch 4774/10000 ] Train Loss: 1.03882   Valid Loss: 0.97309\n",
            "[ Epoch 4775/10000 ] Train Loss: 1.04198   Valid Loss: 0.97676\n",
            "[ Epoch 4776/10000 ] Train Loss: 1.03942   Valid Loss: 0.97409\n",
            "[ Epoch 4777/10000 ] Train Loss: 1.04243   Valid Loss: 0.97421\n",
            "[ Epoch 4778/10000 ] Train Loss: 1.04118   Valid Loss: 0.97438\n",
            "[ Epoch 4779/10000 ] Train Loss: 1.04291   Valid Loss: 0.97283\n",
            "[ Epoch 4780/10000 ] Train Loss: 1.04025   Valid Loss: 0.97387\n",
            "[ Epoch 4781/10000 ] Train Loss: 1.04137   Valid Loss: 0.97283\n",
            "[ Epoch 4782/10000 ] Train Loss: 1.04169   Valid Loss: 0.97450\n",
            "[ Epoch 4783/10000 ] Train Loss: 1.04035   Valid Loss: 0.97264\n",
            "[ Epoch 4784/10000 ] Train Loss: 1.04061   Valid Loss: 0.97197\n",
            "[ Epoch 4785/10000 ] Train Loss: 1.04024   Valid Loss: 0.97145\n",
            "[ Epoch 4786/10000 ] Train Loss: 1.04157   Valid Loss: 0.97548\n",
            "[ Epoch 4787/10000 ] Train Loss: 1.04105   Valid Loss: 0.97195\n",
            "[ Epoch 4788/10000 ] Train Loss: 1.03891   Valid Loss: 0.97265\n",
            "[ Epoch 4789/10000 ] Train Loss: 1.03961   Valid Loss: 0.97118\n",
            "[ Epoch 4790/10000 ] Train Loss: 1.04004   Valid Loss: 0.97191\n",
            "[ Epoch 4791/10000 ] Train Loss: 1.04341   Valid Loss: 0.97673\n",
            "[ Epoch 4792/10000 ] Train Loss: 1.04136   Valid Loss: 0.97459\n",
            "[ Epoch 4793/10000 ] Train Loss: 1.03900   Valid Loss: 0.97194\n",
            "[ Epoch 4794/10000 ] Train Loss: 1.03825   Valid Loss: 0.97462\n",
            "[ Epoch 4795/10000 ] Train Loss: 1.04176   Valid Loss: 0.97801\n",
            "[ Epoch 4796/10000 ] Train Loss: 1.04347   Valid Loss: 0.97301\n",
            "[ Epoch 4797/10000 ] Train Loss: 1.03968   Valid Loss: 0.97322\n",
            "[ Epoch 4798/10000 ] Train Loss: 1.04280   Valid Loss: 0.97438\n",
            "[ Epoch 4799/10000 ] Train Loss: 1.03979   Valid Loss: 0.97308\n",
            "[ Epoch 4800/10000 ] Train Loss: 1.03980   Valid Loss: 0.97209\n",
            "[ Epoch 4801/10000 ] Train Loss: 1.04014   Valid Loss: 0.97501\n",
            "[ Epoch 4802/10000 ] Train Loss: 1.04052   Valid Loss: 0.97051\n",
            "Early Stop Saving Model on Epoch 4802/10000\n",
            "[ Epoch 4803/10000 ] Train Loss: 1.03854   Valid Loss: 0.97265\n",
            "[ Epoch 4804/10000 ] Train Loss: 1.04073   Valid Loss: 0.97256\n",
            "[ Epoch 4805/10000 ] Train Loss: 1.04181   Valid Loss: 0.97533\n",
            "[ Epoch 4806/10000 ] Train Loss: 1.03944   Valid Loss: 0.97631\n",
            "[ Epoch 4807/10000 ] Train Loss: 1.04310   Valid Loss: 0.97182\n",
            "[ Epoch 4808/10000 ] Train Loss: 1.03963   Valid Loss: 0.97137\n",
            "[ Epoch 4809/10000 ] Train Loss: 1.03847   Valid Loss: 0.97186\n",
            "[ Epoch 4810/10000 ] Train Loss: 1.04136   Valid Loss: 0.97324\n",
            "[ Epoch 4811/10000 ] Train Loss: 1.04141   Valid Loss: 0.97169\n",
            "[ Epoch 4812/10000 ] Train Loss: 1.04184   Valid Loss: 0.97156\n",
            "[ Epoch 4813/10000 ] Train Loss: 1.04052   Valid Loss: 0.97303\n",
            "[ Epoch 4814/10000 ] Train Loss: 1.03905   Valid Loss: 0.97105\n",
            "[ Epoch 4815/10000 ] Train Loss: 1.03922   Valid Loss: 0.97221\n",
            "[ Epoch 4816/10000 ] Train Loss: 1.03981   Valid Loss: 0.97299\n",
            "[ Epoch 4817/10000 ] Train Loss: 1.03979   Valid Loss: 0.97137\n",
            "[ Epoch 4818/10000 ] Train Loss: 1.03885   Valid Loss: 0.97224\n",
            "[ Epoch 4819/10000 ] Train Loss: 1.03882   Valid Loss: 0.97201\n",
            "[ Epoch 4820/10000 ] Train Loss: 1.03930   Valid Loss: 0.97182\n",
            "[ Epoch 4821/10000 ] Train Loss: 1.03967   Valid Loss: 0.97135\n",
            "[ Epoch 4822/10000 ] Train Loss: 1.04040   Valid Loss: 0.97613\n",
            "[ Epoch 4823/10000 ] Train Loss: 1.04021   Valid Loss: 0.97267\n",
            "[ Epoch 4824/10000 ] Train Loss: 1.04023   Valid Loss: 0.97062\n",
            "[ Epoch 4825/10000 ] Train Loss: 1.03952   Valid Loss: 0.97473\n",
            "[ Epoch 4826/10000 ] Train Loss: 1.03921   Valid Loss: 0.97285\n",
            "[ Epoch 4827/10000 ] Train Loss: 1.03937   Valid Loss: 0.97100\n",
            "[ Epoch 4828/10000 ] Train Loss: 1.03796   Valid Loss: 0.97323\n",
            "[ Epoch 4829/10000 ] Train Loss: 1.04164   Valid Loss: 0.97150\n",
            "[ Epoch 4830/10000 ] Train Loss: 1.04142   Valid Loss: 0.97280\n",
            "[ Epoch 4831/10000 ] Train Loss: 1.04100   Valid Loss: 0.97215\n",
            "[ Epoch 4832/10000 ] Train Loss: 1.03956   Valid Loss: 0.97291\n",
            "[ Epoch 4833/10000 ] Train Loss: 1.03995   Valid Loss: 0.97935\n",
            "[ Epoch 4834/10000 ] Train Loss: 1.04230   Valid Loss: 0.97078\n",
            "[ Epoch 4835/10000 ] Train Loss: 1.03822   Valid Loss: 0.97288\n",
            "[ Epoch 4836/10000 ] Train Loss: 1.04089   Valid Loss: 0.97387\n",
            "[ Epoch 4837/10000 ] Train Loss: 1.03960   Valid Loss: 0.97085\n",
            "[ Epoch 4838/10000 ] Train Loss: 1.03865   Valid Loss: 0.97262\n",
            "[ Epoch 4839/10000 ] Train Loss: 1.03899   Valid Loss: 0.97234\n",
            "[ Epoch 4840/10000 ] Train Loss: 1.04068   Valid Loss: 0.97114\n",
            "[ Epoch 4841/10000 ] Train Loss: 1.04039   Valid Loss: 0.97223\n",
            "[ Epoch 4842/10000 ] Train Loss: 1.03797   Valid Loss: 0.97392\n",
            "[ Epoch 4843/10000 ] Train Loss: 1.04055   Valid Loss: 0.97182\n",
            "[ Epoch 4844/10000 ] Train Loss: 1.04075   Valid Loss: 0.97122\n",
            "[ Epoch 4845/10000 ] Train Loss: 1.04089   Valid Loss: 0.97735\n",
            "[ Epoch 4846/10000 ] Train Loss: 1.04552   Valid Loss: 0.97976\n",
            "[ Epoch 4847/10000 ] Train Loss: 1.04233   Valid Loss: 0.97224\n",
            "[ Epoch 4848/10000 ] Train Loss: 1.03913   Valid Loss: 0.97092\n",
            "[ Epoch 4849/10000 ] Train Loss: 1.03917   Valid Loss: 0.97322\n",
            "[ Epoch 4850/10000 ] Train Loss: 1.03940   Valid Loss: 0.97269\n",
            "[ Epoch 4851/10000 ] Train Loss: 1.03813   Valid Loss: 0.97098\n",
            "[ Epoch 4852/10000 ] Train Loss: 1.03849   Valid Loss: 0.97173\n",
            "[ Epoch 4853/10000 ] Train Loss: 1.03900   Valid Loss: 0.97464\n",
            "[ Epoch 4854/10000 ] Train Loss: 1.03886   Valid Loss: 0.97293\n",
            "[ Epoch 4855/10000 ] Train Loss: 1.03988   Valid Loss: 0.97010\n",
            "Early Stop Saving Model on Epoch 4855/10000\n",
            "[ Epoch 4856/10000 ] Train Loss: 1.03801   Valid Loss: 0.97188\n",
            "[ Epoch 4857/10000 ] Train Loss: 1.03995   Valid Loss: 0.97217\n",
            "[ Epoch 4858/10000 ] Train Loss: 1.03903   Valid Loss: 0.97047\n",
            "[ Epoch 4859/10000 ] Train Loss: 1.03836   Valid Loss: 0.97165\n",
            "[ Epoch 4860/10000 ] Train Loss: 1.03936   Valid Loss: 0.97086\n",
            "[ Epoch 4861/10000 ] Train Loss: 1.03939   Valid Loss: 0.97259\n",
            "[ Epoch 4862/10000 ] Train Loss: 1.03892   Valid Loss: 0.97367\n",
            "[ Epoch 4863/10000 ] Train Loss: 1.03966   Valid Loss: 0.97592\n",
            "[ Epoch 4864/10000 ] Train Loss: 1.03998   Valid Loss: 0.97311\n",
            "[ Epoch 4865/10000 ] Train Loss: 1.03741   Valid Loss: 0.97324\n",
            "[ Epoch 4866/10000 ] Train Loss: 1.04175   Valid Loss: 0.97066\n",
            "[ Epoch 4867/10000 ] Train Loss: 1.04061   Valid Loss: 0.97354\n",
            "[ Epoch 4868/10000 ] Train Loss: 1.04612   Valid Loss: 0.97241\n",
            "[ Epoch 4869/10000 ] Train Loss: 1.04029   Valid Loss: 0.96985\n",
            "Early Stop Saving Model on Epoch 4869/10000\n",
            "[ Epoch 4870/10000 ] Train Loss: 1.03895   Valid Loss: 0.97118\n",
            "[ Epoch 4871/10000 ] Train Loss: 1.03767   Valid Loss: 0.97356\n",
            "[ Epoch 4872/10000 ] Train Loss: 1.03923   Valid Loss: 0.96968\n",
            "Early Stop Saving Model on Epoch 4872/10000\n",
            "[ Epoch 4873/10000 ] Train Loss: 1.03889   Valid Loss: 0.97147\n",
            "[ Epoch 4874/10000 ] Train Loss: 1.03707   Valid Loss: 0.97156\n",
            "[ Epoch 4875/10000 ] Train Loss: 1.04021   Valid Loss: 0.97491\n",
            "[ Epoch 4876/10000 ] Train Loss: 1.03885   Valid Loss: 0.96936\n",
            "Early Stop Saving Model on Epoch 4876/10000\n",
            "[ Epoch 4877/10000 ] Train Loss: 1.03698   Valid Loss: 0.97120\n",
            "[ Epoch 4878/10000 ] Train Loss: 1.03778   Valid Loss: 0.97098\n",
            "[ Epoch 4879/10000 ] Train Loss: 1.03819   Valid Loss: 0.97466\n",
            "[ Epoch 4880/10000 ] Train Loss: 1.04184   Valid Loss: 0.97064\n",
            "[ Epoch 4881/10000 ] Train Loss: 1.03721   Valid Loss: 0.97115\n",
            "[ Epoch 4882/10000 ] Train Loss: 1.03996   Valid Loss: 0.97116\n",
            "[ Epoch 4883/10000 ] Train Loss: 1.03835   Valid Loss: 0.96963\n",
            "[ Epoch 4884/10000 ] Train Loss: 1.03755   Valid Loss: 0.97448\n",
            "[ Epoch 4885/10000 ] Train Loss: 1.04065   Valid Loss: 0.97135\n",
            "[ Epoch 4886/10000 ] Train Loss: 1.03599   Valid Loss: 0.97043\n",
            "[ Epoch 4887/10000 ] Train Loss: 1.03977   Valid Loss: 0.97063\n",
            "[ Epoch 4888/10000 ] Train Loss: 1.04028   Valid Loss: 0.97194\n",
            "[ Epoch 4889/10000 ] Train Loss: 1.03896   Valid Loss: 0.96939\n",
            "[ Epoch 4890/10000 ] Train Loss: 1.03692   Valid Loss: 0.97154\n",
            "[ Epoch 4891/10000 ] Train Loss: 1.03928   Valid Loss: 0.97326\n",
            "[ Epoch 4892/10000 ] Train Loss: 1.03888   Valid Loss: 0.97057\n",
            "[ Epoch 4893/10000 ] Train Loss: 1.03967   Valid Loss: 0.97023\n",
            "[ Epoch 4894/10000 ] Train Loss: 1.04008   Valid Loss: 0.97643\n",
            "[ Epoch 4895/10000 ] Train Loss: 1.04098   Valid Loss: 0.97521\n",
            "[ Epoch 4896/10000 ] Train Loss: 1.03833   Valid Loss: 0.97241\n",
            "[ Epoch 4897/10000 ] Train Loss: 1.04158   Valid Loss: 0.97161\n",
            "[ Epoch 4898/10000 ] Train Loss: 1.03903   Valid Loss: 0.97106\n",
            "[ Epoch 4899/10000 ] Train Loss: 1.03890   Valid Loss: 0.97310\n",
            "[ Epoch 4900/10000 ] Train Loss: 1.03884   Valid Loss: 0.97191\n",
            "[ Epoch 4901/10000 ] Train Loss: 1.03822   Valid Loss: 0.97038\n",
            "[ Epoch 4902/10000 ] Train Loss: 1.03793   Valid Loss: 0.97115\n",
            "[ Epoch 4903/10000 ] Train Loss: 1.03789   Valid Loss: 0.97155\n",
            "[ Epoch 4904/10000 ] Train Loss: 1.04097   Valid Loss: 0.98311\n",
            "[ Epoch 4905/10000 ] Train Loss: 1.04440   Valid Loss: 0.97703\n",
            "[ Epoch 4906/10000 ] Train Loss: 1.04577   Valid Loss: 0.96968\n",
            "[ Epoch 4907/10000 ] Train Loss: 1.04620   Valid Loss: 0.97869\n",
            "[ Epoch 4908/10000 ] Train Loss: 1.04235   Valid Loss: 0.97021\n",
            "[ Epoch 4909/10000 ] Train Loss: 1.03888   Valid Loss: 0.97199\n",
            "[ Epoch 4910/10000 ] Train Loss: 1.04225   Valid Loss: 0.97175\n",
            "[ Epoch 4911/10000 ] Train Loss: 1.03863   Valid Loss: 0.96955\n",
            "[ Epoch 4912/10000 ] Train Loss: 1.03788   Valid Loss: 0.97036\n",
            "[ Epoch 4913/10000 ] Train Loss: 1.03886   Valid Loss: 0.97157\n",
            "[ Epoch 4914/10000 ] Train Loss: 1.04006   Valid Loss: 0.97130\n",
            "[ Epoch 4915/10000 ] Train Loss: 1.03798   Valid Loss: 0.97005\n",
            "[ Epoch 4916/10000 ] Train Loss: 1.03614   Valid Loss: 0.96932\n",
            "Early Stop Saving Model on Epoch 4916/10000\n",
            "[ Epoch 4917/10000 ] Train Loss: 1.03933   Valid Loss: 0.97256\n",
            "[ Epoch 4918/10000 ] Train Loss: 1.03864   Valid Loss: 0.97110\n",
            "[ Epoch 4919/10000 ] Train Loss: 1.03957   Valid Loss: 0.97330\n",
            "[ Epoch 4920/10000 ] Train Loss: 1.03744   Valid Loss: 0.97317\n",
            "[ Epoch 4921/10000 ] Train Loss: 1.03872   Valid Loss: 0.97088\n",
            "[ Epoch 4922/10000 ] Train Loss: 1.03862   Valid Loss: 0.97040\n",
            "[ Epoch 4923/10000 ] Train Loss: 1.03760   Valid Loss: 0.97072\n",
            "[ Epoch 4924/10000 ] Train Loss: 1.03729   Valid Loss: 0.97065\n",
            "[ Epoch 4925/10000 ] Train Loss: 1.03841   Valid Loss: 0.97181\n",
            "[ Epoch 4926/10000 ] Train Loss: 1.03579   Valid Loss: 0.96980\n",
            "[ Epoch 4927/10000 ] Train Loss: 1.03674   Valid Loss: 0.97028\n",
            "[ Epoch 4928/10000 ] Train Loss: 1.03905   Valid Loss: 0.97139\n",
            "[ Epoch 4929/10000 ] Train Loss: 1.03783   Valid Loss: 0.96999\n",
            "[ Epoch 4930/10000 ] Train Loss: 1.03610   Valid Loss: 0.97068\n",
            "[ Epoch 4931/10000 ] Train Loss: 1.03585   Valid Loss: 0.97315\n",
            "[ Epoch 4932/10000 ] Train Loss: 1.04226   Valid Loss: 0.97697\n",
            "[ Epoch 4933/10000 ] Train Loss: 1.04028   Valid Loss: 0.97016\n",
            "[ Epoch 4934/10000 ] Train Loss: 1.03886   Valid Loss: 0.96959\n",
            "[ Epoch 4935/10000 ] Train Loss: 1.03768   Valid Loss: 0.97259\n",
            "[ Epoch 4936/10000 ] Train Loss: 1.03799   Valid Loss: 0.97108\n",
            "[ Epoch 4937/10000 ] Train Loss: 1.03719   Valid Loss: 0.96979\n",
            "[ Epoch 4938/10000 ] Train Loss: 1.03671   Valid Loss: 0.97080\n",
            "[ Epoch 4939/10000 ] Train Loss: 1.03933   Valid Loss: 0.97167\n",
            "[ Epoch 4940/10000 ] Train Loss: 1.03708   Valid Loss: 0.96895\n",
            "Early Stop Saving Model on Epoch 4940/10000\n",
            "[ Epoch 4941/10000 ] Train Loss: 1.03640   Valid Loss: 0.96979\n",
            "[ Epoch 4942/10000 ] Train Loss: 1.03732   Valid Loss: 0.97276\n",
            "[ Epoch 4943/10000 ] Train Loss: 1.03874   Valid Loss: 0.97094\n",
            "[ Epoch 4944/10000 ] Train Loss: 1.03881   Valid Loss: 0.97049\n",
            "[ Epoch 4945/10000 ] Train Loss: 1.03746   Valid Loss: 0.97128\n",
            "[ Epoch 4946/10000 ] Train Loss: 1.03840   Valid Loss: 0.97256\n",
            "[ Epoch 4947/10000 ] Train Loss: 1.03623   Valid Loss: 0.97069\n",
            "[ Epoch 4948/10000 ] Train Loss: 1.03882   Valid Loss: 0.97017\n",
            "[ Epoch 4949/10000 ] Train Loss: 1.03948   Valid Loss: 0.96977\n",
            "[ Epoch 4950/10000 ] Train Loss: 1.03800   Valid Loss: 0.97052\n",
            "[ Epoch 4951/10000 ] Train Loss: 1.03903   Valid Loss: 0.96895\n",
            "[ Epoch 4952/10000 ] Train Loss: 1.03932   Valid Loss: 0.96890\n",
            "Early Stop Saving Model on Epoch 4952/10000\n",
            "[ Epoch 4953/10000 ] Train Loss: 1.03712   Valid Loss: 0.97127\n",
            "[ Epoch 4954/10000 ] Train Loss: 1.03910   Valid Loss: 0.97673\n",
            "[ Epoch 4955/10000 ] Train Loss: 1.04066   Valid Loss: 0.96861\n",
            "Early Stop Saving Model on Epoch 4955/10000\n",
            "[ Epoch 4956/10000 ] Train Loss: 1.03753   Valid Loss: 0.97095\n",
            "[ Epoch 4957/10000 ] Train Loss: 1.03860   Valid Loss: 0.97690\n",
            "[ Epoch 4958/10000 ] Train Loss: 1.03688   Valid Loss: 0.97038\n",
            "[ Epoch 4959/10000 ] Train Loss: 1.03778   Valid Loss: 0.97191\n",
            "[ Epoch 4960/10000 ] Train Loss: 1.04087   Valid Loss: 0.98066\n",
            "[ Epoch 4961/10000 ] Train Loss: 1.04084   Valid Loss: 0.98032\n",
            "[ Epoch 4962/10000 ] Train Loss: 1.04461   Valid Loss: 0.97008\n",
            "[ Epoch 4963/10000 ] Train Loss: 1.04370   Valid Loss: 0.96973\n",
            "[ Epoch 4964/10000 ] Train Loss: 1.03912   Valid Loss: 0.97050\n",
            "[ Epoch 4965/10000 ] Train Loss: 1.03858   Valid Loss: 0.96944\n",
            "[ Epoch 4966/10000 ] Train Loss: 1.03702   Valid Loss: 0.96957\n",
            "[ Epoch 4967/10000 ] Train Loss: 1.03650   Valid Loss: 0.96978\n",
            "[ Epoch 4968/10000 ] Train Loss: 1.03619   Valid Loss: 0.96875\n",
            "[ Epoch 4969/10000 ] Train Loss: 1.03673   Valid Loss: 0.96947\n",
            "[ Epoch 4970/10000 ] Train Loss: 1.03810   Valid Loss: 0.97014\n",
            "[ Epoch 4971/10000 ] Train Loss: 1.03976   Valid Loss: 0.97915\n",
            "[ Epoch 4972/10000 ] Train Loss: 1.04354   Valid Loss: 0.97642\n",
            "[ Epoch 4973/10000 ] Train Loss: 1.03934   Valid Loss: 0.96913\n",
            "[ Epoch 4974/10000 ] Train Loss: 1.03600   Valid Loss: 0.96962\n",
            "[ Epoch 4975/10000 ] Train Loss: 1.03628   Valid Loss: 0.96871\n",
            "[ Epoch 4976/10000 ] Train Loss: 1.03676   Valid Loss: 0.97038\n",
            "[ Epoch 4977/10000 ] Train Loss: 1.03679   Valid Loss: 0.96983\n",
            "[ Epoch 4978/10000 ] Train Loss: 1.03737   Valid Loss: 0.97051\n",
            "[ Epoch 4979/10000 ] Train Loss: 1.03843   Valid Loss: 0.97553\n",
            "[ Epoch 4980/10000 ] Train Loss: 1.04029   Valid Loss: 0.97301\n",
            "[ Epoch 4981/10000 ] Train Loss: 1.03657   Valid Loss: 0.96899\n",
            "[ Epoch 4982/10000 ] Train Loss: 1.03792   Valid Loss: 0.97168\n",
            "[ Epoch 4983/10000 ] Train Loss: 1.03590   Valid Loss: 0.96959\n",
            "[ Epoch 4984/10000 ] Train Loss: 1.03566   Valid Loss: 0.96834\n",
            "Early Stop Saving Model on Epoch 4984/10000\n",
            "[ Epoch 4985/10000 ] Train Loss: 1.03759   Valid Loss: 0.96905\n",
            "[ Epoch 4986/10000 ] Train Loss: 1.03701   Valid Loss: 0.96858\n",
            "[ Epoch 4987/10000 ] Train Loss: 1.03600   Valid Loss: 0.97053\n",
            "[ Epoch 4988/10000 ] Train Loss: 1.03690   Valid Loss: 0.96842\n",
            "[ Epoch 4989/10000 ] Train Loss: 1.03811   Valid Loss: 0.96993\n",
            "[ Epoch 4990/10000 ] Train Loss: 1.03598   Valid Loss: 0.96843\n",
            "[ Epoch 4991/10000 ] Train Loss: 1.03643   Valid Loss: 0.96928\n",
            "[ Epoch 4992/10000 ] Train Loss: 1.03754   Valid Loss: 0.96995\n",
            "[ Epoch 4993/10000 ] Train Loss: 1.03631   Valid Loss: 0.96841\n",
            "[ Epoch 4994/10000 ] Train Loss: 1.03626   Valid Loss: 0.96979\n",
            "[ Epoch 4995/10000 ] Train Loss: 1.03726   Valid Loss: 0.96916\n",
            "[ Epoch 4996/10000 ] Train Loss: 1.03807   Valid Loss: 0.97034\n",
            "[ Epoch 4997/10000 ] Train Loss: 1.04078   Valid Loss: 0.97200\n",
            "[ Epoch 4998/10000 ] Train Loss: 1.03758   Valid Loss: 0.97232\n",
            "[ Epoch 4999/10000 ] Train Loss: 1.03820   Valid Loss: 0.96988\n",
            "[ Epoch 5000/10000 ] Train Loss: 1.03417   Valid Loss: 0.96946\n",
            "[ Epoch 5001/10000 ] Train Loss: 1.03747   Valid Loss: 0.96972\n",
            "[ Epoch 5002/10000 ] Train Loss: 1.03667   Valid Loss: 0.96913\n",
            "[ Epoch 5003/10000 ] Train Loss: 1.03563   Valid Loss: 0.97034\n",
            "[ Epoch 5004/10000 ] Train Loss: 1.03665   Valid Loss: 0.96807\n",
            "Early Stop Saving Model on Epoch 5004/10000\n",
            "[ Epoch 5005/10000 ] Train Loss: 1.03891   Valid Loss: 0.97618\n",
            "[ Epoch 5006/10000 ] Train Loss: 1.03829   Valid Loss: 0.97070\n",
            "[ Epoch 5007/10000 ] Train Loss: 1.03915   Valid Loss: 0.97186\n",
            "[ Epoch 5008/10000 ] Train Loss: 1.03823   Valid Loss: 0.96832\n",
            "[ Epoch 5009/10000 ] Train Loss: 1.03548   Valid Loss: 0.96864\n",
            "[ Epoch 5010/10000 ] Train Loss: 1.03703   Valid Loss: 0.96860\n",
            "[ Epoch 5011/10000 ] Train Loss: 1.03580   Valid Loss: 0.96772\n",
            "Early Stop Saving Model on Epoch 5011/10000\n",
            "[ Epoch 5012/10000 ] Train Loss: 1.03534   Valid Loss: 0.96913\n",
            "[ Epoch 5013/10000 ] Train Loss: 1.03637   Valid Loss: 0.96983\n",
            "[ Epoch 5014/10000 ] Train Loss: 1.03644   Valid Loss: 0.96819\n",
            "[ Epoch 5015/10000 ] Train Loss: 1.03697   Valid Loss: 0.96946\n",
            "[ Epoch 5016/10000 ] Train Loss: 1.03673   Valid Loss: 0.96923\n",
            "[ Epoch 5017/10000 ] Train Loss: 1.03708   Valid Loss: 0.97226\n",
            "[ Epoch 5018/10000 ] Train Loss: 1.03572   Valid Loss: 0.97232\n",
            "[ Epoch 5019/10000 ] Train Loss: 1.03625   Valid Loss: 0.96854\n",
            "[ Epoch 5020/10000 ] Train Loss: 1.03767   Valid Loss: 0.96788\n",
            "[ Epoch 5021/10000 ] Train Loss: 1.03718   Valid Loss: 0.97110\n",
            "[ Epoch 5022/10000 ] Train Loss: 1.03727   Valid Loss: 0.96922\n",
            "[ Epoch 5023/10000 ] Train Loss: 1.03545   Valid Loss: 0.96990\n",
            "[ Epoch 5024/10000 ] Train Loss: 1.03383   Valid Loss: 0.96846\n",
            "[ Epoch 5025/10000 ] Train Loss: 1.03490   Valid Loss: 0.96738\n",
            "Early Stop Saving Model on Epoch 5025/10000\n",
            "[ Epoch 5026/10000 ] Train Loss: 1.03779   Valid Loss: 0.97222\n",
            "[ Epoch 5027/10000 ] Train Loss: 1.03827   Valid Loss: 0.96791\n",
            "[ Epoch 5028/10000 ] Train Loss: 1.03572   Valid Loss: 0.96853\n",
            "[ Epoch 5029/10000 ] Train Loss: 1.03700   Valid Loss: 0.97201\n",
            "[ Epoch 5030/10000 ] Train Loss: 1.03890   Valid Loss: 0.97293\n",
            "[ Epoch 5031/10000 ] Train Loss: 1.03699   Valid Loss: 0.96927\n",
            "[ Epoch 5032/10000 ] Train Loss: 1.03593   Valid Loss: 0.96838\n",
            "[ Epoch 5033/10000 ] Train Loss: 1.03678   Valid Loss: 0.96842\n",
            "[ Epoch 5034/10000 ] Train Loss: 1.03670   Valid Loss: 0.97037\n",
            "[ Epoch 5035/10000 ] Train Loss: 1.03949   Valid Loss: 0.96867\n",
            "[ Epoch 5036/10000 ] Train Loss: 1.03689   Valid Loss: 0.96938\n",
            "[ Epoch 5037/10000 ] Train Loss: 1.03788   Valid Loss: 0.97157\n",
            "[ Epoch 5038/10000 ] Train Loss: 1.03914   Valid Loss: 0.96903\n",
            "[ Epoch 5039/10000 ] Train Loss: 1.03751   Valid Loss: 0.96889\n",
            "[ Epoch 5040/10000 ] Train Loss: 1.03539   Valid Loss: 0.97003\n",
            "[ Epoch 5041/10000 ] Train Loss: 1.03619   Valid Loss: 0.96918\n",
            "[ Epoch 5042/10000 ] Train Loss: 1.03638   Valid Loss: 0.96775\n",
            "[ Epoch 5043/10000 ] Train Loss: 1.03785   Valid Loss: 0.97067\n",
            "[ Epoch 5044/10000 ] Train Loss: 1.03936   Valid Loss: 0.97089\n",
            "[ Epoch 5045/10000 ] Train Loss: 1.03577   Valid Loss: 0.96917\n",
            "[ Epoch 5046/10000 ] Train Loss: 1.03688   Valid Loss: 0.97067\n",
            "[ Epoch 5047/10000 ] Train Loss: 1.03720   Valid Loss: 0.96819\n",
            "[ Epoch 5048/10000 ] Train Loss: 1.03797   Valid Loss: 0.96920\n",
            "[ Epoch 5049/10000 ] Train Loss: 1.03590   Valid Loss: 0.96720\n",
            "Early Stop Saving Model on Epoch 5049/10000\n",
            "[ Epoch 5050/10000 ] Train Loss: 1.03421   Valid Loss: 0.96856\n",
            "[ Epoch 5051/10000 ] Train Loss: 1.03544   Valid Loss: 0.96851\n",
            "[ Epoch 5052/10000 ] Train Loss: 1.03757   Valid Loss: 0.96796\n",
            "[ Epoch 5053/10000 ] Train Loss: 1.03470   Valid Loss: 0.96756\n",
            "[ Epoch 5054/10000 ] Train Loss: 1.03613   Valid Loss: 0.97069\n",
            "[ Epoch 5055/10000 ] Train Loss: 1.03447   Valid Loss: 0.96683\n",
            "Early Stop Saving Model on Epoch 5055/10000\n",
            "[ Epoch 5056/10000 ] Train Loss: 1.03503   Valid Loss: 0.96841\n",
            "[ Epoch 5057/10000 ] Train Loss: 1.04022   Valid Loss: 0.97522\n",
            "[ Epoch 5058/10000 ] Train Loss: 1.03842   Valid Loss: 0.97021\n",
            "[ Epoch 5059/10000 ] Train Loss: 1.03597   Valid Loss: 0.96864\n",
            "[ Epoch 5060/10000 ] Train Loss: 1.03607   Valid Loss: 0.96674\n",
            "Early Stop Saving Model on Epoch 5060/10000\n",
            "[ Epoch 5061/10000 ] Train Loss: 1.03635   Valid Loss: 0.96821\n",
            "[ Epoch 5062/10000 ] Train Loss: 1.03494   Valid Loss: 0.96826\n",
            "[ Epoch 5063/10000 ] Train Loss: 1.03557   Valid Loss: 0.97077\n",
            "[ Epoch 5064/10000 ] Train Loss: 1.03472   Valid Loss: 0.97005\n",
            "[ Epoch 5065/10000 ] Train Loss: 1.03781   Valid Loss: 0.97129\n",
            "[ Epoch 5066/10000 ] Train Loss: 1.03891   Valid Loss: 0.96981\n",
            "[ Epoch 5067/10000 ] Train Loss: 1.03852   Valid Loss: 0.96929\n",
            "[ Epoch 5068/10000 ] Train Loss: 1.03678   Valid Loss: 0.96912\n",
            "[ Epoch 5069/10000 ] Train Loss: 1.03610   Valid Loss: 0.97208\n",
            "[ Epoch 5070/10000 ] Train Loss: 1.03671   Valid Loss: 0.96828\n",
            "[ Epoch 5071/10000 ] Train Loss: 1.03525   Valid Loss: 0.96803\n",
            "[ Epoch 5072/10000 ] Train Loss: 1.03671   Valid Loss: 0.96858\n",
            "[ Epoch 5073/10000 ] Train Loss: 1.03513   Valid Loss: 0.96679\n",
            "[ Epoch 5074/10000 ] Train Loss: 1.03421   Valid Loss: 0.96740\n",
            "[ Epoch 5075/10000 ] Train Loss: 1.03469   Valid Loss: 0.96883\n",
            "[ Epoch 5076/10000 ] Train Loss: 1.03694   Valid Loss: 0.97016\n",
            "[ Epoch 5077/10000 ] Train Loss: 1.03936   Valid Loss: 0.96830\n",
            "[ Epoch 5078/10000 ] Train Loss: 1.03728   Valid Loss: 0.96756\n",
            "[ Epoch 5079/10000 ] Train Loss: 1.03324   Valid Loss: 0.97103\n",
            "[ Epoch 5080/10000 ] Train Loss: 1.03818   Valid Loss: 0.96755\n",
            "[ Epoch 5081/10000 ] Train Loss: 1.03640   Valid Loss: 0.97025\n",
            "[ Epoch 5082/10000 ] Train Loss: 1.03518   Valid Loss: 0.96795\n",
            "[ Epoch 5083/10000 ] Train Loss: 1.03604   Valid Loss: 0.96994\n",
            "[ Epoch 5084/10000 ] Train Loss: 1.03671   Valid Loss: 0.96675\n",
            "[ Epoch 5085/10000 ] Train Loss: 1.03475   Valid Loss: 0.96843\n",
            "[ Epoch 5086/10000 ] Train Loss: 1.03514   Valid Loss: 0.96666\n",
            "Early Stop Saving Model on Epoch 5086/10000\n",
            "[ Epoch 5087/10000 ] Train Loss: 1.03476   Valid Loss: 0.96753\n",
            "[ Epoch 5088/10000 ] Train Loss: 1.03510   Valid Loss: 0.96708\n",
            "[ Epoch 5089/10000 ] Train Loss: 1.03483   Valid Loss: 0.97007\n",
            "[ Epoch 5090/10000 ] Train Loss: 1.03345   Valid Loss: 0.96806\n",
            "[ Epoch 5091/10000 ] Train Loss: 1.03677   Valid Loss: 0.96719\n",
            "[ Epoch 5092/10000 ] Train Loss: 1.03576   Valid Loss: 0.96793\n",
            "[ Epoch 5093/10000 ] Train Loss: 1.03462   Valid Loss: 0.96695\n",
            "[ Epoch 5094/10000 ] Train Loss: 1.03318   Valid Loss: 0.96832\n",
            "[ Epoch 5095/10000 ] Train Loss: 1.03514   Valid Loss: 0.97013\n",
            "[ Epoch 5096/10000 ] Train Loss: 1.04297   Valid Loss: 0.96901\n",
            "[ Epoch 5097/10000 ] Train Loss: 1.03395   Valid Loss: 0.96721\n",
            "[ Epoch 5098/10000 ] Train Loss: 1.03615   Valid Loss: 0.96704\n",
            "[ Epoch 5099/10000 ] Train Loss: 1.03520   Valid Loss: 0.96932\n",
            "[ Epoch 5100/10000 ] Train Loss: 1.03516   Valid Loss: 0.96753\n",
            "[ Epoch 5101/10000 ] Train Loss: 1.03562   Valid Loss: 0.96815\n",
            "[ Epoch 5102/10000 ] Train Loss: 1.03551   Valid Loss: 0.96641\n",
            "Early Stop Saving Model on Epoch 5102/10000\n",
            "[ Epoch 5103/10000 ] Train Loss: 1.03513   Valid Loss: 0.96955\n",
            "[ Epoch 5104/10000 ] Train Loss: 1.03437   Valid Loss: 0.96675\n",
            "[ Epoch 5105/10000 ] Train Loss: 1.03612   Valid Loss: 0.96791\n",
            "[ Epoch 5106/10000 ] Train Loss: 1.03744   Valid Loss: 0.97817\n",
            "[ Epoch 5107/10000 ] Train Loss: 1.03817   Valid Loss: 0.97052\n",
            "[ Epoch 5108/10000 ] Train Loss: 1.03910   Valid Loss: 0.96847\n",
            "[ Epoch 5109/10000 ] Train Loss: 1.03792   Valid Loss: 0.96580\n",
            "Early Stop Saving Model on Epoch 5109/10000\n",
            "[ Epoch 5110/10000 ] Train Loss: 1.03630   Valid Loss: 0.96978\n",
            "[ Epoch 5111/10000 ] Train Loss: 1.03498   Valid Loss: 0.97392\n",
            "[ Epoch 5112/10000 ] Train Loss: 1.03772   Valid Loss: 0.97102\n",
            "[ Epoch 5113/10000 ] Train Loss: 1.03568   Valid Loss: 0.96660\n",
            "[ Epoch 5114/10000 ] Train Loss: 1.03445   Valid Loss: 0.96705\n",
            "[ Epoch 5115/10000 ] Train Loss: 1.03525   Valid Loss: 0.96795\n",
            "[ Epoch 5116/10000 ] Train Loss: 1.03361   Valid Loss: 0.96868\n",
            "[ Epoch 5117/10000 ] Train Loss: 1.03650   Valid Loss: 0.97315\n",
            "[ Epoch 5118/10000 ] Train Loss: 1.03796   Valid Loss: 0.96805\n",
            "[ Epoch 5119/10000 ] Train Loss: 1.03484   Valid Loss: 0.96619\n",
            "[ Epoch 5120/10000 ] Train Loss: 1.03354   Valid Loss: 0.96652\n",
            "[ Epoch 5121/10000 ] Train Loss: 1.03586   Valid Loss: 0.96968\n",
            "[ Epoch 5122/10000 ] Train Loss: 1.03511   Valid Loss: 0.96662\n",
            "[ Epoch 5123/10000 ] Train Loss: 1.03568   Valid Loss: 0.96696\n",
            "[ Epoch 5124/10000 ] Train Loss: 1.03440   Valid Loss: 0.96839\n",
            "[ Epoch 5125/10000 ] Train Loss: 1.03389   Valid Loss: 0.96772\n",
            "[ Epoch 5126/10000 ] Train Loss: 1.03588   Valid Loss: 0.96503\n",
            "Early Stop Saving Model on Epoch 5126/10000\n",
            "[ Epoch 5127/10000 ] Train Loss: 1.03664   Valid Loss: 0.96972\n",
            "[ Epoch 5128/10000 ] Train Loss: 1.03457   Valid Loss: 0.96651\n",
            "[ Epoch 5129/10000 ] Train Loss: 1.03454   Valid Loss: 0.96848\n",
            "[ Epoch 5130/10000 ] Train Loss: 1.03542   Valid Loss: 0.97131\n",
            "[ Epoch 5131/10000 ] Train Loss: 1.03681   Valid Loss: 0.96804\n",
            "[ Epoch 5132/10000 ] Train Loss: 1.03489   Valid Loss: 0.96655\n",
            "[ Epoch 5133/10000 ] Train Loss: 1.03693   Valid Loss: 0.97039\n",
            "[ Epoch 5134/10000 ] Train Loss: 1.03378   Valid Loss: 0.96685\n",
            "[ Epoch 5135/10000 ] Train Loss: 1.03652   Valid Loss: 0.96856\n",
            "[ Epoch 5136/10000 ] Train Loss: 1.03776   Valid Loss: 0.96872\n",
            "[ Epoch 5137/10000 ] Train Loss: 1.03892   Valid Loss: 0.97043\n",
            "[ Epoch 5138/10000 ] Train Loss: 1.03773   Valid Loss: 0.96908\n",
            "[ Epoch 5139/10000 ] Train Loss: 1.03581   Valid Loss: 0.96755\n",
            "[ Epoch 5140/10000 ] Train Loss: 1.03894   Valid Loss: 0.97524\n",
            "[ Epoch 5141/10000 ] Train Loss: 1.04358   Valid Loss: 0.96621\n",
            "[ Epoch 5142/10000 ] Train Loss: 1.03482   Valid Loss: 0.96689\n",
            "[ Epoch 5143/10000 ] Train Loss: 1.03442   Valid Loss: 0.96665\n",
            "[ Epoch 5144/10000 ] Train Loss: 1.03361   Valid Loss: 0.96623\n",
            "[ Epoch 5145/10000 ] Train Loss: 1.03471   Valid Loss: 0.96878\n",
            "[ Epoch 5146/10000 ] Train Loss: 1.03461   Valid Loss: 0.96689\n",
            "[ Epoch 5147/10000 ] Train Loss: 1.03306   Valid Loss: 0.96664\n",
            "[ Epoch 5148/10000 ] Train Loss: 1.03554   Valid Loss: 0.96759\n",
            "[ Epoch 5149/10000 ] Train Loss: 1.03391   Valid Loss: 0.96731\n",
            "[ Epoch 5150/10000 ] Train Loss: 1.03740   Valid Loss: 0.96633\n",
            "[ Epoch 5151/10000 ] Train Loss: 1.03737   Valid Loss: 0.97359\n",
            "[ Epoch 5152/10000 ] Train Loss: 1.03807   Valid Loss: 0.96711\n",
            "[ Epoch 5153/10000 ] Train Loss: 1.03369   Valid Loss: 0.96926\n",
            "[ Epoch 5154/10000 ] Train Loss: 1.03517   Valid Loss: 0.96658\n",
            "[ Epoch 5155/10000 ] Train Loss: 1.03418   Valid Loss: 0.96725\n",
            "[ Epoch 5156/10000 ] Train Loss: 1.03426   Valid Loss: 0.96647\n",
            "[ Epoch 5157/10000 ] Train Loss: 1.03491   Valid Loss: 0.96693\n",
            "[ Epoch 5158/10000 ] Train Loss: 1.03676   Valid Loss: 0.97149\n",
            "[ Epoch 5159/10000 ] Train Loss: 1.03752   Valid Loss: 0.96618\n",
            "[ Epoch 5160/10000 ] Train Loss: 1.03508   Valid Loss: 0.96805\n",
            "[ Epoch 5161/10000 ] Train Loss: 1.03385   Valid Loss: 0.96676\n",
            "[ Epoch 5162/10000 ] Train Loss: 1.03416   Valid Loss: 0.96647\n",
            "[ Epoch 5163/10000 ] Train Loss: 1.03341   Valid Loss: 0.96728\n",
            "[ Epoch 5164/10000 ] Train Loss: 1.03388   Valid Loss: 0.96620\n",
            "[ Epoch 5165/10000 ] Train Loss: 1.03540   Valid Loss: 0.96869\n",
            "[ Epoch 5166/10000 ] Train Loss: 1.03635   Valid Loss: 0.96603\n",
            "[ Epoch 5167/10000 ] Train Loss: 1.03436   Valid Loss: 0.96760\n",
            "[ Epoch 5168/10000 ] Train Loss: 1.03306   Valid Loss: 0.96874\n",
            "[ Epoch 5169/10000 ] Train Loss: 1.03446   Valid Loss: 0.96739\n",
            "[ Epoch 5170/10000 ] Train Loss: 1.03638   Valid Loss: 0.97201\n",
            "[ Epoch 5171/10000 ] Train Loss: 1.03609   Valid Loss: 0.96949\n",
            "[ Epoch 5172/10000 ] Train Loss: 1.03728   Valid Loss: 0.96624\n",
            "[ Epoch 5173/10000 ] Train Loss: 1.03853   Valid Loss: 0.96856\n",
            "[ Epoch 5174/10000 ] Train Loss: 1.03417   Valid Loss: 0.96551\n",
            "[ Epoch 5175/10000 ] Train Loss: 1.03350   Valid Loss: 0.96767\n",
            "[ Epoch 5176/10000 ] Train Loss: 1.03440   Valid Loss: 0.96776\n",
            "[ Epoch 5177/10000 ] Train Loss: 1.03317   Valid Loss: 0.96574\n",
            "[ Epoch 5178/10000 ] Train Loss: 1.03363   Valid Loss: 0.96560\n",
            "[ Epoch 5179/10000 ] Train Loss: 1.03428   Valid Loss: 0.96671\n",
            "[ Epoch 5180/10000 ] Train Loss: 1.03472   Valid Loss: 0.96814\n",
            "[ Epoch 5181/10000 ] Train Loss: 1.03298   Valid Loss: 0.96685\n",
            "[ Epoch 5182/10000 ] Train Loss: 1.03350   Valid Loss: 0.96477\n",
            "Early Stop Saving Model on Epoch 5182/10000\n",
            "[ Epoch 5183/10000 ] Train Loss: 1.03580   Valid Loss: 0.96751\n",
            "[ Epoch 5184/10000 ] Train Loss: 1.03445   Valid Loss: 0.96566\n",
            "[ Epoch 5185/10000 ] Train Loss: 1.03366   Valid Loss: 0.96590\n",
            "[ Epoch 5186/10000 ] Train Loss: 1.03517   Valid Loss: 0.96630\n",
            "[ Epoch 5187/10000 ] Train Loss: 1.03318   Valid Loss: 0.96631\n",
            "[ Epoch 5188/10000 ] Train Loss: 1.03378   Valid Loss: 0.96558\n",
            "[ Epoch 5189/10000 ] Train Loss: 1.03349   Valid Loss: 0.96618\n",
            "[ Epoch 5190/10000 ] Train Loss: 1.03520   Valid Loss: 0.96913\n",
            "[ Epoch 5191/10000 ] Train Loss: 1.03588   Valid Loss: 0.96660\n",
            "[ Epoch 5192/10000 ] Train Loss: 1.03758   Valid Loss: 0.96878\n",
            "[ Epoch 5193/10000 ] Train Loss: 1.03757   Valid Loss: 0.97027\n",
            "[ Epoch 5194/10000 ] Train Loss: 1.03486   Valid Loss: 0.97130\n",
            "[ Epoch 5195/10000 ] Train Loss: 1.03857   Valid Loss: 0.96526\n",
            "[ Epoch 5196/10000 ] Train Loss: 1.03478   Valid Loss: 0.96754\n",
            "[ Epoch 5197/10000 ] Train Loss: 1.03496   Valid Loss: 0.96584\n",
            "[ Epoch 5198/10000 ] Train Loss: 1.03402   Valid Loss: 0.96698\n",
            "[ Epoch 5199/10000 ] Train Loss: 1.03449   Valid Loss: 0.97231\n",
            "[ Epoch 5200/10000 ] Train Loss: 1.03691   Valid Loss: 0.96670\n",
            "[ Epoch 5201/10000 ] Train Loss: 1.03474   Valid Loss: 0.96521\n",
            "[ Epoch 5202/10000 ] Train Loss: 1.03463   Valid Loss: 0.96819\n",
            "[ Epoch 5203/10000 ] Train Loss: 1.03204   Valid Loss: 0.96505\n",
            "[ Epoch 5204/10000 ] Train Loss: 1.03271   Valid Loss: 0.96507\n",
            "[ Epoch 5205/10000 ] Train Loss: 1.03439   Valid Loss: 0.97192\n",
            "[ Epoch 5206/10000 ] Train Loss: 1.03585   Valid Loss: 0.97852\n",
            "[ Epoch 5207/10000 ] Train Loss: 1.03433   Valid Loss: 0.97596\n",
            "[ Epoch 5208/10000 ] Train Loss: 1.03731   Valid Loss: 0.96618\n",
            "[ Epoch 5209/10000 ] Train Loss: 1.03501   Valid Loss: 0.96652\n",
            "[ Epoch 5210/10000 ] Train Loss: 1.03337   Valid Loss: 0.96513\n",
            "[ Epoch 5211/10000 ] Train Loss: 1.03163   Valid Loss: 0.96713\n",
            "[ Epoch 5212/10000 ] Train Loss: 1.03368   Valid Loss: 0.96608\n",
            "[ Epoch 5213/10000 ] Train Loss: 1.03413   Valid Loss: 0.96527\n",
            "[ Epoch 5214/10000 ] Train Loss: 1.03447   Valid Loss: 0.96619\n",
            "[ Epoch 5215/10000 ] Train Loss: 1.03480   Valid Loss: 0.96999\n",
            "[ Epoch 5216/10000 ] Train Loss: 1.03441   Valid Loss: 0.97136\n",
            "[ Epoch 5217/10000 ] Train Loss: 1.03548   Valid Loss: 0.96896\n",
            "[ Epoch 5218/10000 ] Train Loss: 1.03435   Valid Loss: 0.96497\n",
            "[ Epoch 5219/10000 ] Train Loss: 1.03502   Valid Loss: 0.96639\n",
            "[ Epoch 5220/10000 ] Train Loss: 1.03357   Valid Loss: 0.96516\n",
            "[ Epoch 5221/10000 ] Train Loss: 1.03211   Valid Loss: 0.96850\n",
            "[ Epoch 5222/10000 ] Train Loss: 1.03696   Valid Loss: 0.96830\n",
            "[ Epoch 5223/10000 ] Train Loss: 1.03562   Valid Loss: 0.96543\n",
            "[ Epoch 5224/10000 ] Train Loss: 1.03296   Valid Loss: 0.96657\n",
            "[ Epoch 5225/10000 ] Train Loss: 1.03341   Valid Loss: 0.96639\n",
            "[ Epoch 5226/10000 ] Train Loss: 1.03520   Valid Loss: 0.96657\n",
            "[ Epoch 5227/10000 ] Train Loss: 1.03424   Valid Loss: 0.96554\n",
            "[ Epoch 5228/10000 ] Train Loss: 1.03299   Valid Loss: 0.96724\n",
            "[ Epoch 5229/10000 ] Train Loss: 1.03179   Valid Loss: 0.96570\n",
            "[ Epoch 5230/10000 ] Train Loss: 1.03528   Valid Loss: 0.96631\n",
            "[ Epoch 5231/10000 ] Train Loss: 1.03526   Valid Loss: 0.96660\n",
            "[ Epoch 5232/10000 ] Train Loss: 1.03328   Valid Loss: 0.96663\n",
            "[ Epoch 5233/10000 ] Train Loss: 1.03448   Valid Loss: 0.96612\n",
            "[ Epoch 5234/10000 ] Train Loss: 1.03311   Valid Loss: 0.96969\n",
            "[ Epoch 5235/10000 ] Train Loss: 1.03359   Valid Loss: 0.97005\n",
            "[ Epoch 5236/10000 ] Train Loss: 1.03401   Valid Loss: 0.96578\n",
            "[ Epoch 5237/10000 ] Train Loss: 1.03517   Valid Loss: 0.96933\n",
            "[ Epoch 5238/10000 ] Train Loss: 1.03906   Valid Loss: 0.97014\n",
            "[ Epoch 5239/10000 ] Train Loss: 1.03447   Valid Loss: 0.96611\n",
            "[ Epoch 5240/10000 ] Train Loss: 1.03359   Valid Loss: 0.96587\n",
            "[ Epoch 5241/10000 ] Train Loss: 1.03550   Valid Loss: 0.96776\n",
            "[ Epoch 5242/10000 ] Train Loss: 1.03397   Valid Loss: 0.96545\n",
            "[ Epoch 5243/10000 ] Train Loss: 1.03234   Valid Loss: 0.96582\n",
            "[ Epoch 5244/10000 ] Train Loss: 1.03431   Valid Loss: 0.96877\n",
            "[ Epoch 5245/10000 ] Train Loss: 1.03583   Valid Loss: 0.96693\n",
            "[ Epoch 5246/10000 ] Train Loss: 1.03464   Valid Loss: 0.96468\n",
            "Early Stop Saving Model on Epoch 5246/10000\n",
            "[ Epoch 5247/10000 ] Train Loss: 1.03647   Valid Loss: 0.97026\n",
            "[ Epoch 5248/10000 ] Train Loss: 1.03468   Valid Loss: 0.96656\n",
            "[ Epoch 5249/10000 ] Train Loss: 1.03639   Valid Loss: 0.96655\n",
            "[ Epoch 5250/10000 ] Train Loss: 1.03379   Valid Loss: 0.96678\n",
            "[ Epoch 5251/10000 ] Train Loss: 1.03448   Valid Loss: 0.96489\n",
            "[ Epoch 5252/10000 ] Train Loss: 1.03380   Valid Loss: 0.96552\n",
            "[ Epoch 5253/10000 ] Train Loss: 1.03328   Valid Loss: 0.96582\n",
            "[ Epoch 5254/10000 ] Train Loss: 1.03727   Valid Loss: 0.97733\n",
            "[ Epoch 5255/10000 ] Train Loss: 1.03545   Valid Loss: 0.96900\n",
            "[ Epoch 5256/10000 ] Train Loss: 1.03527   Valid Loss: 0.97035\n",
            "[ Epoch 5257/10000 ] Train Loss: 1.03181   Valid Loss: 0.96632\n",
            "[ Epoch 5258/10000 ] Train Loss: 1.03253   Valid Loss: 0.96466\n",
            "Early Stop Saving Model on Epoch 5258/10000\n",
            "[ Epoch 5259/10000 ] Train Loss: 1.03234   Valid Loss: 0.96529\n",
            "[ Epoch 5260/10000 ] Train Loss: 1.03264   Valid Loss: 0.96543\n",
            "[ Epoch 5261/10000 ] Train Loss: 1.03234   Valid Loss: 0.96676\n",
            "[ Epoch 5262/10000 ] Train Loss: 1.03707   Valid Loss: 0.96918\n",
            "[ Epoch 5263/10000 ] Train Loss: 1.03990   Valid Loss: 0.96805\n",
            "[ Epoch 5264/10000 ] Train Loss: 1.03067   Valid Loss: 0.96589\n",
            "[ Epoch 5265/10000 ] Train Loss: 1.03469   Valid Loss: 0.96485\n",
            "[ Epoch 5266/10000 ] Train Loss: 1.03579   Valid Loss: 0.97057\n",
            "[ Epoch 5267/10000 ] Train Loss: 1.03510   Valid Loss: 0.96773\n",
            "[ Epoch 5268/10000 ] Train Loss: 1.03340   Valid Loss: 0.96534\n",
            "[ Epoch 5269/10000 ] Train Loss: 1.03248   Valid Loss: 0.96511\n",
            "[ Epoch 5270/10000 ] Train Loss: 1.03379   Valid Loss: 0.96503\n",
            "[ Epoch 5271/10000 ] Train Loss: 1.03222   Valid Loss: 0.96722\n",
            "[ Epoch 5272/10000 ] Train Loss: 1.03239   Valid Loss: 0.96823\n",
            "[ Epoch 5273/10000 ] Train Loss: 1.03303   Valid Loss: 0.96549\n",
            "[ Epoch 5274/10000 ] Train Loss: 1.03170   Valid Loss: 0.96659\n",
            "[ Epoch 5275/10000 ] Train Loss: 1.03576   Valid Loss: 0.97639\n",
            "[ Epoch 5276/10000 ] Train Loss: 1.03459   Valid Loss: 0.96967\n",
            "[ Epoch 5277/10000 ] Train Loss: 1.03497   Valid Loss: 0.96457\n",
            "Early Stop Saving Model on Epoch 5277/10000\n",
            "[ Epoch 5278/10000 ] Train Loss: 1.03240   Valid Loss: 0.96501\n",
            "[ Epoch 5279/10000 ] Train Loss: 1.03258   Valid Loss: 0.96473\n",
            "[ Epoch 5280/10000 ] Train Loss: 1.03243   Valid Loss: 0.96747\n",
            "[ Epoch 5281/10000 ] Train Loss: 1.03043   Valid Loss: 0.96612\n",
            "[ Epoch 5282/10000 ] Train Loss: 1.03168   Valid Loss: 0.96488\n",
            "[ Epoch 5283/10000 ] Train Loss: 1.03229   Valid Loss: 0.96557\n",
            "[ Epoch 5284/10000 ] Train Loss: 1.03276   Valid Loss: 0.96654\n",
            "[ Epoch 5285/10000 ] Train Loss: 1.03340   Valid Loss: 0.96705\n",
            "[ Epoch 5286/10000 ] Train Loss: 1.03610   Valid Loss: 0.96691\n",
            "[ Epoch 5287/10000 ] Train Loss: 1.03694   Valid Loss: 0.97085\n",
            "[ Epoch 5288/10000 ] Train Loss: 1.03423   Valid Loss: 0.96641\n",
            "[ Epoch 5289/10000 ] Train Loss: 1.03423   Valid Loss: 0.96495\n",
            "[ Epoch 5290/10000 ] Train Loss: 1.03424   Valid Loss: 0.96531\n",
            "[ Epoch 5291/10000 ] Train Loss: 1.03322   Valid Loss: 0.96520\n",
            "[ Epoch 5292/10000 ] Train Loss: 1.03268   Valid Loss: 0.96589\n",
            "[ Epoch 5293/10000 ] Train Loss: 1.03473   Valid Loss: 0.96707\n",
            "[ Epoch 5294/10000 ] Train Loss: 1.03305   Valid Loss: 0.96630\n",
            "[ Epoch 5295/10000 ] Train Loss: 1.03278   Valid Loss: 0.96565\n",
            "[ Epoch 5296/10000 ] Train Loss: 1.03500   Valid Loss: 0.96509\n",
            "[ Epoch 5297/10000 ] Train Loss: 1.03366   Valid Loss: 0.96695\n",
            "[ Epoch 5298/10000 ] Train Loss: 1.03376   Valid Loss: 0.96720\n",
            "[ Epoch 5299/10000 ] Train Loss: 1.03323   Valid Loss: 0.96487\n",
            "[ Epoch 5300/10000 ] Train Loss: 1.03063   Valid Loss: 0.96566\n",
            "[ Epoch 5301/10000 ] Train Loss: 1.03328   Valid Loss: 0.96640\n",
            "[ Epoch 5302/10000 ] Train Loss: 1.03245   Valid Loss: 0.96487\n",
            "[ Epoch 5303/10000 ] Train Loss: 1.03634   Valid Loss: 0.97329\n",
            "[ Epoch 5304/10000 ] Train Loss: 1.03951   Valid Loss: 0.97702\n",
            "[ Epoch 5305/10000 ] Train Loss: 1.03901   Valid Loss: 0.96413\n",
            "Early Stop Saving Model on Epoch 5305/10000\n",
            "[ Epoch 5306/10000 ] Train Loss: 1.03470   Valid Loss: 0.96786\n",
            "[ Epoch 5307/10000 ] Train Loss: 1.03477   Valid Loss: 0.97166\n",
            "[ Epoch 5308/10000 ] Train Loss: 1.03525   Valid Loss: 0.96539\n",
            "[ Epoch 5309/10000 ] Train Loss: 1.03251   Valid Loss: 0.96526\n",
            "[ Epoch 5310/10000 ] Train Loss: 1.03263   Valid Loss: 0.96613\n",
            "[ Epoch 5311/10000 ] Train Loss: 1.03501   Valid Loss: 0.96491\n",
            "[ Epoch 5312/10000 ] Train Loss: 1.03529   Valid Loss: 0.96562\n",
            "[ Epoch 5313/10000 ] Train Loss: 1.03238   Valid Loss: 0.96518\n",
            "[ Epoch 5314/10000 ] Train Loss: 1.03322   Valid Loss: 0.96705\n",
            "[ Epoch 5315/10000 ] Train Loss: 1.03612   Valid Loss: 0.96468\n",
            "[ Epoch 5316/10000 ] Train Loss: 1.03627   Valid Loss: 0.96808\n",
            "[ Epoch 5317/10000 ] Train Loss: 1.03524   Valid Loss: 0.96673\n",
            "[ Epoch 5318/10000 ] Train Loss: 1.03256   Valid Loss: 0.96521\n",
            "[ Epoch 5319/10000 ] Train Loss: 1.03338   Valid Loss: 0.96637\n",
            "[ Epoch 5320/10000 ] Train Loss: 1.03291   Valid Loss: 0.96624\n",
            "[ Epoch 5321/10000 ] Train Loss: 1.03062   Valid Loss: 0.96666\n",
            "[ Epoch 5322/10000 ] Train Loss: 1.03740   Valid Loss: 0.97669\n",
            "[ Epoch 5323/10000 ] Train Loss: 1.03749   Valid Loss: 0.96521\n",
            "[ Epoch 5324/10000 ] Train Loss: 1.03574   Valid Loss: 0.96983\n",
            "[ Epoch 5325/10000 ] Train Loss: 1.03458   Valid Loss: 0.96698\n",
            "[ Epoch 5326/10000 ] Train Loss: 1.03364   Valid Loss: 0.96491\n",
            "[ Epoch 5327/10000 ] Train Loss: 1.03306   Valid Loss: 0.96681\n",
            "[ Epoch 5328/10000 ] Train Loss: 1.03226   Valid Loss: 0.96533\n",
            "[ Epoch 5329/10000 ] Train Loss: 1.03352   Valid Loss: 0.96704\n",
            "[ Epoch 5330/10000 ] Train Loss: 1.03449   Valid Loss: 0.97224\n",
            "[ Epoch 5331/10000 ] Train Loss: 1.03538   Valid Loss: 0.96496\n",
            "[ Epoch 5332/10000 ] Train Loss: 1.03521   Valid Loss: 0.96681\n",
            "[ Epoch 5333/10000 ] Train Loss: 1.03475   Valid Loss: 0.96494\n",
            "[ Epoch 5334/10000 ] Train Loss: 1.03290   Valid Loss: 0.96581\n",
            "[ Epoch 5335/10000 ] Train Loss: 1.03218   Valid Loss: 0.96445\n",
            "[ Epoch 5336/10000 ] Train Loss: 1.03178   Valid Loss: 0.96542\n",
            "[ Epoch 5337/10000 ] Train Loss: 1.03290   Valid Loss: 0.96518\n",
            "[ Epoch 5338/10000 ] Train Loss: 1.03309   Valid Loss: 0.96726\n",
            "[ Epoch 5339/10000 ] Train Loss: 1.03474   Valid Loss: 0.96831\n",
            "[ Epoch 5340/10000 ] Train Loss: 1.03479   Valid Loss: 0.96514\n",
            "[ Epoch 5341/10000 ] Train Loss: 1.03580   Valid Loss: 0.96619\n",
            "[ Epoch 5342/10000 ] Train Loss: 1.03749   Valid Loss: 0.96999\n",
            "[ Epoch 5343/10000 ] Train Loss: 1.03536   Valid Loss: 0.96889\n",
            "[ Epoch 5344/10000 ] Train Loss: 1.03339   Valid Loss: 0.96741\n",
            "[ Epoch 5345/10000 ] Train Loss: 1.03300   Valid Loss: 0.96431\n",
            "[ Epoch 5346/10000 ] Train Loss: 1.03194   Valid Loss: 0.96582\n",
            "[ Epoch 5347/10000 ] Train Loss: 1.03154   Valid Loss: 0.96529\n",
            "[ Epoch 5348/10000 ] Train Loss: 1.03218   Valid Loss: 0.96543\n",
            "[ Epoch 5349/10000 ] Train Loss: 1.03409   Valid Loss: 0.96831\n",
            "[ Epoch 5350/10000 ] Train Loss: 1.03487   Valid Loss: 0.96791\n",
            "[ Epoch 5351/10000 ] Train Loss: 1.03551   Valid Loss: 0.96412\n",
            "Early Stop Saving Model on Epoch 5351/10000\n",
            "[ Epoch 5352/10000 ] Train Loss: 1.03362   Valid Loss: 0.96644\n",
            "[ Epoch 5353/10000 ] Train Loss: 1.03154   Valid Loss: 0.96483\n",
            "[ Epoch 5354/10000 ] Train Loss: 1.03367   Valid Loss: 0.96740\n",
            "[ Epoch 5355/10000 ] Train Loss: 1.03681   Valid Loss: 0.96561\n",
            "[ Epoch 5356/10000 ] Train Loss: 1.03378   Valid Loss: 0.96597\n",
            "[ Epoch 5357/10000 ] Train Loss: 1.03621   Valid Loss: 0.96739\n",
            "[ Epoch 5358/10000 ] Train Loss: 1.03314   Valid Loss: 0.96609\n",
            "[ Epoch 5359/10000 ] Train Loss: 1.03289   Valid Loss: 0.96444\n",
            "[ Epoch 5360/10000 ] Train Loss: 1.03185   Valid Loss: 0.96618\n",
            "[ Epoch 5361/10000 ] Train Loss: 1.03173   Valid Loss: 0.96499\n",
            "[ Epoch 5362/10000 ] Train Loss: 1.03287   Valid Loss: 0.96444\n",
            "[ Epoch 5363/10000 ] Train Loss: 1.03189   Valid Loss: 0.96576\n",
            "[ Epoch 5364/10000 ] Train Loss: 1.03253   Valid Loss: 0.96555\n",
            "[ Epoch 5365/10000 ] Train Loss: 1.03387   Valid Loss: 0.96622\n",
            "[ Epoch 5366/10000 ] Train Loss: 1.04198   Valid Loss: 0.97199\n",
            "[ Epoch 5367/10000 ] Train Loss: 1.03595   Valid Loss: 0.96430\n",
            "[ Epoch 5368/10000 ] Train Loss: 1.03365   Valid Loss: 0.96817\n",
            "[ Epoch 5369/10000 ] Train Loss: 1.03342   Valid Loss: 0.96506\n",
            "[ Epoch 5370/10000 ] Train Loss: 1.03229   Valid Loss: 0.96462\n",
            "[ Epoch 5371/10000 ] Train Loss: 1.03296   Valid Loss: 0.96562\n",
            "[ Epoch 5372/10000 ] Train Loss: 1.03258   Valid Loss: 0.96521\n",
            "[ Epoch 5373/10000 ] Train Loss: 1.03070   Valid Loss: 0.96451\n",
            "[ Epoch 5374/10000 ] Train Loss: 1.03188   Valid Loss: 0.96488\n",
            "[ Epoch 5375/10000 ] Train Loss: 1.03259   Valid Loss: 0.96484\n",
            "[ Epoch 5376/10000 ] Train Loss: 1.03252   Valid Loss: 0.96554\n",
            "[ Epoch 5377/10000 ] Train Loss: 1.03246   Valid Loss: 0.96932\n",
            "[ Epoch 5378/10000 ] Train Loss: 1.03716   Valid Loss: 0.96773\n",
            "[ Epoch 5379/10000 ] Train Loss: 1.03194   Valid Loss: 0.96619\n",
            "[ Epoch 5380/10000 ] Train Loss: 1.03241   Valid Loss: 0.96673\n",
            "[ Epoch 5381/10000 ] Train Loss: 1.03247   Valid Loss: 0.96438\n",
            "[ Epoch 5382/10000 ] Train Loss: 1.03094   Valid Loss: 0.96469\n",
            "[ Epoch 5383/10000 ] Train Loss: 1.03119   Valid Loss: 0.96687\n",
            "[ Epoch 5384/10000 ] Train Loss: 1.03179   Valid Loss: 0.96595\n",
            "[ Epoch 5385/10000 ] Train Loss: 1.03239   Valid Loss: 0.96402\n",
            "Early Stop Saving Model on Epoch 5385/10000\n",
            "[ Epoch 5386/10000 ] Train Loss: 1.03175   Valid Loss: 0.96566\n",
            "[ Epoch 5387/10000 ] Train Loss: 1.03326   Valid Loss: 0.96435\n",
            "[ Epoch 5388/10000 ] Train Loss: 1.03382   Valid Loss: 0.96726\n",
            "[ Epoch 5389/10000 ] Train Loss: 1.03552   Valid Loss: 0.97082\n",
            "[ Epoch 5390/10000 ] Train Loss: 1.03345   Valid Loss: 0.96451\n",
            "[ Epoch 5391/10000 ] Train Loss: 1.03455   Valid Loss: 0.96569\n",
            "[ Epoch 5392/10000 ] Train Loss: 1.03527   Valid Loss: 0.96535\n",
            "[ Epoch 5393/10000 ] Train Loss: 1.03460   Valid Loss: 0.96461\n",
            "[ Epoch 5394/10000 ] Train Loss: 1.03217   Valid Loss: 0.96500\n",
            "[ Epoch 5395/10000 ] Train Loss: 1.03113   Valid Loss: 0.96425\n",
            "[ Epoch 5396/10000 ] Train Loss: 1.03203   Valid Loss: 0.96405\n",
            "[ Epoch 5397/10000 ] Train Loss: 1.03245   Valid Loss: 0.96454\n",
            "[ Epoch 5398/10000 ] Train Loss: 1.03349   Valid Loss: 0.96828\n",
            "[ Epoch 5399/10000 ] Train Loss: 1.03005   Valid Loss: 0.96570\n",
            "[ Epoch 5400/10000 ] Train Loss: 1.03490   Valid Loss: 0.96489\n",
            "[ Epoch 5401/10000 ] Train Loss: 1.03322   Valid Loss: 0.96746\n",
            "[ Epoch 5402/10000 ] Train Loss: 1.03134   Valid Loss: 0.96759\n",
            "[ Epoch 5403/10000 ] Train Loss: 1.03314   Valid Loss: 0.96541\n",
            "[ Epoch 5404/10000 ] Train Loss: 1.03277   Valid Loss: 0.96555\n",
            "[ Epoch 5405/10000 ] Train Loss: 1.03403   Valid Loss: 0.96812\n",
            "[ Epoch 5406/10000 ] Train Loss: 1.03312   Valid Loss: 0.96330\n",
            "Early Stop Saving Model on Epoch 5406/10000\n",
            "[ Epoch 5407/10000 ] Train Loss: 1.03288   Valid Loss: 0.96617\n",
            "[ Epoch 5408/10000 ] Train Loss: 1.03243   Valid Loss: 0.96497\n",
            "[ Epoch 5409/10000 ] Train Loss: 1.03144   Valid Loss: 0.96456\n",
            "[ Epoch 5410/10000 ] Train Loss: 1.03336   Valid Loss: 0.96522\n",
            "[ Epoch 5411/10000 ] Train Loss: 1.03744   Valid Loss: 0.96799\n",
            "[ Epoch 5412/10000 ] Train Loss: 1.03446   Valid Loss: 0.96448\n",
            "[ Epoch 5413/10000 ] Train Loss: 1.03236   Valid Loss: 0.96571\n",
            "[ Epoch 5414/10000 ] Train Loss: 1.03221   Valid Loss: 0.96852\n",
            "[ Epoch 5415/10000 ] Train Loss: 1.03277   Valid Loss: 0.96578\n",
            "[ Epoch 5416/10000 ] Train Loss: 1.03300   Valid Loss: 0.96829\n",
            "[ Epoch 5417/10000 ] Train Loss: 1.03321   Valid Loss: 0.96482\n",
            "[ Epoch 5418/10000 ] Train Loss: 1.03178   Valid Loss: 0.96389\n",
            "[ Epoch 5419/10000 ] Train Loss: 1.03228   Valid Loss: 0.96464\n",
            "[ Epoch 5420/10000 ] Train Loss: 1.03562   Valid Loss: 0.96493\n",
            "[ Epoch 5421/10000 ] Train Loss: 1.03295   Valid Loss: 0.96408\n",
            "[ Epoch 5422/10000 ] Train Loss: 1.03204   Valid Loss: 0.96459\n",
            "[ Epoch 5423/10000 ] Train Loss: 1.03166   Valid Loss: 0.96425\n",
            "[ Epoch 5424/10000 ] Train Loss: 1.03095   Valid Loss: 0.96588\n",
            "[ Epoch 5425/10000 ] Train Loss: 1.03613   Valid Loss: 0.96951\n",
            "[ Epoch 5426/10000 ] Train Loss: 1.03502   Valid Loss: 0.96456\n",
            "[ Epoch 5427/10000 ] Train Loss: 1.03336   Valid Loss: 0.96509\n",
            "[ Epoch 5428/10000 ] Train Loss: 1.03250   Valid Loss: 0.96365\n",
            "[ Epoch 5429/10000 ] Train Loss: 1.03179   Valid Loss: 0.96721\n",
            "[ Epoch 5430/10000 ] Train Loss: 1.03254   Valid Loss: 0.96361\n",
            "[ Epoch 5431/10000 ] Train Loss: 1.03300   Valid Loss: 0.96989\n",
            "[ Epoch 5432/10000 ] Train Loss: 1.03473   Valid Loss: 0.97276\n",
            "[ Epoch 5433/10000 ] Train Loss: 1.03286   Valid Loss: 0.96344\n",
            "[ Epoch 5434/10000 ] Train Loss: 1.03209   Valid Loss: 0.96506\n",
            "[ Epoch 5435/10000 ] Train Loss: 1.03378   Valid Loss: 0.96483\n",
            "[ Epoch 5436/10000 ] Train Loss: 1.03488   Valid Loss: 0.96687\n",
            "[ Epoch 5437/10000 ] Train Loss: 1.03289   Valid Loss: 0.96882\n",
            "[ Epoch 5438/10000 ] Train Loss: 1.03631   Valid Loss: 0.96541\n",
            "[ Epoch 5439/10000 ] Train Loss: 1.03420   Valid Loss: 0.96503\n",
            "[ Epoch 5440/10000 ] Train Loss: 1.03186   Valid Loss: 0.96408\n",
            "[ Epoch 5441/10000 ] Train Loss: 1.03204   Valid Loss: 0.96559\n",
            "[ Epoch 5442/10000 ] Train Loss: 1.03318   Valid Loss: 0.96871\n",
            "[ Epoch 5443/10000 ] Train Loss: 1.03578   Valid Loss: 0.96455\n",
            "[ Epoch 5444/10000 ] Train Loss: 1.03407   Valid Loss: 0.96807\n",
            "[ Epoch 5445/10000 ] Train Loss: 1.03237   Valid Loss: 0.96562\n",
            "[ Epoch 5446/10000 ] Train Loss: 1.03425   Valid Loss: 0.96530\n",
            "[ Epoch 5447/10000 ] Train Loss: 1.03105   Valid Loss: 0.96502\n",
            "[ Epoch 5448/10000 ] Train Loss: 1.03162   Valid Loss: 0.96483\n",
            "[ Epoch 5449/10000 ] Train Loss: 1.03135   Valid Loss: 0.96299\n",
            "Early Stop Saving Model on Epoch 5449/10000\n",
            "[ Epoch 5450/10000 ] Train Loss: 1.03187   Valid Loss: 0.96416\n",
            "[ Epoch 5451/10000 ] Train Loss: 1.03139   Valid Loss: 0.96534\n",
            "[ Epoch 5452/10000 ] Train Loss: 1.03255   Valid Loss: 0.96446\n",
            "[ Epoch 5453/10000 ] Train Loss: 1.03256   Valid Loss: 0.96404\n",
            "[ Epoch 5454/10000 ] Train Loss: 1.03229   Valid Loss: 0.96821\n",
            "[ Epoch 5455/10000 ] Train Loss: 1.03290   Valid Loss: 0.97143\n",
            "[ Epoch 5456/10000 ] Train Loss: 1.04130   Valid Loss: 0.96612\n",
            "[ Epoch 5457/10000 ] Train Loss: 1.03514   Valid Loss: 0.96489\n",
            "[ Epoch 5458/10000 ] Train Loss: 1.03506   Valid Loss: 0.96991\n",
            "[ Epoch 5459/10000 ] Train Loss: 1.03241   Valid Loss: 0.96468\n",
            "[ Epoch 5460/10000 ] Train Loss: 1.03256   Valid Loss: 0.96808\n",
            "[ Epoch 5461/10000 ] Train Loss: 1.03365   Valid Loss: 0.96376\n",
            "[ Epoch 5462/10000 ] Train Loss: 1.03468   Valid Loss: 0.96573\n",
            "[ Epoch 5463/10000 ] Train Loss: 1.03228   Valid Loss: 0.96389\n",
            "[ Epoch 5464/10000 ] Train Loss: 1.03281   Valid Loss: 0.96621\n",
            "[ Epoch 5465/10000 ] Train Loss: 1.03400   Valid Loss: 0.96479\n",
            "[ Epoch 5466/10000 ] Train Loss: 1.03320   Valid Loss: 0.96461\n",
            "[ Epoch 5467/10000 ] Train Loss: 1.03320   Valid Loss: 0.96765\n",
            "[ Epoch 5468/10000 ] Train Loss: 1.03389   Valid Loss: 0.96710\n",
            "[ Epoch 5469/10000 ] Train Loss: 1.03292   Valid Loss: 0.96350\n",
            "[ Epoch 5470/10000 ] Train Loss: 1.03219   Valid Loss: 0.96772\n",
            "[ Epoch 5471/10000 ] Train Loss: 1.03441   Valid Loss: 0.96374\n",
            "[ Epoch 5472/10000 ] Train Loss: 1.03200   Valid Loss: 0.96448\n",
            "[ Epoch 5473/10000 ] Train Loss: 1.03250   Valid Loss: 0.96443\n",
            "[ Epoch 5474/10000 ] Train Loss: 1.03185   Valid Loss: 0.96554\n",
            "[ Epoch 5475/10000 ] Train Loss: 1.03067   Valid Loss: 0.96560\n",
            "[ Epoch 5476/10000 ] Train Loss: 1.03155   Valid Loss: 0.96444\n",
            "[ Epoch 5477/10000 ] Train Loss: 1.03256   Valid Loss: 0.96426\n",
            "[ Epoch 5478/10000 ] Train Loss: 1.03193   Valid Loss: 0.96644\n",
            "[ Epoch 5479/10000 ] Train Loss: 1.03221   Valid Loss: 0.96324\n",
            "[ Epoch 5480/10000 ] Train Loss: 1.03134   Valid Loss: 0.96334\n",
            "[ Epoch 5481/10000 ] Train Loss: 1.03233   Valid Loss: 0.96454\n",
            "[ Epoch 5482/10000 ] Train Loss: 1.03171   Valid Loss: 0.96602\n",
            "[ Epoch 5483/10000 ] Train Loss: 1.03344   Valid Loss: 0.96415\n",
            "[ Epoch 5484/10000 ] Train Loss: 1.03312   Valid Loss: 0.96689\n",
            "[ Epoch 5485/10000 ] Train Loss: 1.03441   Valid Loss: 0.96664\n",
            "[ Epoch 5486/10000 ] Train Loss: 1.03259   Valid Loss: 0.96371\n",
            "[ Epoch 5487/10000 ] Train Loss: 1.03124   Valid Loss: 0.96431\n",
            "[ Epoch 5488/10000 ] Train Loss: 1.03148   Valid Loss: 0.96612\n",
            "[ Epoch 5489/10000 ] Train Loss: 1.03293   Valid Loss: 0.96423\n",
            "[ Epoch 5490/10000 ] Train Loss: 1.03072   Valid Loss: 0.96533\n",
            "[ Epoch 5491/10000 ] Train Loss: 1.03196   Valid Loss: 0.96858\n",
            "[ Epoch 5492/10000 ] Train Loss: 1.03486   Valid Loss: 0.97185\n",
            "[ Epoch 5493/10000 ] Train Loss: 1.03407   Valid Loss: 0.96693\n",
            "[ Epoch 5494/10000 ] Train Loss: 1.03276   Valid Loss: 0.96398\n",
            "[ Epoch 5495/10000 ] Train Loss: 1.03148   Valid Loss: 0.96415\n",
            "[ Epoch 5496/10000 ] Train Loss: 1.03342   Valid Loss: 0.96695\n",
            "[ Epoch 5497/10000 ] Train Loss: 1.03278   Valid Loss: 0.96452\n",
            "[ Epoch 5498/10000 ] Train Loss: 1.03193   Valid Loss: 0.96426\n",
            "[ Epoch 5499/10000 ] Train Loss: 1.03237   Valid Loss: 0.96428\n",
            "[ Epoch 5500/10000 ] Train Loss: 1.03298   Valid Loss: 0.96591\n",
            "[ Epoch 5501/10000 ] Train Loss: 1.03293   Valid Loss: 0.96504\n",
            "[ Epoch 5502/10000 ] Train Loss: 1.03161   Valid Loss: 0.96310\n",
            "[ Epoch 5503/10000 ] Train Loss: 1.03190   Valid Loss: 0.96513\n",
            "[ Epoch 5504/10000 ] Train Loss: 1.03287   Valid Loss: 0.96618\n",
            "[ Epoch 5505/10000 ] Train Loss: 1.03176   Valid Loss: 0.96548\n",
            "[ Epoch 5506/10000 ] Train Loss: 1.03319   Valid Loss: 0.96391\n",
            "[ Epoch 5507/10000 ] Train Loss: 1.03094   Valid Loss: 0.96364\n",
            "[ Epoch 5508/10000 ] Train Loss: 1.03175   Valid Loss: 0.96593\n",
            "[ Epoch 5509/10000 ] Train Loss: 1.03266   Valid Loss: 0.96804\n",
            "[ Epoch 5510/10000 ] Train Loss: 1.03061   Valid Loss: 0.96702\n",
            "[ Epoch 5511/10000 ] Train Loss: 1.03517   Valid Loss: 0.96500\n",
            "[ Epoch 5512/10000 ] Train Loss: 1.03030   Valid Loss: 0.96451\n",
            "[ Epoch 5513/10000 ] Train Loss: 1.03030   Valid Loss: 0.96355\n",
            "[ Epoch 5514/10000 ] Train Loss: 1.03329   Valid Loss: 0.96709\n",
            "[ Epoch 5515/10000 ] Train Loss: 1.03269   Valid Loss: 0.96504\n",
            "[ Epoch 5516/10000 ] Train Loss: 1.03282   Valid Loss: 0.96678\n",
            "[ Epoch 5517/10000 ] Train Loss: 1.03360   Valid Loss: 0.96530\n",
            "[ Epoch 5518/10000 ] Train Loss: 1.03181   Valid Loss: 0.96443\n",
            "[ Epoch 5519/10000 ] Train Loss: 1.03208   Valid Loss: 0.96394\n",
            "[ Epoch 5520/10000 ] Train Loss: 1.03231   Valid Loss: 0.96516\n",
            "[ Epoch 5521/10000 ] Train Loss: 1.03278   Valid Loss: 0.96465\n",
            "[ Epoch 5522/10000 ] Train Loss: 1.03197   Valid Loss: 0.96445\n",
            "[ Epoch 5523/10000 ] Train Loss: 1.03139   Valid Loss: 0.96363\n",
            "[ Epoch 5524/10000 ] Train Loss: 1.03114   Valid Loss: 0.96528\n",
            "[ Epoch 5525/10000 ] Train Loss: 1.03374   Valid Loss: 0.96414\n",
            "[ Epoch 5526/10000 ] Train Loss: 1.03951   Valid Loss: 0.96967\n",
            "[ Epoch 5527/10000 ] Train Loss: 1.03359   Valid Loss: 0.96634\n",
            "[ Epoch 5528/10000 ] Train Loss: 1.03233   Valid Loss: 0.96321\n",
            "[ Epoch 5529/10000 ] Train Loss: 1.03251   Valid Loss: 0.96757\n",
            "[ Epoch 5530/10000 ] Train Loss: 1.03596   Valid Loss: 0.97476\n",
            "[ Epoch 5531/10000 ] Train Loss: 1.03167   Valid Loss: 0.96336\n",
            "[ Epoch 5532/10000 ] Train Loss: 1.03066   Valid Loss: 0.96436\n",
            "[ Epoch 5533/10000 ] Train Loss: 1.03453   Valid Loss: 0.96458\n",
            "[ Epoch 5534/10000 ] Train Loss: 1.03458   Valid Loss: 0.96813\n",
            "[ Epoch 5535/10000 ] Train Loss: 1.03438   Valid Loss: 0.96980\n",
            "[ Epoch 5536/10000 ] Train Loss: 1.03371   Valid Loss: 0.96662\n",
            "[ Epoch 5537/10000 ] Train Loss: 1.03236   Valid Loss: 0.96405\n",
            "[ Epoch 5538/10000 ] Train Loss: 1.03284   Valid Loss: 0.96429\n",
            "[ Epoch 5539/10000 ] Train Loss: 1.03227   Valid Loss: 0.96540\n",
            "[ Epoch 5540/10000 ] Train Loss: 1.03244   Valid Loss: 0.96552\n",
            "[ Epoch 5541/10000 ] Train Loss: 1.03377   Valid Loss: 0.96468\n",
            "[ Epoch 5542/10000 ] Train Loss: 1.03178   Valid Loss: 0.96661\n",
            "[ Epoch 5543/10000 ] Train Loss: 1.03134   Valid Loss: 0.96388\n",
            "[ Epoch 5544/10000 ] Train Loss: 1.03458   Valid Loss: 0.96632\n",
            "[ Epoch 5545/10000 ] Train Loss: 1.03294   Valid Loss: 0.96754\n",
            "[ Epoch 5546/10000 ] Train Loss: 1.03714   Valid Loss: 0.97246\n",
            "[ Epoch 5547/10000 ] Train Loss: 1.03549   Valid Loss: 0.96372\n",
            "[ Epoch 5548/10000 ] Train Loss: 1.03122   Valid Loss: 0.96458\n",
            "[ Epoch 5549/10000 ] Train Loss: 1.03138   Valid Loss: 0.96421\n",
            "[ Epoch 5550/10000 ] Train Loss: 1.03109   Valid Loss: 0.96512\n",
            "[ Epoch 5551/10000 ] Train Loss: 1.03172   Valid Loss: 0.96493\n",
            "[ Epoch 5552/10000 ] Train Loss: 1.03234   Valid Loss: 0.96510\n",
            "[ Epoch 5553/10000 ] Train Loss: 1.03192   Valid Loss: 0.96519\n",
            "[ Epoch 5554/10000 ] Train Loss: 1.03170   Valid Loss: 0.96455\n",
            "[ Epoch 5555/10000 ] Train Loss: 1.03208   Valid Loss: 0.96440\n",
            "[ Epoch 5556/10000 ] Train Loss: 1.03271   Valid Loss: 0.96730\n",
            "[ Epoch 5557/10000 ] Train Loss: 1.03614   Valid Loss: 0.96638\n",
            "[ Epoch 5558/10000 ] Train Loss: 1.03482   Valid Loss: 0.96575\n",
            "[ Epoch 5559/10000 ] Train Loss: 1.03412   Valid Loss: 0.96536\n",
            "[ Epoch 5560/10000 ] Train Loss: 1.03405   Valid Loss: 0.96771\n",
            "[ Epoch 5561/10000 ] Train Loss: 1.03203   Valid Loss: 0.96532\n",
            "[ Epoch 5562/10000 ] Train Loss: 1.03201   Valid Loss: 0.96624\n",
            "[ Epoch 5563/10000 ] Train Loss: 1.03204   Valid Loss: 0.96494\n",
            "[ Epoch 5564/10000 ] Train Loss: 1.03347   Valid Loss: 0.96454\n",
            "[ Epoch 5565/10000 ] Train Loss: 1.03221   Valid Loss: 0.96531\n",
            "[ Epoch 5566/10000 ] Train Loss: 1.03374   Valid Loss: 0.96872\n",
            "[ Epoch 5567/10000 ] Train Loss: 1.03693   Valid Loss: 0.96387\n",
            "[ Epoch 5568/10000 ] Train Loss: 1.03714   Valid Loss: 0.96520\n",
            "[ Epoch 5569/10000 ] Train Loss: 1.02815   Valid Loss: 0.96461\n",
            "[ Epoch 5570/10000 ] Train Loss: 1.03221   Valid Loss: 0.96365\n",
            "[ Epoch 5571/10000 ] Train Loss: 1.03132   Valid Loss: 0.96596\n",
            "[ Epoch 5572/10000 ] Train Loss: 1.03338   Valid Loss: 0.96507\n",
            "[ Epoch 5573/10000 ] Train Loss: 1.03164   Valid Loss: 0.96489\n",
            "[ Epoch 5574/10000 ] Train Loss: 1.03194   Valid Loss: 0.97053\n",
            "[ Epoch 5575/10000 ] Train Loss: 1.03462   Valid Loss: 0.96440\n",
            "[ Epoch 5576/10000 ] Train Loss: 1.02958   Valid Loss: 0.96487\n",
            "[ Epoch 5577/10000 ] Train Loss: 1.03237   Valid Loss: 0.96779\n",
            "[ Epoch 5578/10000 ] Train Loss: 1.03300   Valid Loss: 0.96968\n",
            "[ Epoch 5579/10000 ] Train Loss: 1.03265   Valid Loss: 0.96944\n",
            "[ Epoch 5580/10000 ] Train Loss: 1.03540   Valid Loss: 0.96406\n",
            "[ Epoch 5581/10000 ] Train Loss: 1.03214   Valid Loss: 0.96443\n",
            "[ Epoch 5582/10000 ] Train Loss: 1.03244   Valid Loss: 0.96786\n",
            "[ Epoch 5583/10000 ] Train Loss: 1.03199   Valid Loss: 0.96790\n",
            "[ Epoch 5584/10000 ] Train Loss: 1.03189   Valid Loss: 0.96748\n",
            "[ Epoch 5585/10000 ] Train Loss: 1.03176   Valid Loss: 0.96388\n",
            "[ Epoch 5586/10000 ] Train Loss: 1.03372   Valid Loss: 0.96594\n",
            "[ Epoch 5587/10000 ] Train Loss: 1.03155   Valid Loss: 0.96622\n",
            "[ Epoch 5588/10000 ] Train Loss: 1.03065   Valid Loss: 0.96629\n",
            "[ Epoch 5589/10000 ] Train Loss: 1.03498   Valid Loss: 0.96855\n",
            "[ Epoch 5590/10000 ] Train Loss: 1.03217   Valid Loss: 0.96389\n",
            "[ Epoch 5591/10000 ] Train Loss: 1.03243   Valid Loss: 0.96344\n",
            "[ Epoch 5592/10000 ] Train Loss: 1.03470   Valid Loss: 0.96992\n",
            "[ Epoch 5593/10000 ] Train Loss: 1.03208   Valid Loss: 0.96470\n",
            "[ Epoch 5594/10000 ] Train Loss: 1.03229   Valid Loss: 0.96457\n",
            "[ Epoch 5595/10000 ] Train Loss: 1.03294   Valid Loss: 0.96424\n",
            "[ Epoch 5596/10000 ] Train Loss: 1.03246   Valid Loss: 0.96436\n",
            "[ Epoch 5597/10000 ] Train Loss: 1.03161   Valid Loss: 0.96539\n",
            "[ Epoch 5598/10000 ] Train Loss: 1.03458   Valid Loss: 0.96511\n",
            "[ Epoch 5599/10000 ] Train Loss: 1.03572   Valid Loss: 0.96954\n",
            "[ Epoch 5600/10000 ] Train Loss: 1.03509   Valid Loss: 0.96613\n",
            "[ Epoch 5601/10000 ] Train Loss: 1.03302   Valid Loss: 0.96812\n",
            "[ Epoch 5602/10000 ] Train Loss: 1.03208   Valid Loss: 0.96512\n",
            "[ Epoch 5603/10000 ] Train Loss: 1.03165   Valid Loss: 0.96735\n",
            "[ Epoch 5604/10000 ] Train Loss: 1.03484   Valid Loss: 0.96909\n",
            "[ Epoch 5605/10000 ] Train Loss: 1.03174   Valid Loss: 0.97363\n",
            "[ Epoch 5606/10000 ] Train Loss: 1.03940   Valid Loss: 0.96506\n",
            "[ Epoch 5607/10000 ] Train Loss: 1.03333   Valid Loss: 0.96359\n",
            "[ Epoch 5608/10000 ] Train Loss: 1.03697   Valid Loss: 0.96920\n",
            "[ Epoch 5609/10000 ] Train Loss: 1.03392   Valid Loss: 0.96402\n",
            "[ Epoch 5610/10000 ] Train Loss: 1.03259   Valid Loss: 0.96441\n",
            "[ Epoch 5611/10000 ] Train Loss: 1.03174   Valid Loss: 0.97001\n",
            "[ Epoch 5612/10000 ] Train Loss: 1.03115   Valid Loss: 0.96354\n",
            "[ Epoch 5613/10000 ] Train Loss: 1.03175   Valid Loss: 0.96449\n",
            "[ Epoch 5614/10000 ] Train Loss: 1.03145   Valid Loss: 0.96468\n",
            "[ Epoch 5615/10000 ] Train Loss: 1.03116   Valid Loss: 0.96532\n",
            "[ Epoch 5616/10000 ] Train Loss: 1.03150   Valid Loss: 0.96397\n",
            "[ Epoch 5617/10000 ] Train Loss: 1.03254   Valid Loss: 0.96782\n",
            "[ Epoch 5618/10000 ] Train Loss: 1.03150   Valid Loss: 0.96416\n",
            "[ Epoch 5619/10000 ] Train Loss: 1.03297   Valid Loss: 0.96342\n",
            "[ Epoch 5620/10000 ] Train Loss: 1.03181   Valid Loss: 0.96584\n",
            "[ Epoch 5621/10000 ] Train Loss: 1.03163   Valid Loss: 0.96465\n",
            "[ Epoch 5622/10000 ] Train Loss: 1.03217   Valid Loss: 0.96382\n",
            "[ Epoch 5623/10000 ] Train Loss: 1.03208   Valid Loss: 0.96402\n",
            "[ Epoch 5624/10000 ] Train Loss: 1.03210   Valid Loss: 0.96361\n",
            "[ Epoch 5625/10000 ] Train Loss: 1.03189   Valid Loss: 0.96500\n",
            "[ Epoch 5626/10000 ] Train Loss: 1.03179   Valid Loss: 0.96449\n",
            "[ Epoch 5627/10000 ] Train Loss: 1.03100   Valid Loss: 0.96396\n",
            "[ Epoch 5628/10000 ] Train Loss: 1.03122   Valid Loss: 0.96471\n",
            "[ Epoch 5629/10000 ] Train Loss: 1.03210   Valid Loss: 0.96411\n",
            "[ Epoch 5630/10000 ] Train Loss: 1.03078   Valid Loss: 0.96428\n",
            "[ Epoch 5631/10000 ] Train Loss: 1.03269   Valid Loss: 0.96672\n",
            "[ Epoch 5632/10000 ] Train Loss: 1.03197   Valid Loss: 0.96605\n",
            "[ Epoch 5633/10000 ] Train Loss: 1.03328   Valid Loss: 0.96386\n",
            "[ Epoch 5634/10000 ] Train Loss: 1.03042   Valid Loss: 0.96594\n",
            "[ Epoch 5635/10000 ] Train Loss: 1.03184   Valid Loss: 0.96466\n",
            "[ Epoch 5636/10000 ] Train Loss: 1.03305   Valid Loss: 0.96410\n",
            "[ Epoch 5637/10000 ] Train Loss: 1.03260   Valid Loss: 0.96482\n",
            "[ Epoch 5638/10000 ] Train Loss: 1.03289   Valid Loss: 0.96571\n",
            "[ Epoch 5639/10000 ] Train Loss: 1.03298   Valid Loss: 0.96511\n",
            "[ Epoch 5640/10000 ] Train Loss: 1.03277   Valid Loss: 0.96572\n",
            "[ Epoch 5641/10000 ] Train Loss: 1.03161   Valid Loss: 0.96526\n",
            "[ Epoch 5642/10000 ] Train Loss: 1.03319   Valid Loss: 0.96668\n",
            "[ Epoch 5643/10000 ] Train Loss: 1.03413   Valid Loss: 0.97249\n",
            "[ Epoch 5644/10000 ] Train Loss: 1.03316   Valid Loss: 0.96700\n",
            "[ Epoch 5645/10000 ] Train Loss: 1.03224   Valid Loss: 0.96664\n",
            "[ Epoch 5646/10000 ] Train Loss: 1.03283   Valid Loss: 0.96420\n",
            "[ Epoch 5647/10000 ] Train Loss: 1.03159   Valid Loss: 0.96446\n",
            "[ Epoch 5648/10000 ] Train Loss: 1.03309   Valid Loss: 0.96471\n",
            "[ Epoch 5649/10000 ] Train Loss: 1.03174   Valid Loss: 0.96452\n",
            "[ Epoch 5650/10000 ] Train Loss: 1.03517   Valid Loss: 0.96742\n",
            "Finish Train After 5650 Epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "2eJavM6meM9T",
        "outputId": "6fbc4267-7fb5-4594-ccf2-5aaff2739fd2"
      },
      "source": [
        "plot_learning_curve(loss_record, title='DNN Model')"
      ],
      "execution_count": 1155,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 382.603125 277.314375\" width=\"382.603125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 277.314375 \nL 382.603125 277.314375 \nL 382.603125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 40.603125 239.758125 \nL 375.403125 239.758125 \nL 375.403125 22.318125 \nL 40.603125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0d93081d2e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"55.821307\" xlink:href=\"#m0d93081d2e\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(52.640057 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"109.700513\" xlink:href=\"#m0d93081d2e\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(96.975513 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"163.579719\" xlink:href=\"#m0d93081d2e\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2000 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(150.854719 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"217.458926\" xlink:href=\"#m0d93081d2e\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3000 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(204.733926 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.338132\" xlink:href=\"#m0d93081d2e\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4000 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(258.613132 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"325.217338\" xlink:href=\"#m0d93081d2e\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5000 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(312.492338 254.356562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(192.692187 268.034687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m9b4c2ef601\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m9b4c2ef601\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(27.240625 243.557344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m9b4c2ef601\" y=\"196.270125\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2 -->\n      <g transform=\"translate(27.240625 200.069344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m9b4c2ef601\" y=\"152.782125\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 4 -->\n      <g transform=\"translate(27.240625 156.581344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m9b4c2ef601\" y=\"109.294125\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(27.240625 113.093344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m9b4c2ef601\" y=\"65.806125\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(27.240625 69.605344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m9b4c2ef601\" y=\"22.318125\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 10 -->\n      <g transform=\"translate(20.878125 26.117344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Loss -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(14.798438 142.005312)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#p54593d48fa)\" d=\"M 56.831553 -1 \nL 57.545441 82.84388 \nL 58.138113 171.349319 \nL 58.407509 179.291935 \nL 58.892422 185.843404 \nL 59.64673 193.15774 \nL 60.562677 200.109251 \nL 62.017416 207.278333 \nL 62.771724 209.538336 \nL 62.879483 209.718994 \nL 63.418275 210.712823 \nL 63.472154 210.691815 \nL 63.687671 210.933836 \nL 63.957067 211.156826 \nL 64.226463 211.415288 \nL 64.765255 211.624594 \nL 64.873013 211.508845 \nL 65.034651 211.735793 \nL 65.304047 211.838799 \nL 65.573443 211.904062 \nL 66.058356 211.992742 \nL 66.112235 211.931585 \nL 66.166114 211.982132 \nL 67.998007 212.414161 \nL 68.051887 212.219465 \nL 68.105766 212.352903 \nL 68.321283 212.450904 \nL 68.752316 212.40141 \nL 68.913954 212.500285 \nL 69.021712 212.508123 \nL 69.291108 212.574786 \nL 69.8299 212.597078 \nL 69.937659 212.700409 \nL 70.207055 212.56935 \nL 70.368693 212.681489 \nL 70.422572 212.613434 \nL 70.53033 212.703153 \nL 70.584209 212.657221 \nL 70.638089 212.720704 \nL 73.385928 212.91788 \nL 73.493686 212.935157 \nL 76.403164 213.232965 \nL 76.510922 213.19568 \nL 76.67256 213.254463 \nL 77.696265 213.282756 \nL 77.911781 213.32705 \nL 80.120829 213.441811 \nL 80.282466 213.454232 \nL 80.929017 213.475499 \nL 81.198413 213.537432 \nL 81.252292 213.452085 \nL 81.306171 213.522132 \nL 81.521688 213.525053 \nL 81.737205 213.560901 \nL 81.791084 213.557749 \nL 81.844963 213.436416 \nL 81.898843 213.50844 \nL 82.06048 213.547522 \nL 82.275997 213.61966 \nL 82.437635 213.590391 \nL 82.707031 213.627942 \nL 82.76091 213.561907 \nL 82.814789 213.611851 \nL 83.030306 213.639958 \nL 85.023837 213.708328 \nL 85.239353 213.72493 \nL 85.400991 213.732162 \nL 85.724266 213.72997 \nL 86.101421 213.778054 \nL 86.370817 213.665839 \nL 86.532454 213.77454 \nL 86.694092 213.745898 \nL 86.85573 213.769796 \nL 87.232884 213.805355 \nL 87.286763 213.84439 \nL 87.340643 213.755879 \nL 87.610039 213.759518 \nL 87.663918 213.836009 \nL 87.717797 213.789188 \nL 88.310468 213.817989 \nL 89.172536 213.852527 \nL 89.280294 213.773022 \nL 89.441932 213.857701 \nL 89.495811 213.877923 \nL 89.54969 213.7703 \nL 89.603569 213.845452 \nL 90.034603 213.891673 \nL 90.842791 213.897885 \nL 90.89667 213.74392 \nL 90.950549 213.904792 \nL 101.025961 214.228949 \nL 101.07984 214.098247 \nL 101.133719 214.222114 \nL 101.295357 214.332061 \nL 101.403115 214.191463 \nL 101.456995 214.22935 \nL 102.265183 214.228421 \nL 102.42682 214.292783 \nL 102.588458 214.218596 \nL 102.642337 214.13631 \nL 102.750096 214.305253 \nL 102.803975 214.270096 \nL 103.181129 214.289043 \nL 104.420351 214.402057 \nL 104.47423 214.439963 \nL 104.528109 214.350526 \nL 104.851385 214.358451 \nL 104.905264 214.233191 \nL 104.959143 214.342858 \nL 105.228539 214.428971 \nL 105.390177 214.415909 \nL 107.006553 214.492393 \nL 107.545345 214.487776 \nL 107.706982 214.493933 \nL 110.61646 214.638303 \nL 110.885856 214.668535 \nL 110.993614 214.62498 \nL 111.209131 214.655906 \nL 111.478527 214.66208 \nL 111.586285 214.441443 \nL 111.747923 214.677817 \nL 111.855681 214.656332 \nL 112.017319 214.696546 \nL 112.933265 214.738291 \nL 112.987145 214.622115 \nL 113.041024 214.719604 \nL 113.202662 214.730531 \nL 113.364299 214.80042 \nL 113.418178 214.611442 \nL 113.472058 214.717552 \nL 113.687574 214.741878 \nL 113.903091 214.811912 \nL 115.734984 214.85191 \nL 116.650931 214.890386 \nL 116.812568 214.871736 \nL 116.974206 214.930148 \nL 117.135844 214.904018 \nL 117.944032 214.849974 \nL 118.05179 214.870964 \nL 118.536703 214.964521 \nL 119.237133 214.945629 \nL 119.39877 214.974948 \nL 119.668166 214.978894 \nL 120.045321 214.888761 \nL 120.206958 215.013672 \nL 120.691871 215.005245 \nL 120.74575 215.067738 \nL 120.79963 215.001361 \nL 121.715576 215.030254 \nL 121.931093 215.016387 \nL 122.092731 215.028027 \nL 122.523764 215.081706 \nL 126.780222 215.173857 \nL 126.941859 215.203832 \nL 127.426772 215.234121 \nL 127.53453 215.243972 \nL 127.58841 215.177636 \nL 127.642289 215.246186 \nL 128.019443 215.234061 \nL 128.665994 215.260823 \nL 128.881511 215.103252 \nL 128.989269 215.324029 \nL 129.097027 215.282617 \nL 129.258665 215.320589 \nL 129.528061 215.288607 \nL 129.689699 215.294583 \nL 130.821162 215.329076 \nL 131.144437 215.386271 \nL 131.521592 215.33458 \nL 131.683229 215.3977 \nL 131.844867 215.354713 \nL 131.952625 215.361732 \nL 132.168142 215.341193 \nL 132.32978 215.394151 \nL 133.191847 215.419399 \nL 133.515122 215.458708 \nL 133.622881 215.354201 \nL 133.784518 215.454833 \nL 134.32331 215.461308 \nL 134.646586 215.495694 \nL 135.778049 215.520618 \nL 135.993566 215.518334 \nL 136.155203 215.576804 \nL 136.424599 215.557546 \nL 136.640116 215.533683 \nL 136.693995 215.467976 \nL 136.747875 215.528303 \nL 137.663821 215.583974 \nL 137.77158 215.570299 \nL 138.040976 215.573876 \nL 138.094855 215.467192 \nL 138.148734 215.536554 \nL 138.525888 215.624623 \nL 138.687526 215.58014 \nL 139.010801 215.640186 \nL 139.495714 215.619063 \nL 139.711231 215.673111 \nL 139.926748 215.614053 \nL 140.088385 215.594671 \nL 140.250023 215.675829 \nL 140.627178 215.68193 \nL 140.734936 215.663732 \nL 141.058211 215.67023 \nL 141.219849 215.70125 \nL 141.381486 215.61167 \nL 141.650882 215.727967 \nL 141.866399 215.734973 \nL 142.135795 215.750262 \nL 142.297433 215.663414 \nL 142.566829 215.729854 \nL 142.836225 215.763764 \nL 142.890104 215.635217 \nL 142.943983 215.730115 \nL 144.775876 215.812867 \nL 144.937514 215.732255 \nL 145.099152 215.748822 \nL 149.30173 215.778546 \nL 149.355609 215.741601 \nL 149.517247 215.857866 \nL 149.625005 215.881899 \nL 149.786643 215.856396 \nL 149.94828 215.933541 \nL 150.163797 215.90989 \nL 150.325435 215.884735 \nL 150.433193 215.89513 \nL 150.487072 215.798034 \nL 150.540951 215.89344 \nL 151.025864 215.847046 \nL 151.187502 215.912009 \nL 151.99569 215.953795 \nL 152.265086 215.917919 \nL 153.288791 215.910825 \nL 153.612066 215.925349 \nL 153.719825 215.917419 \nL 153.773704 215.81216 \nL 153.827583 215.908742 \nL 154.096979 215.933164 \nL 154.635771 215.945422 \nL 155.012926 215.933057 \nL 155.174563 215.905317 \nL 155.605597 216.016182 \nL 155.767234 215.956882 \nL 156.09051 215.988841 \nL 156.252147 215.963788 \nL 156.413785 215.974044 \nL 156.467664 215.900841 \nL 156.521543 215.975835 \nL 156.790939 215.995 \nL 157.060335 215.932176 \nL 157.329731 215.989429 \nL 158.08404 215.983748 \nL 158.461195 215.990038 \nL 158.622832 215.932264 \nL 158.838349 216.013758 \nL 158.892228 215.919754 \nL 158.946108 216.024517 \nL 159.323262 215.900589 \nL 159.4849 216.030249 \nL 159.700417 216.012654 \nL 160.670242 216.01291 \nL 160.83188 215.988604 \nL 160.993518 216.033847 \nL 161.316793 216.026804 \nL 161.47843 215.990261 \nL 161.640068 216.055651 \nL 161.801706 216.044299 \nL 162.502135 216.100411 \nL 162.663773 216.032258 \nL 163.094807 216.003942 \nL 163.52584 216.032698 \nL 163.687478 216.009241 \nL 169.129278 216.068259 \nL 169.344794 215.992463 \nL 169.560311 216.156022 \nL 169.721949 216.134532 \nL 170.368499 216.100279 \nL 170.530137 216.145002 \nL 170.637895 216.134876 \nL 170.799533 216.127202 \nL 171.392204 216.126533 \nL 171.553842 216.152232 \nL 171.6616 216.119181 \nL 171.984876 216.177517 \nL 172.254272 216.150773 \nL 176.887883 216.174242 \nL 177.049521 216.207808 \nL 177.211159 216.139877 \nL 177.318917 216.169398 \nL 177.642192 216.113395 \nL 177.80383 216.199645 \nL 178.073226 216.1836 \nL 178.180984 216.18505 \nL 178.234864 216.102498 \nL 178.288743 216.147523 \nL 178.989172 216.201799 \nL 179.366327 216.195439 \nL 179.635723 216.174859 \nL 179.797361 216.131305 \nL 180.012877 216.213111 \nL 181.19822 216.150364 \nL 181.252099 216.240142 \nL 181.305978 216.203372 \nL 181.521495 216.163581 \nL 181.737012 216.211065 \nL 181.952529 216.136969 \nL 182.114166 216.214681 \nL 182.329683 216.187832 \nL 182.652958 216.207566 \nL 182.868475 216.217165 \nL 183.191751 216.244663 \nL 183.407267 216.242177 \nL 185.777952 216.209173 \nL 185.831832 216.264014 \nL 185.885711 216.164466 \nL 186.155107 216.259942 \nL 186.909416 216.203876 \nL 187.017174 216.246813 \nL 187.28657 216.197321 \nL 187.502087 216.252104 \nL 187.933121 216.218406 \nL 187.987 216.135277 \nL 188.040879 216.188324 \nL 188.256396 216.244428 \nL 188.471913 216.265298 \nL 188.741309 216.271851 \nL 189.118463 216.243314 \nL 189.711134 216.277584 \nL 189.872772 216.231261 \nL 190.03441 216.26496 \nL 190.196047 216.27764 \nL 192.243457 216.295349 \nL 192.351216 216.191391 \nL 192.512853 216.300945 \nL 192.674491 216.224909 \nL 192.943887 216.303139 \nL 193.159404 216.262169 \nL 193.752075 216.27792 \nL 193.913713 216.288738 \nL 194.129229 216.279154 \nL 194.614142 216.269959 \nL 194.883538 216.293332 \nL 195.099055 216.252055 \nL 195.314572 216.299727 \nL 195.691726 216.082504 \nL 195.853364 216.249402 \nL 196.015002 216.2703 \nL 196.068881 216.366001 \nL 196.12276 216.27683 \nL 196.230518 216.263502 \nL 196.284398 216.155159 \nL 196.338277 216.312201 \nL 196.392156 216.285916 \nL 196.446035 216.232672 \nL 196.499914 216.287232 \nL 197.415861 216.2846 \nL 197.46974 216.19902 \nL 197.523619 216.296713 \nL 197.900774 216.308644 \nL 198.224049 216.295936 \nL 198.277928 216.288623 \nL 198.331807 216.124578 \nL 198.385687 216.362451 \nL 198.439566 216.305457 \nL 198.655083 216.306326 \nL 199.51715 216.301763 \nL 199.678788 216.298897 \nL 199.840425 216.283106 \nL 200.325338 216.283811 \nL 200.379217 216.201033 \nL 200.433097 216.310143 \nL 201.241285 216.258536 \nL 201.295164 216.181392 \nL 201.349043 216.264565 \nL 201.56456 216.311123 \nL 202.21111 216.316075 \nL 202.26499 216.383614 \nL 202.318869 216.340423 \nL 202.696023 216.299295 \nL 202.857661 216.357949 \nL 203.396453 216.290019 \nL 203.773607 216.361264 \nL 204.096883 216.345081 \nL 207.221877 216.39112 \nL 207.275756 216.188078 \nL 207.329635 216.35851 \nL 207.437393 216.372611 \nL 207.599031 216.220607 \nL 207.814548 216.380545 \nL 208.946011 216.348329 \nL 208.99989 216.38851 \nL 209.05377 216.303518 \nL 209.269286 216.301387 \nL 209.430924 216.40947 \nL 209.592562 216.343438 \nL 209.70032 216.35833 \nL 209.808078 216.322156 \nL 210.239112 216.421003 \nL 210.454629 216.382136 \nL 210.616267 216.400314 \nL 211.0473 216.343827 \nL 211.532213 216.433152 \nL 211.586092 216.320429 \nL 211.639971 216.377095 \nL 212.071005 216.386566 \nL 213.09471 216.38327 \nL 213.256348 216.405045 \nL 213.417985 216.418689 \nL 213.579623 216.41625 \nL 214.064536 216.393129 \nL 214.226173 216.404296 \nL 214.818845 216.458597 \nL 214.980482 216.370299 \nL 215.195999 216.448207 \nL 215.411516 216.433729 \nL 216.111946 216.402337 \nL 216.327462 216.407399 \nL 216.704617 216.469243 \nL 216.812375 216.391838 \nL 216.866254 216.449337 \nL 217.728322 216.429403 \nL 217.782201 216.289302 \nL 217.943839 216.439145 \nL 219.129181 216.484006 \nL 219.452456 216.40273 \nL 219.614094 216.491815 \nL 219.775732 216.465744 \nL 219.937369 216.412773 \nL 220.206765 216.502025 \nL 220.53004 216.391499 \nL 220.691678 216.419966 \nL 220.853316 216.417545 \nL 221.122712 216.465604 \nL 221.284349 216.491281 \nL 222.308054 216.514077 \nL 222.57745 216.515452 \nL 222.739088 216.49413 \nL 223.493397 216.505909 \nL 224.786498 216.523155 \nL 225.217531 216.558754 \nL 225.379169 216.524911 \nL 225.594686 216.538712 \nL 225.864082 216.516695 \nL 226.510632 216.460936 \nL 227.103304 216.50054 \nL 227.31882 216.55631 \nL 227.749854 216.547968 \nL 232.221828 216.53851 \nL 232.329587 216.399903 \nL 232.491224 216.607798 \nL 232.652862 216.614685 \nL 232.868379 216.582838 \nL 232.922258 216.485253 \nL 233.030016 216.64387 \nL 233.137775 216.560659 \nL 233.191654 216.652788 \nL 233.245533 216.620092 \nL 233.46105 216.476645 \nL 233.568808 216.590867 \nL 233.676567 216.424691 \nL 233.730446 216.527086 \nL 233.784325 216.650097 \nL 233.838204 216.60802 \nL 233.892084 216.546353 \nL 233.945963 216.614293 \nL 234.16148 216.571736 \nL 234.269238 216.584092 \nL 234.484755 216.58478 \nL 234.754151 216.601946 \nL 234.915789 216.62413 \nL 235.723977 216.628885 \nL 236.047252 216.658203 \nL 236.101131 216.517684 \nL 236.15501 216.631161 \nL 236.909319 216.532202 \nL 237.017078 216.722288 \nL 237.070957 216.619519 \nL 237.178715 216.5995 \nL 237.286474 216.653434 \nL 237.340353 216.572743 \nL 237.394232 216.664951 \nL 237.609749 216.641858 \nL 237.663628 216.496498 \nL 237.717507 216.61818 \nL 238.310179 216.663314 \nL 238.417937 216.588509 \nL 238.633454 216.673485 \nL 238.795091 216.662907 \nL 238.956729 216.664588 \nL 239.280004 216.652142 \nL 239.333883 216.716682 \nL 239.387763 216.630733 \nL 239.657159 216.686942 \nL 239.818796 216.650071 \nL 240.303709 216.689794 \nL 240.519226 216.643701 \nL 240.680864 216.673823 \nL 241.381293 216.662364 \nL 241.435173 216.739296 \nL 241.489052 216.616142 \nL 241.542931 216.662647 \nL 242.189481 216.601145 \nL 242.243361 216.513925 \nL 242.29724 216.616518 \nL 242.512757 216.678603 \nL 243.213186 216.683615 \nL 243.267066 216.587737 \nL 243.320945 216.69278 \nL 243.482582 216.6758 \nL 243.590341 216.720314 \nL 243.64422 216.629306 \nL 243.698099 216.668013 \nL 245.476113 216.712158 \nL 245.637751 216.648903 \nL 245.799388 216.728295 \nL 245.961026 216.648097 \nL 246.33818 216.662599 \nL 246.823093 216.694535 \nL 246.984731 216.725848 \nL 247.146368 216.694702 \nL 247.73904 216.655836 \nL 247.792919 216.55506 \nL 247.846798 216.671863 \nL 248.331711 216.716743 \nL 248.708865 216.6419 \nL 248.870503 216.736061 \nL 249.08602 216.516606 \nL 249.139899 216.726706 \nL 249.894208 216.761044 \nL 250.109725 216.671173 \nL 250.217483 216.754917 \nL 250.271362 216.718727 \nL 250.486879 216.696126 \nL 250.756275 216.687861 \nL 250.971792 216.762051 \nL 251.187309 216.626807 \nL 251.402826 216.728866 \nL 251.833859 216.728843 \nL 252.049376 216.739895 \nL 252.857564 216.752033 \nL 253.073081 216.670137 \nL 253.234719 216.742486 \nL 253.396356 216.741106 \nL 254.096786 216.765571 \nL 254.47394 216.769704 \nL 255.012732 216.710059 \nL 255.228249 216.782235 \nL 255.497645 216.777379 \nL 255.659283 216.735469 \nL 255.8748 216.771758 \nL 256.090317 216.75825 \nL 256.251954 216.819214 \nL 256.413592 216.637229 \nL 256.629109 216.76633 \nL 256.682988 216.716227 \nL 256.736867 216.807698 \nL 256.952384 216.742349 \nL 257.167901 216.742798 \nL 257.598934 216.725565 \nL 257.86833 216.72638 \nL 258.137726 216.830173 \nL 258.299364 216.738479 \nL 259.161431 216.762734 \nL 259.215311 216.680911 \nL 259.26919 216.749106 \nL 259.484707 216.740117 \nL 259.646344 216.7821 \nL 259.807982 216.778861 \nL 260.400653 216.790864 \nL 260.562291 216.778298 \nL 260.777808 216.812639 \nL 260.993324 216.782826 \nL 261.370479 216.792148 \nL 261.801512 216.77653 \nL 262.717459 216.821653 \nL 262.825217 216.747114 \nL 262.932976 216.852069 \nL 263.31013 216.74496 \nL 263.579526 216.838682 \nL 263.902802 216.816368 \nL 264.064439 216.819474 \nL 264.279956 216.816426 \nL 264.549352 216.82191 \nL 264.764869 216.842807 \nL 264.926506 216.837414 \nL 266.004091 216.778083 \nL 266.381245 216.849579 \nL 266.596762 216.790372 \nL 266.866158 216.828265 \nL 267.027795 216.824698 \nL 267.566588 216.85302 \nL 267.620467 216.73234 \nL 267.674346 216.865799 \nL 268.0515 216.825618 \nL 268.320896 216.849047 \nL 268.75193 216.833823 \nL 268.859689 216.874569 \nL 269.182964 216.839651 \nL 269.937273 216.899997 \nL 270.152789 216.808384 \nL 270.260548 216.892889 \nL 270.314427 216.802015 \nL 270.368306 216.885628 \nL 274.463126 216.838024 \nL 274.517005 216.750639 \nL 274.678643 216.907951 \nL 274.948039 216.915277 \nL 277.803637 216.90894 \nL 277.911395 216.991367 \nL 277.965274 216.939083 \nL 278.773462 216.893196 \nL 278.827342 216.706744 \nL 278.881221 216.988486 \nL 278.9351 216.923039 \nL 279.581651 216.967861 \nL 279.63553 216.897947 \nL 279.689409 216.974441 \nL 280.335959 216.916172 \nL 280.497597 216.966029 \nL 281.036389 216.997837 \nL 281.251906 216.989453 \nL 281.575181 216.872531 \nL 281.736819 217.036988 \nL 282.006215 216.950051 \nL 282.221732 217.047655 \nL 282.32949 216.963902 \nL 282.491128 217.00077 \nL 282.922161 216.994947 \nL 282.976041 217.001142 \nL 283.02992 216.873997 \nL 283.083799 216.963855 \nL 283.245437 216.986662 \nL 285.292846 216.959928 \nL 285.400605 216.917004 \nL 285.508363 217.050817 \nL 285.939397 216.993477 \nL 286.478189 216.994762 \nL 286.639827 216.992843 \nL 286.855343 217.040156 \nL 286.963102 216.992077 \nL 287.07086 217.003624 \nL 287.232498 217.055201 \nL 287.286377 216.954893 \nL 287.340256 217.005768 \nL 287.717411 217.022604 \nL 287.879048 217.011824 \nL 287.932928 217.023238 \nL 288.094565 216.875326 \nL 288.256203 217.016036 \nL 288.525599 217.01375 \nL 288.741116 217.059893 \nL 288.956632 216.981778 \nL 289.064391 217.048563 \nL 289.279908 216.95533 \nL 289.441545 217.003479 \nL 289.603183 217.040987 \nL 290.411371 216.971535 \nL 290.680767 216.995643 \nL 290.842405 217.063471 \nL 290.950163 217.02077 \nL 291.16568 217.030716 \nL 291.219559 217.098589 \nL 291.273438 216.995497 \nL 291.488955 217.050587 \nL 291.650593 216.915271 \nL 291.704472 217.002503 \nL 292.943694 217.048834 \nL 293.105331 217.042857 \nL 293.428607 217.125656 \nL 293.482486 217.015151 \nL 293.536365 217.050596 \nL 293.644123 216.978871 \nL 293.698003 216.933124 \nL 293.805761 217.05556 \nL 294.021278 217.027902 \nL 294.236795 217.06528 \nL 294.290674 216.898941 \nL 294.344553 217.021661 \nL 294.452312 217.033624 \nL 294.506191 216.956528 \nL 294.56007 217.027324 \nL 294.667828 217.048501 \nL 294.829466 217.02461 \nL 294.991104 217.060608 \nL 295.20662 217.038642 \nL 295.691533 217.066575 \nL 295.799292 216.88285 \nL 295.853171 217.007871 \nL 296.122567 217.059914 \nL 296.338084 217.025011 \nL 296.876876 217.070164 \nL 296.984634 217.121872 \nL 297.092393 216.912225 \nL 297.146272 216.997288 \nL 297.307909 217.074574 \nL 297.631185 216.973768 \nL 297.792822 217.115418 \nL 298.60101 217.046916 \nL 298.762648 217.090275 \nL 298.816527 217.01688 \nL 298.870406 217.072397 \nL 299.085923 217.073804 \nL 300.594541 217.085754 \nL 300.64842 217.135089 \nL 300.702299 217.052067 \nL 300.756179 216.999386 \nL 300.810058 217.057957 \nL 301.187212 217.105729 \nL 301.456608 217.039887 \nL 301.779884 217.084974 \nL 301.9954 217.031179 \nL 302.157038 217.113716 \nL 302.480313 217.008923 \nL 302.641951 217.057395 \nL 303.288501 217.097183 \nL 304.04281 217.053451 \nL 304.150569 217.058581 \nL 304.419965 217.112649 \nL 304.581602 217.052176 \nL 305.551428 217.118427 \nL 305.713066 217.066504 \nL 305.874703 217.10878 \nL 306.305737 217.148302 \nL 306.467375 217.124606 \nL 306.844529 217.087928 \nL 307.060046 217.122227 \nL 308.622543 217.11869 \nL 308.78418 217.139447 \nL 308.945818 217.093072 \nL 309.053576 217.028508 \nL 309.269093 217.190819 \nL 309.430731 217.101977 \nL 309.592368 217.120637 \nL 309.700127 217.126099 \nL 309.861765 217.038937 \nL 310.400557 217.141092 \nL 310.993228 217.077606 \nL 311.047107 217.007858 \nL 311.100986 217.057152 \nL 311.262624 217.10486 \nL 311.478141 217.143905 \nL 311.53202 217.035414 \nL 311.585899 217.06602 \nL 311.909174 217.152018 \nL 312.070812 217.142613 \nL 313.687188 217.121449 \nL 313.848826 217.143597 \nL 313.902705 217.070304 \nL 313.956584 217.114827 \nL 314.064343 217.182482 \nL 314.172101 217.068994 \nL 314.333739 217.149027 \nL 318.96735 217.130251 \nL 319.02123 217.23156 \nL 319.075109 217.149303 \nL 319.506142 217.122984 \nL 319.66778 217.165454 \nL 319.991055 217.123228 \nL 320.152693 217.00957 \nL 320.36821 217.174142 \nL 320.745364 217.173985 \nL 320.960881 217.174394 \nL 321.230277 217.215211 \nL 321.338035 217.191616 \nL 321.445794 217.234542 \nL 321.499673 217.095242 \nL 321.553552 217.138284 \nL 321.822948 217.215888 \nL 321.930707 217.207792 \nL 322.200103 217.199631 \nL 322.577257 217.159118 \nL 322.685016 217.163862 \nL 322.846653 217.174731 \nL 322.954412 217.192662 \nL 323.169928 217.063943 \nL 323.331566 217.209068 \nL 323.547083 217.185687 \nL 323.654841 217.067399 \nL 323.708721 217.158673 \nL 323.870358 217.214834 \nL 329.096641 217.250344 \nL 329.258279 217.210974 \nL 329.366037 217.20357 \nL 329.419916 217.291406 \nL 329.473796 217.183875 \nL 329.743192 217.258565 \nL 330.335863 217.079736 \nL 330.497501 217.248662 \nL 332.491031 217.193154 \nL 332.760427 217.066589 \nL 332.922065 217.283414 \nL 333.353098 217.186411 \nL 333.514736 217.270918 \nL 336.047059 217.261046 \nL 336.154817 217.302807 \nL 336.424213 217.252841 \nL 336.63973 217.272045 \nL 337.394039 217.269593 \nL 337.555677 217.246973 \nL 339.279811 217.207979 \nL 339.33369 217.146635 \nL 339.38757 217.347135 \nL 339.441449 217.259814 \nL 339.603086 217.287952 \nL 339.926362 217.324791 \nL 340.087999 217.25376 \nL 340.303516 217.352368 \nL 340.680671 217.269737 \nL 341.488859 217.223891 \nL 341.596617 217.1659 \nL 341.758255 217.247593 \nL 341.866013 217.304522 \nL 341.973771 217.246686 \nL 342.08153 217.291884 \nL 342.243167 217.247899 \nL 342.458684 217.348353 \nL 342.566443 217.198986 \nL 342.835839 217.312764 \nL 343.105235 217.258469 \nL 343.320752 217.298763 \nL 344.506094 217.29902 \nL 344.77549 217.306865 \nL 344.829369 217.277726 \nL 344.883249 217.101206 \nL 344.937128 217.232328 \nL 345.152645 217.297393 \nL 345.47592 217.308243 \nL 345.529799 217.206087 \nL 345.583678 217.319695 \nL 346.337987 217.261739 \nL 346.499625 217.317619 \nL 347.146175 217.308924 \nL 347.253934 217.288768 \nL 347.307813 217.20001 \nL 347.361692 217.264859 \nL 347.52333 217.301677 \nL 348.816431 217.270479 \nL 348.978068 217.292747 \nL 349.085827 217.273271 \nL 349.355223 217.332413 \nL 349.678498 217.298745 \nL 349.732377 217.116113 \nL 349.786256 217.249972 \nL 353.450042 217.280552 \nL 353.503922 217.154996 \nL 353.557801 217.283845 \nL 353.665559 217.307297 \nL 353.719438 217.232172 \nL 353.773318 217.325575 \nL 353.881076 217.263224 \nL 355.766848 217.20657 \nL 355.820727 217.40205 \nL 355.874607 217.313797 \nL 356.090124 217.319689 \nL 356.144003 217.261325 \nL 356.197882 217.370893 \nL 356.251761 217.310167 \nL 356.628916 217.320746 \nL 357.383224 217.262223 \nL 357.544862 217.29604 \nL 357.760379 217.323935 \nL 357.814258 217.15746 \nL 357.868137 217.289457 \nL 357.922017 217.210238 \nL 357.975896 217.27661 \nL 358.299171 217.336543 \nL 359.05348 217.316175 \nL 359.215117 217.318938 \nL 359.430634 217.295585 \nL 360.023306 217.327129 \nL 360.184943 217.249475 \nL 360.184943 217.249475 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p54593d48fa)\" d=\"M 56.748961 -1 \nL 57.599321 104.229022 \nL 58.030354 169.115019 \nL 58.29975 179.04576 \nL 58.784663 186.22358 \nL 59.64673 194.601609 \nL 60.508798 201.056297 \nL 61.424744 206.149382 \nL 61.69414 207.301137 \nL 62.071295 208.76459 \nL 62.771724 210.728272 \nL 62.933362 211.040333 \nL 63.256637 211.475534 \nL 63.472154 211.947087 \nL 63.795429 212.157237 \nL 63.849309 212.165846 \nL 64.118705 212.545055 \nL 64.765255 212.892104 \nL 64.819134 212.662135 \nL 64.873013 212.771119 \nL 65.034651 212.963765 \nL 65.304047 213.035893 \nL 65.465685 212.978514 \nL 65.627322 213.135209 \nL 65.842839 213.216636 \nL 66.48939 213.23455 \nL 66.651027 213.40349 \nL 67.944128 213.527124 \nL 67.998007 213.396037 \nL 68.159645 213.675298 \nL 68.48292 213.688834 \nL 68.5368 213.621328 \nL 68.644558 213.770721 \nL 68.698437 213.667242 \nL 68.752316 213.775794 \nL 68.967833 213.797417 \nL 70.045417 213.961117 \nL 70.099296 213.834105 \nL 70.153176 213.879928 \nL 70.314813 213.996447 \nL 73.493686 214.366828 \nL 73.601445 214.055327 \nL 73.709203 214.347758 \nL 73.763083 214.246698 \nL 73.870841 214.374016 \nL 73.978599 214.325562 \nL 74.194116 214.417216 \nL 74.247995 214.197845 \nL 74.301875 214.31684 \nL 74.409633 214.434287 \nL 74.517391 214.430622 \nL 74.679029 214.432587 \nL 74.732908 214.311228 \nL 74.786787 214.348334 \nL 74.948425 214.491666 \nL 75.110063 214.46026 \nL 75.756613 214.532732 \nL 76.079888 214.499442 \nL 76.241526 214.581116 \nL 76.349284 214.575968 \nL 76.403164 214.480691 \nL 76.457043 214.543759 \nL 76.726439 214.632976 \nL 77.049714 214.617524 \nL 77.265231 214.662184 \nL 77.857902 214.688125 \nL 78.719969 214.710803 \nL 78.827728 214.70713 \nL 78.989366 214.746577 \nL 79.312641 214.722792 \nL 79.36652 214.615308 \nL 79.528158 214.767772 \nL 79.797554 214.827859 \nL 79.905312 214.771435 \nL 79.959191 214.837857 \nL 80.01307 214.647025 \nL 80.06695 214.822846 \nL 80.497983 214.775447 \nL 80.551863 214.682363 \nL 80.659621 214.863171 \nL 80.767379 214.727253 \nL 80.821259 214.849133 \nL 80.982896 214.86575 \nL 81.144534 214.824534 \nL 81.360051 214.927084 \nL 81.41393 214.783628 \nL 81.467809 214.89452 \nL 81.737205 214.935597 \nL 81.844963 214.722131 \nL 82.006601 214.960639 \nL 82.76091 214.995972 \nL 83.084185 215.028357 \nL 83.46134 215.011703 \nL 83.730736 214.954389 \nL 83.784615 214.92625 \nL 83.892373 215.072697 \nL 83.946253 215.049343 \nL 84.215649 215.055113 \nL 84.377286 214.954353 \nL 84.592803 215.089396 \nL 84.700561 214.920464 \nL 84.862199 215.103707 \nL 85.023837 215.087594 \nL 85.347112 215.127924 \nL 85.724266 215.151178 \nL 86.101421 215.156572 \nL 86.424696 215.127308 \nL 86.694092 215.196814 \nL 86.909609 215.167972 \nL 87.879435 215.220988 \nL 88.310468 215.219135 \nL 90.19624 215.175782 \nL 90.25012 215.076409 \nL 90.357878 215.289769 \nL 90.519516 215.302955 \nL 90.788912 215.29851 \nL 90.842791 215.221076 \nL 90.89667 215.274455 \nL 91.166066 215.326727 \nL 91.543221 215.342129 \nL 91.866496 215.315229 \nL 91.920375 215.146852 \nL 91.974254 215.305861 \nL 92.135892 215.346279 \nL 92.24365 215.135099 \nL 92.351409 215.335465 \nL 92.459167 215.240455 \nL 92.674684 215.344257 \nL 96.33847 215.43482 \nL 96.446228 215.503368 \nL 96.607866 215.472607 \nL 96.769504 215.519882 \nL 96.931141 215.516445 \nL 97.793209 215.533495 \nL 97.847088 215.365883 \nL 97.900967 215.545787 \nL 98.170363 215.493225 \nL 98.224242 215.469917 \nL 98.332001 215.569489 \nL 98.601397 215.49035 \nL 98.709155 215.55916 \nL 98.870793 215.498572 \nL 99.03243 215.598881 \nL 101.07984 215.610662 \nL 101.241478 215.670137 \nL 101.834149 215.624016 \nL 101.995787 215.706792 \nL 102.265183 215.614156 \nL 102.42682 215.670145 \nL 102.534579 215.674492 \nL 102.588458 215.569974 \nL 102.696216 215.739343 \nL 102.803975 215.621668 \nL 102.965612 215.741155 \nL 103.12725 215.670648 \nL 103.181129 215.745919 \nL 103.235008 215.63061 \nL 103.450525 215.717075 \nL 103.881559 215.752936 \nL 104.420351 215.769593 \nL 104.581989 215.813179 \nL 104.905264 215.689127 \nL 105.066901 215.80982 \nL 105.228539 215.811193 \nL 105.605693 215.831539 \nL 106.306123 215.873722 \nL 107.706982 215.90497 \nL 107.86862 215.917492 \nL 108.030258 215.897442 \nL 108.299654 215.979085 \nL 108.407412 215.901823 \nL 108.515171 215.965798 \nL 108.622929 215.831489 \nL 108.676808 215.926552 \nL 108.892325 215.951342 \nL 109.107842 215.972053 \nL 109.377238 215.956666 \nL 109.431117 215.904913 \nL 109.484996 215.966415 \nL 109.538875 216.007601 \nL 109.700513 215.898503 \nL 109.862151 216.027695 \nL 110.778097 216.02713 \nL 110.939735 216.049671 \nL 111.478527 216.093384 \nL 111.586285 215.822345 \nL 111.747923 216.110393 \nL 112.017319 216.145821 \nL 112.771628 216.110058 \nL 112.879386 216.150503 \nL 113.148782 216.128633 \nL 113.31042 216.181991 \nL 113.525937 216.152302 \nL 113.849212 216.22102 \nL 114.603521 216.209817 \nL 114.711279 216.18301 \nL 114.765159 216.071755 \nL 114.819038 216.138076 \nL 114.980675 216.248942 \nL 115.088434 216.18321 \nL 115.250071 216.259293 \nL 115.465588 216.252704 \nL 115.681105 216.246856 \nL 115.788863 216.264531 \nL 116.112139 216.295538 \nL 116.435414 216.29223 \nL 116.650931 216.298148 \nL 116.866448 216.289322 \nL 117.243602 216.326119 \nL 117.297481 216.239738 \nL 117.35136 216.299384 \nL 117.512998 216.336254 \nL 118.267307 216.354694 \nL 118.590582 216.385854 \nL 118.644461 216.292033 \nL 118.698341 216.366429 \nL 119.021616 216.396829 \nL 119.452649 216.387684 \nL 119.668166 216.416091 \nL 119.829804 216.406246 \nL 120.314717 216.411715 \nL 120.584113 216.409089 \nL 121.607818 216.447374 \nL 121.769455 216.446955 \nL 122.14661 216.413058 \nL 122.308247 216.496023 \nL 122.79316 216.454192 \nL 122.954798 216.451721 \nL 123.278073 216.536122 \nL 123.385832 216.44099 \nL 123.439711 216.493672 \nL 123.601348 216.501132 \nL 124.086261 216.546664 \nL 125.918154 216.613911 \nL 125.972033 216.467393 \nL 126.025913 216.584664 \nL 126.295309 216.620598 \nL 126.672463 216.549228 \nL 126.726342 216.654923 \nL 126.780222 216.625347 \nL 127.049618 216.633968 \nL 127.265134 216.666743 \nL 127.480651 216.648432 \nL 127.642289 216.701907 \nL 127.857806 216.599825 \nL 128.181081 216.71093 \nL 128.288839 216.629787 \nL 128.342718 216.670097 \nL 128.827631 216.498718 \nL 128.93539 216.715961 \nL 128.989269 216.697298 \nL 129.58194 216.68996 \nL 129.635819 216.745547 \nL 129.689699 216.684607 \nL 129.959095 216.672233 \nL 130.012974 216.611404 \nL 130.174612 216.766662 \nL 130.713404 216.729381 \nL 130.821162 216.769978 \nL 130.92892 216.730425 \nL 131.090558 216.782342 \nL 131.359954 216.793739 \nL 132.222021 216.799828 \nL 132.437538 216.843588 \nL 133.461243 216.871725 \nL 133.67676 216.827522 \nL 142.782346 217.129549 \nL 142.836225 217.075841 \nL 142.890104 217.178169 \nL 143.213379 217.15201 \nL 143.321138 217.179727 \nL 143.644413 217.168661 \nL 143.752171 217.218157 \nL 143.85993 217.121327 \nL 143.967688 217.188483 \nL 144.075447 217.193361 \nL 144.344843 217.212185 \nL 144.614239 217.174115 \nL 144.775876 217.123525 \nL 144.937514 217.20753 \nL 145.045272 217.243329 \nL 145.153031 217.119339 \nL 145.314668 217.233676 \nL 145.961219 217.251165 \nL 147.523716 217.244825 \nL 147.739233 217.294046 \nL 147.793112 217.210057 \nL 147.846991 217.276464 \nL 148.224146 217.242176 \nL 148.385783 217.290679 \nL 148.762938 217.319772 \nL 148.870696 217.147487 \nL 149.032334 217.310537 \nL 149.140092 217.187467 \nL 149.193971 217.299847 \nL 149.247851 217.320716 \nL 149.30173 217.150527 \nL 149.355609 217.280142 \nL 149.840522 217.251411 \nL 150.002159 217.301939 \nL 150.379314 217.322084 \nL 150.487072 217.205606 \nL 150.540951 217.345916 \nL 151.133623 217.31605 \nL 151.564656 217.336693 \nL 151.672415 217.299326 \nL 151.834052 217.342225 \nL 153.665945 217.352487 \nL 153.719825 217.243695 \nL 153.773704 217.379478 \nL 153.827583 217.316994 \nL 153.881462 217.397009 \nL 154.258617 217.246331 \nL 154.474134 217.381241 \nL 154.635771 217.382299 \nL 154.68965 217.399064 \nL 154.74353 217.243275 \nL 154.797409 217.349021 \nL 154.905167 217.376257 \nL 155.39008 217.393411 \nL 156.359906 217.412266 \nL 156.683181 217.411193 \nL 157.060335 217.421356 \nL 157.114215 217.292758 \nL 157.168094 217.418992 \nL 158.461195 217.329819 \nL 158.515074 217.283579 \nL 158.568953 217.36459 \nL 159.053866 217.447 \nL 159.215504 217.413492 \nL 159.269383 217.270608 \nL 159.323262 217.434065 \nL 159.592658 217.434337 \nL 160.077571 217.439102 \nL 160.13145 217.369089 \nL 160.185329 217.442998 \nL 160.400846 217.446782 \nL 160.670242 217.440092 \nL 160.724121 217.337295 \nL 160.778001 217.44406 \nL 160.993518 217.459196 \nL 164.22627 217.426209 \nL 164.280149 217.32239 \nL 164.441787 217.507896 \nL 165.196096 217.517727 \nL 165.465492 217.460795 \nL 165.627129 217.479704 \nL 165.681008 217.395876 \nL 165.734888 217.465948 \nL 165.950404 217.540017 \nL 166.381438 217.508303 \nL 166.596955 217.478429 \nL 166.650834 217.389417 \nL 166.704713 217.514428 \nL 166.974109 217.479204 \nL 167.135747 217.472438 \nL 167.405143 217.477737 \nL 168.536606 217.501224 \nL 168.644365 217.3922 \nL 168.806002 217.540784 \nL 169.075398 217.557659 \nL 169.129278 217.397776 \nL 169.183157 217.476713 \nL 169.237036 217.525172 \nL 169.290915 217.408012 \nL 169.344794 217.45003 \nL 169.506432 217.567807 \nL 169.66807 217.510877 \nL 169.829707 217.559968 \nL 170.368499 217.553091 \nL 170.530137 217.560359 \nL 171.068929 217.552811 \nL 171.176687 217.561891 \nL 171.284446 217.405902 \nL 171.446084 217.54819 \nL 171.984876 217.591042 \nL 173.170218 217.538666 \nL 173.439614 217.572138 \nL 173.816769 217.613212 \nL 174.086165 217.550175 \nL 174.140044 217.615835 \nL 174.247802 217.397229 \nL 174.40944 217.571441 \nL 174.517198 217.562482 \nL 174.624957 217.546907 \nL 174.732715 217.599715 \nL 174.786594 217.535475 \nL 174.840474 217.609498 \nL 175.10987 217.589261 \nL 177.372796 217.53687 \nL 177.426675 217.391521 \nL 177.480555 217.602136 \nL 177.534434 217.582475 \nL 177.642192 217.595176 \nL 177.857709 217.585871 \nL 177.911588 217.535325 \nL 177.965467 217.603608 \nL 178.127105 217.610848 \nL 178.288743 217.407336 \nL 178.396501 217.624814 \nL 178.558139 217.489583 \nL 178.719776 217.639737 \nL 178.989172 217.603684 \nL 179.581844 217.646469 \nL 179.743481 217.549677 \nL 179.905119 217.609057 \nL 180.443911 217.616525 \nL 180.928824 217.638433 \nL 181.19822 217.594422 \nL 181.413737 217.638342 \nL 181.521495 217.569274 \nL 181.683133 217.591283 \nL 181.790891 217.430268 \nL 181.952529 217.638327 \nL 182.168046 217.662692 \nL 182.275804 217.586488 \nL 182.437442 217.65693 \nL 182.760717 217.60774 \nL 182.922354 217.655834 \nL 183.461147 217.619246 \nL 183.676663 217.638208 \nL 183.946059 217.667278 \nL 184.161576 217.603987 \nL 184.430972 217.689248 \nL 184.59261 217.618033 \nL 184.700368 217.648143 \nL 184.754247 217.602364 \nL 184.808127 217.68051 \nL 185.185281 217.637088 \nL 185.454677 217.680383 \nL 185.616315 217.642116 \nL 185.831832 217.641295 \nL 186.155107 217.645701 \nL 186.316744 217.650696 \nL 186.58614 217.628091 \nL 186.747778 217.645932 \nL 186.909416 217.652309 \nL 187.232691 217.523617 \nL 187.340449 217.679186 \nL 187.394329 217.576096 \nL 187.448208 217.678587 \nL 187.609845 217.685609 \nL 187.771483 217.59071 \nL 188.040879 217.673307 \nL 188.094758 217.594896 \nL 188.148637 217.664559 \nL 188.310275 217.644613 \nL 188.471913 217.672304 \nL 188.849067 217.666109 \nL 188.902946 217.555232 \nL 188.956826 217.67255 \nL 189.172342 217.685933 \nL 189.98053 217.67205 \nL 190.196047 217.69634 \nL 190.411564 217.665979 \nL 190.896477 217.702914 \nL 191.058115 217.642845 \nL 191.327511 217.714534 \nL 191.704665 217.691895 \nL 192.189578 217.701061 \nL 192.620612 217.66171 \nL 192.836128 217.698012 \nL 193.159404 217.691745 \nL 193.321041 217.657013 \nL 193.37492 217.735561 \nL 193.4288 217.685798 \nL 193.644317 217.653192 \nL 193.698196 217.728941 \nL 193.752075 217.653576 \nL 193.859833 217.696988 \nL 194.236988 217.679748 \nL 194.452505 217.61442 \nL 194.77578 217.701986 \nL 195.314572 217.703204 \nL 195.368451 217.584194 \nL 195.42233 217.660888 \nL 195.583968 217.709998 \nL 195.637847 217.577032 \nL 195.691726 217.671083 \nL 195.907243 217.710566 \nL 196.230518 217.555323 \nL 196.392156 217.730641 \nL 196.76931 217.703194 \nL 196.984827 217.735675 \nL 197.415861 217.618868 \nL 197.46974 217.528586 \nL 197.523619 217.637049 \nL 197.685257 217.701727 \nL 198.493445 217.708552 \nL 198.708962 217.753879 \nL 198.924479 217.689409 \nL 199.086116 217.742228 \nL 199.247754 217.752109 \nL 199.571029 217.684101 \nL 199.732667 217.723321 \nL 199.894304 217.734828 \nL 200.271459 217.735953 \nL 200.325338 217.623104 \nL 200.379217 217.748008 \nL 200.702493 217.730053 \nL 200.756372 217.775158 \nL 200.86413 217.584821 \nL 201.025768 217.771946 \nL 201.241285 217.597546 \nL 201.295164 217.712165 \nL 201.618439 217.785 \nL 201.780077 217.734314 \nL 201.995593 217.757213 \nL 202.21111 217.73997 \nL 202.372748 217.712678 \nL 202.426627 217.449252 \nL 202.480506 217.505037 \nL 202.588265 217.773261 \nL 202.642144 217.734729 \nL 202.803782 217.789368 \nL 202.965419 217.731772 \nL 203.127057 217.785386 \nL 203.234815 217.716579 \nL 203.342574 217.748511 \nL 203.719728 217.755956 \nL 203.827487 217.765891 \nL 203.881366 217.689832 \nL 203.935245 217.738607 \nL 204.150762 217.766547 \nL 204.581795 217.763939 \nL 204.635675 217.690228 \nL 204.689554 217.749691 \nL 204.905071 217.769704 \nL 205.228346 217.771052 \nL 205.389983 217.7506 \nL 205.551621 217.778821 \nL 205.65938 217.769269 \nL 205.767138 217.731691 \nL 205.821017 217.807038 \nL 205.874896 217.710081 \nL 205.928776 217.589119 \nL 205.982655 217.726792 \nL 206.144292 217.775306 \nL 206.198172 217.711188 \nL 206.252051 217.798507 \nL 206.898601 217.769206 \nL 207.060239 217.781117 \nL 207.275756 217.739861 \nL 207.329635 217.80914 \nL 207.383514 217.762483 \nL 207.437393 217.679673 \nL 207.491273 217.738063 \nL 207.760669 217.790827 \nL 207.868427 217.794863 \nL 207.976185 217.781814 \nL 208.245581 217.813684 \nL 208.299461 217.627829 \nL 208.35334 217.785459 \nL 208.622736 217.822754 \nL 208.676615 217.616478 \nL 208.730494 217.789749 \nL 208.892132 217.814164 \nL 209.05377 217.674455 \nL 209.107649 217.816948 \nL 209.161528 217.779712 \nL 209.269286 217.793912 \nL 210.885663 217.846692 \nL 210.939542 217.697826 \nL 210.993421 217.829415 \nL 211.586092 217.724369 \nL 211.74773 217.843825 \nL 212.609797 217.814187 \nL 212.825314 217.841956 \nL 212.986952 217.827827 \nL 213.040831 217.774448 \nL 213.09471 217.875741 \nL 213.310227 217.816608 \nL 213.471864 217.834693 \nL 213.74126 217.854149 \nL 214.118415 217.832645 \nL 214.226173 217.809866 \nL 214.387811 217.888458 \nL 214.764965 217.827891 \nL 214.926603 217.878525 \nL 215.195999 217.8627 \nL 215.357637 217.856371 \nL 215.734791 217.891501 \nL 215.950308 217.744514 \nL 216.111946 217.832974 \nL 216.165825 217.76692 \nL 216.219704 217.88704 \nL 216.273583 217.831388 \nL 216.327462 217.770137 \nL 216.381342 217.866977 \nL 217.458926 217.892909 \nL 217.566684 217.862524 \nL 217.674443 217.861005 \nL 217.782201 217.710122 \nL 217.997718 217.878655 \nL 218.105476 217.856842 \nL 218.159355 217.734211 \nL 218.213235 217.913575 \nL 218.267114 217.868712 \nL 221.9309 217.935792 \nL 222.038658 217.93588 \nL 222.146417 217.746305 \nL 222.254175 217.93953 \nL 222.308054 217.906362 \nL 222.523571 217.950704 \nL 222.846846 217.939317 \nL 225.109773 217.960676 \nL 225.379169 217.970127 \nL 225.810203 217.956853 \nL 225.917961 217.946101 \nL 226.187357 217.962581 \nL 226.780028 217.964072 \nL 226.833908 218.006087 \nL 226.887787 217.933988 \nL 227.049424 217.875594 \nL 227.157183 217.985459 \nL 227.211062 217.895503 \nL 227.264941 217.965521 \nL 227.588216 217.97802 \nL 227.695975 217.945494 \nL 227.803733 217.983847 \nL 228.01925 217.993544 \nL 229.042955 218.029412 \nL 229.312351 217.974585 \nL 229.473989 218.008184 \nL 229.689506 217.97782 \nL 229.797264 218.024048 \nL 229.851143 217.966314 \nL 229.905022 218.035985 \nL 230.174418 217.971496 \nL 230.282177 218.031136 \nL 230.389935 218.020447 \nL 230.659331 218.01885 \nL 231.144244 218.009801 \nL 231.521399 218.053027 \nL 231.736915 217.961166 \nL 231.952432 218.059124 \nL 232.167949 218.031414 \nL 232.221828 218.006333 \nL 232.275707 217.81603 \nL 232.329587 218.055821 \nL 232.383466 217.952454 \nL 232.491224 217.896338 \nL 232.706741 218.053623 \nL 232.976137 218.036679 \nL 233.245533 218.052326 \nL 233.353292 217.956933 \nL 233.407171 217.801815 \nL 233.46105 217.973844 \nL 233.568808 218.059349 \nL 233.622688 218.008975 \nL 233.676567 217.702992 \nL 233.730446 217.97838 \nL 233.838204 217.884049 \nL 233.945963 218.068917 \nL 233.999842 218.050365 \nL 234.1076 218.033275 \nL 234.16148 217.968175 \nL 234.323117 218.085291 \nL 234.700272 217.961993 \nL 234.80803 218.077771 \nL 234.861909 217.988658 \nL 234.915789 218.097739 \nL 235.077426 218.037692 \nL 235.239064 218.020416 \nL 235.292943 217.974515 \nL 235.454581 218.065555 \nL 235.670097 218.076712 \nL 235.723977 218.030318 \nL 235.777856 218.119418 \nL 236.047252 217.895192 \nL 236.101131 218.069409 \nL 236.316648 218.080075 \nL 236.693802 218.055769 \nL 236.85544 217.887901 \nL 237.017078 218.069248 \nL 237.55587 218.084231 \nL 237.609749 217.979557 \nL 237.663628 218.106167 \nL 237.879145 218.097032 \nL 238.094662 218.101557 \nL 238.364058 217.993106 \nL 238.471816 218.113486 \nL 238.525695 218.074287 \nL 238.795091 218.109281 \nL 239.118367 218.104032 \nL 239.280004 218.120385 \nL 239.333883 218.062537 \nL 239.387763 218.113554 \nL 239.603279 218.08669 \nL 240.24983 218.110547 \nL 240.465347 218.127775 \nL 240.626984 218.074614 \nL 240.788622 218.140992 \nL 240.842501 218.048259 \nL 240.89638 218.120115 \nL 241.111897 218.111817 \nL 242.081723 218.061626 \nL 242.135602 217.980319 \nL 242.189481 218.135982 \nL 242.243361 217.98999 \nL 242.29724 217.97584 \nL 242.458877 218.140502 \nL 242.997669 218.121518 \nL 243.159307 218.119638 \nL 243.267066 218.040152 \nL 243.536462 218.125543 \nL 243.64422 218.071888 \nL 243.751978 218.123847 \nL 243.805858 218.013625 \nL 243.859737 218.133743 \nL 248.116194 218.115907 \nL 248.223952 218.128547 \nL 248.439469 218.110041 \nL 248.978261 218.170751 \nL 249.032141 218.010794 \nL 249.08602 218.06607 \nL 249.247657 218.169002 \nL 250.379121 218.134719 \nL 250.486879 218.118757 \nL 250.756275 218.162072 \nL 250.971792 218.171579 \nL 251.187309 218.131355 \nL 257.275659 218.155667 \nL 257.383418 218.213214 \nL 257.706693 218.161634 \nL 257.86833 218.224431 \nL 258.083847 218.217269 \nL 258.514881 218.240535 \nL 258.56876 218.166593 \nL 258.622639 218.214006 \nL 258.999794 218.231098 \nL 259.053673 218.115955 \nL 259.107552 218.227109 \nL 259.26919 218.109712 \nL 259.376948 218.222457 \nL 259.430827 218.154765 \nL 259.861861 218.239919 \nL 260.023499 218.145334 \nL 260.185136 218.233903 \nL 260.346774 218.187826 \nL 260.400653 218.066021 \nL 260.454532 218.184434 \nL 260.562291 218.255877 \nL 260.831687 218.068697 \nL 260.939445 218.251571 \nL 260.993324 218.216387 \nL 261.047204 218.150147 \nL 261.101083 218.252296 \nL 261.585996 218.196551 \nL 261.693754 218.250486 \nL 261.855392 218.223371 \nL 262.124788 218.277152 \nL 262.178667 218.199177 \nL 262.232546 218.24226 \nL 262.394184 218.221266 \nL 262.609701 218.242258 \nL 262.66358 218.29171 \nL 262.717459 218.216052 \nL 262.825217 218.200583 \nL 262.986855 218.258735 \nL 263.202372 218.254579 \nL 263.256251 218.257309 \nL 263.31013 218.078917 \nL 263.364009 218.248561 \nL 263.633406 218.288856 \nL 264.172198 218.278924 \nL 264.226077 218.290299 \nL 264.279956 218.146489 \nL 264.333835 218.202387 \nL 264.495473 218.277366 \nL 265.088144 218.21101 \nL 265.249782 218.257226 \nL 265.411419 218.280719 \nL 265.896332 218.212041 \nL 266.111849 218.291887 \nL 266.165728 218.174829 \nL 266.219607 218.270944 \nL 266.435124 218.277992 \nL 267.566588 218.280507 \nL 267.620467 218.328252 \nL 267.674346 218.256317 \nL 267.943742 218.291236 \nL 268.267017 218.331201 \nL 268.805809 218.290165 \nL 268.913568 218.291832 \nL 269.021326 218.33171 \nL 269.398481 218.29269 \nL 269.45236 218.243031 \nL 269.506239 218.34789 \nL 269.560118 218.260283 \nL 273.762696 218.363326 \nL 273.924334 218.374231 \nL 273.978213 218.26508 \nL 274.032092 218.295346 \nL 274.19373 218.349681 \nL 274.355368 218.360709 \nL 274.463126 218.154724 \nL 274.517005 218.362587 \nL 274.570884 218.331745 \nL 274.84028 218.357956 \nL 275.001918 218.360937 \nL 275.109676 218.313038 \nL 275.325193 218.368713 \nL 275.486831 218.356638 \nL 275.648469 218.370682 \nL 275.917865 218.381748 \nL 277.103207 218.391248 \nL 277.210965 218.24147 \nL 277.264845 218.367316 \nL 277.749758 218.355664 \nL 277.857516 218.407512 \nL 277.965274 218.382493 \nL 278.126912 218.406746 \nL 278.23467 218.423243 \nL 278.28855 218.330373 \nL 278.342429 218.377904 \nL 278.504066 218.422385 \nL 278.611825 218.339405 \nL 278.665704 218.433898 \nL 278.827342 218.294083 \nL 278.881221 218.246231 \nL 279.042859 218.425722 \nL 279.743288 218.431823 \nL 279.958805 218.437474 \nL 280.228201 218.410116 \nL 280.28208 218.324448 \nL 280.389839 218.447379 \nL 280.551476 218.387362 \nL 280.713114 218.448053 \nL 281.62906 218.41919 \nL 281.844577 218.445543 \nL 282.814403 218.417519 \nL 282.868282 218.506382 \nL 282.922161 218.444782 \nL 283.02992 218.251288 \nL 283.137678 218.461983 \nL 283.191557 218.438841 \nL 283.67647 218.42449 \nL 283.891987 218.450476 \nL 284.269142 218.483238 \nL 284.538538 218.427848 \nL 284.700175 218.494147 \nL 285.292846 218.378864 \nL 285.346726 218.213736 \nL 285.508363 218.49715 \nL 285.939397 218.464135 \nL 286.047155 218.407386 \nL 286.208793 218.459506 \nL 286.370431 218.340728 \nL 286.532068 218.511059 \nL 286.639827 218.427324 \nL 286.855343 218.487402 \nL 287.07086 218.481058 \nL 287.232498 218.479226 \nL 287.286377 218.422051 \nL 287.340256 218.499649 \nL 288.41784 218.476708 \nL 288.525599 218.491446 \nL 288.579478 218.425331 \nL 288.633357 218.527187 \nL 288.902753 218.42753 \nL 289.064391 218.505358 \nL 290.088096 218.444691 \nL 290.141975 218.53269 \nL 290.195854 218.493603 \nL 290.411371 218.392497 \nL 290.46525 218.519515 \nL 290.519129 218.393097 \nL 290.788525 218.493995 \nL 291.542834 218.526993 \nL 291.596714 218.410629 \nL 291.650593 218.530509 \nL 291.81223 218.478847 \nL 291.86611 218.528106 \nL 291.919989 218.416304 \nL 291.973868 218.484353 \nL 292.189385 218.506093 \nL 292.674298 218.463628 \nL 292.943694 218.527623 \nL 293.266969 218.464884 \nL 293.482486 218.560314 \nL 293.644123 218.27831 \nL 293.698003 218.365675 \nL 293.751882 218.482426 \nL 293.805761 218.437099 \nL 294.991104 218.533017 \nL 295.044983 218.395237 \nL 295.098862 218.416591 \nL 295.368258 218.52692 \nL 295.691533 218.510123 \nL 295.745412 218.335913 \nL 295.799292 218.439011 \nL 295.960929 218.50727 \nL 296.122567 218.491739 \nL 296.176446 218.371048 \nL 296.230325 218.521796 \nL 296.445842 218.470624 \nL 296.60748 218.526395 \nL 296.769117 218.521657 \nL 297.685064 218.530015 \nL 297.900581 218.536268 \nL 298.062218 218.507819 \nL 298.116098 218.568487 \nL 298.169977 218.47624 \nL 298.439373 218.491279 \nL 298.493252 218.41981 \nL 298.547131 218.504749 \nL 298.708769 218.552268 \nL 298.870406 218.525971 \nL 299.085923 218.554878 \nL 299.409198 218.556239 \nL 299.840232 218.5177 \nL 299.947991 218.399729 \nL 300.00187 218.563248 \nL 300.055749 218.504535 \nL 301.456608 218.487086 \nL 301.510488 218.409138 \nL 301.672125 218.567712 \nL 301.833763 218.394293 \nL 301.9954 218.572046 \nL 302.372555 218.547613 \nL 302.588072 218.530294 \nL 302.641951 218.445456 \nL 302.69583 218.552921 \nL 302.911347 218.535309 \nL 303.072985 218.555126 \nL 304.366085 218.589141 \nL 304.473844 218.438089 \nL 304.635481 218.541099 \nL 305.120394 218.542359 \nL 305.282032 218.585169 \nL 305.44367 218.544519 \nL 305.497549 218.58936 \nL 305.605307 218.36496 \nL 305.659186 218.386556 \nL 305.713066 218.59078 \nL 305.766945 218.556218 \nL 306.521254 218.546725 \nL 306.575133 218.452499 \nL 306.629012 218.557424 \nL 306.736771 218.56938 \nL 307.006167 218.599097 \nL 307.221683 218.569091 \nL 307.383321 218.589757 \nL 307.544959 218.461574 \nL 307.706596 218.591356 \nL 307.814355 218.506528 \nL 307.868234 218.411165 \nL 307.922113 218.602074 \nL 307.975992 218.584394 \nL 308.13763 218.574665 \nL 308.460905 218.609543 \nL 308.514784 218.518673 \nL 308.568664 218.587758 \nL 308.891939 218.55333 \nL 308.945818 218.351657 \nL 308.999697 218.469612 \nL 309.053576 218.609009 \nL 309.107456 218.552402 \nL 309.215214 218.529832 \nL 309.269093 218.578705 \nL 309.322972 218.470172 \nL 309.376852 218.583714 \nL 309.754006 218.586182 \nL 310.616073 218.573083 \nL 310.777711 218.570678 \nL 310.885469 218.582886 \nL 310.993228 218.474754 \nL 311.047107 218.592956 \nL 311.100986 218.553992 \nL 311.154865 218.445231 \nL 311.316503 218.59739 \nL 311.424261 218.60736 \nL 311.53202 218.462478 \nL 311.639778 218.623112 \nL 311.693658 218.596951 \nL 311.855295 218.597596 \nL 312.070812 218.630024 \nL 312.124691 218.555049 \nL 312.17857 218.634142 \nL 312.340208 218.598016 \nL 312.501846 218.600513 \nL 313.471671 218.609126 \nL 313.848826 218.624874 \nL 313.902705 218.52017 \nL 313.956584 218.566614 \nL 314.010463 218.624257 \nL 314.064343 218.566011 \nL 314.118222 218.492198 \nL 314.172101 218.600981 \nL 315.088048 218.600652 \nL 315.303564 218.636678 \nL 315.62684 218.608415 \nL 315.842356 218.644701 \nL 316.003994 218.60562 \nL 316.111752 218.603199 \nL 316.165632 218.463041 \nL 316.219511 218.64941 \nL 316.27339 218.60388 \nL 316.488907 218.615527 \nL 316.758303 218.639811 \nL 316.866061 218.454244 \nL 316.97382 218.646353 \nL 317.027699 218.596481 \nL 317.62037 218.647744 \nL 317.835887 218.598847 \nL 318.428558 218.559624 \nL 318.482438 218.680269 \nL 318.536317 218.64039 \nL 319.398384 218.661337 \nL 319.452263 218.526623 \nL 319.506142 218.553069 \nL 319.66778 218.643466 \nL 319.775538 218.624914 \nL 319.937176 218.632677 \nL 319.991055 218.381369 \nL 320.044934 218.51357 \nL 320.098814 218.67343 \nL 320.152693 218.477586 \nL 320.206572 218.661864 \nL 320.36821 218.676158 \nL 320.853123 218.597477 \nL 321.068639 218.652415 \nL 321.284156 218.63623 \nL 321.391915 218.651751 \nL 321.499673 218.514963 \nL 321.607431 218.675418 \nL 321.71519 218.642917 \nL 321.984586 218.671096 \nL 322.092344 218.646081 \nL 322.631136 218.638883 \nL 322.685016 218.52016 \nL 322.738895 218.696645 \nL 322.792774 218.645806 \nL 322.846653 218.516401 \nL 322.900532 218.658231 \nL 322.954412 218.624888 \nL 323.06217 218.441944 \nL 323.169928 218.672393 \nL 323.223808 218.655512 \nL 323.493204 218.677917 \nL 323.547083 218.663361 \nL 323.600962 218.467522 \nL 323.654841 218.526814 \nL 323.816479 218.694482 \nL 324.085875 218.601064 \nL 324.247513 218.675426 \nL 324.40915 218.697254 \nL 324.570788 218.668018 \nL 324.786305 218.701085 \nL 325.055701 218.615953 \nL 325.271218 218.685468 \nL 325.540614 218.626003 \nL 325.702251 218.696896 \nL 325.971647 218.678203 \nL 326.510439 218.723429 \nL 326.564318 218.61811 \nL 326.618198 218.71179 \nL 327.15699 218.632405 \nL 327.318627 218.665857 \nL 327.588023 218.684415 \nL 327.749661 218.683844 \nL 327.911299 218.698764 \nL 328.180695 218.70092 \nL 328.234574 218.553043 \nL 328.288453 218.661805 \nL 328.50397 218.704312 \nL 328.665607 218.638411 \nL 328.827245 218.685604 \nL 328.881124 218.621194 \nL 328.935004 218.703761 \nL 329.904829 218.729868 \nL 330.012588 218.708566 \nL 330.228104 218.703024 \nL 330.335863 218.687872 \nL 330.55138 218.720128 \nL 330.820776 218.711871 \nL 330.874655 218.488702 \nL 330.928534 218.655173 \nL 331.036293 218.757777 \nL 331.090172 218.671227 \nL 331.144051 218.581254 \nL 331.19793 218.644279 \nL 331.359568 218.710971 \nL 331.682843 218.673438 \nL 331.844481 218.701549 \nL 332.113877 218.699487 \nL 332.167756 218.638064 \nL 332.221635 218.709105 \nL 332.383273 218.735013 \nL 332.59879 218.686542 \nL 332.652669 218.719734 \nL 332.706548 218.552463 \nL 332.868186 218.739387 \nL 333.24534 218.746312 \nL 333.299219 218.588284 \nL 333.353098 218.7292 \nL 333.514736 218.726271 \nL 333.622494 218.733214 \nL 333.676374 218.634102 \nL 333.730253 218.749516 \nL 333.94577 218.725569 \nL 334.161287 218.718523 \nL 334.376803 218.677462 \nL 334.538441 218.764058 \nL 334.700079 218.759067 \nL 335.346629 218.749595 \nL 335.562146 218.660651 \nL 335.616025 218.638226 \nL 335.777663 218.756941 \nL 336.047059 218.705882 \nL 336.154817 218.773547 \nL 336.262576 218.481237 \nL 336.316455 218.53691 \nL 336.478092 218.772445 \nL 336.63973 218.769324 \nL 336.963005 218.744884 \nL 337.178522 218.765881 \nL 337.447918 218.726407 \nL 337.663435 218.739645 \nL 337.878952 218.758288 \nL 337.98671 218.663492 \nL 338.094469 218.75632 \nL 338.148348 218.715256 \nL 338.256106 218.757406 \nL 338.363865 218.733287 \nL 338.417744 218.782075 \nL 338.471623 218.660725 \nL 338.525502 218.741348 \nL 338.794898 218.75737 \nL 338.848777 218.506993 \nL 338.902657 218.688156 \nL 339.010415 218.746428 \nL 339.172053 218.765876 \nL 339.38757 218.755909 \nL 339.441449 218.778381 \nL 339.495328 218.654094 \nL 339.549207 218.715729 \nL 339.710845 218.77445 \nL 339.872482 218.764592 \nL 339.926362 218.740529 \nL 339.980241 218.527515 \nL 340.03412 218.673545 \nL 340.195758 218.781074 \nL 340.303516 218.750914 \nL 340.465154 218.741629 \nL 340.950067 218.730177 \nL 341.327221 218.760914 \nL 341.434979 218.777952 \nL 341.542738 218.513877 \nL 341.596617 218.79419 \nL 341.650496 218.713019 \nL 341.704375 218.630308 \nL 341.866013 218.750574 \nL 342.027651 218.771325 \nL 342.243167 218.737623 \nL 342.458684 218.739072 \nL 342.512564 218.521005 \nL 342.566443 218.770706 \nL 342.620322 218.670053 \nL 342.835839 218.768066 \nL 343.051356 218.735784 \nL 343.266872 218.766061 \nL 343.536268 218.749303 \nL 343.644027 218.690662 \nL 343.913423 218.76576 \nL 344.021181 218.711796 \nL 344.182819 218.778844 \nL 344.344457 218.753974 \nL 344.559973 218.749451 \nL 344.77549 218.763129 \nL 345.152645 218.761602 \nL 345.422041 218.763344 \nL 345.529799 218.715809 \nL 345.745316 218.781834 \nL 345.853074 218.754504 \nL 346.014712 218.789355 \nL 346.12247 218.648521 \nL 346.284108 218.767524 \nL 346.553504 218.785231 \nL 346.607383 218.703825 \nL 346.661262 218.759889 \nL 346.930658 218.763304 \nL 346.984538 218.707384 \nL 347.038417 218.812231 \nL 347.092296 218.749624 \nL 347.253934 218.770441 \nL 347.307813 218.710072 \nL 347.361692 218.786564 \nL 347.577209 218.703689 \nL 347.738847 218.782976 \nL 348.439276 218.60633 \nL 348.493155 218.809071 \nL 348.547035 218.773952 \nL 348.924189 218.762269 \nL 349.085827 218.708487 \nL 349.355223 218.818785 \nL 349.678498 218.635256 \nL 349.732377 218.750793 \nL 349.786256 218.777571 \nL 349.840136 218.668302 \nL 349.894015 218.782031 \nL 349.947894 218.708152 \nL 350.001773 218.802236 \nL 350.163411 218.748805 \nL 350.325048 218.717488 \nL 351.079357 218.785126 \nL 351.294874 218.739545 \nL 351.402633 218.790275 \nL 351.672029 218.62629 \nL 351.833666 218.793639 \nL 351.887545 218.732826 \nL 351.941425 218.785546 \nL 352.534096 218.755003 \nL 352.641854 218.731223 \nL 352.803492 218.806722 \nL 352.96513 218.736533 \nL 353.234526 218.782738 \nL 353.450042 218.793953 \nL 353.503922 218.673595 \nL 353.557801 218.745997 \nL 353.61168 218.814104 \nL 353.665559 218.71938 \nL 353.719438 218.562946 \nL 353.773318 218.810868 \nL 353.881076 218.78438 \nL 353.988834 218.670742 \nL 354.042714 218.739839 \nL 354.204351 218.766487 \nL 354.527627 218.719948 \nL 354.581506 218.612865 \nL 354.743143 218.792336 \nL 355.174177 218.745184 \nL 355.605211 218.768481 \nL 355.65909 218.694265 \nL 355.712969 218.79965 \nL 355.982365 218.773601 \nL 356.036244 218.777458 \nL 356.090124 218.654938 \nL 356.144003 218.788118 \nL 356.898312 218.69799 \nL 357.00607 218.80917 \nL 357.059949 218.668181 \nL 357.113828 218.781711 \nL 357.383224 218.772702 \nL 357.544862 218.70736 \nL 357.598741 218.772656 \nL 357.65262 218.724126 \nL 357.760379 218.587553 \nL 357.868137 218.805887 \nL 357.922017 218.683747 \nL 357.975896 218.796497 \nL 358.029775 218.788096 \nL 358.083654 218.666153 \nL 358.137533 218.806929 \nL 358.460809 218.793378 \nL 358.784084 218.805286 \nL 358.999601 218.781457 \nL 359.430634 218.794718 \nL 359.915547 218.739409 \nL 360.077185 218.781536 \nL 360.184943 218.722553 \nL 360.184943 218.722553 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 40.603125 239.758125 \nL 40.603125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 375.403125 239.758125 \nL 375.403125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 40.603125 239.758125 \nL 375.403125 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 40.603125 22.318125 \nL 375.403125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_15\">\n    <!-- Learning curve of DNN Model -->\n    <defs>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n     <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n     <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n     <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n     <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n     <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n    </defs>\n    <g transform=\"translate(120.118125 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-76\"/>\n     <use x=\"53.962891\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"115.486328\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"176.765625\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"216.128906\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"279.507812\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"307.291016\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"370.669922\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"434.146484\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"465.933594\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"520.914062\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"584.292969\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"625.40625\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"684.585938\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"746.109375\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"777.896484\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"839.078125\" xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"874.283203\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"906.070312\" xlink:href=\"#DejaVuSans-68\"/>\n     <use x=\"983.072266\" xlink:href=\"#DejaVuSans-78\"/>\n     <use x=\"1057.876953\" xlink:href=\"#DejaVuSans-78\"/>\n     <use x=\"1132.681641\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1164.46875\" xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"1250.748047\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1311.929688\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"1375.40625\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1436.929688\" xlink:href=\"#DejaVuSans-108\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 313.128125 59.674375 \nL 368.403125 59.674375 \nQ 370.403125 59.674375 370.403125 57.674375 \nL 370.403125 29.318125 \nQ 370.403125 27.318125 368.403125 27.318125 \nL 313.128125 27.318125 \nQ 311.128125 27.318125 311.128125 29.318125 \nL 311.128125 57.674375 \nQ 311.128125 59.674375 313.128125 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 315.128125 35.416562 \nL 335.128125 35.416562 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_16\"/>\n    <g id=\"text_16\">\n     <!-- train -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     </defs>\n     <g transform=\"translate(343.128125 38.916562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 315.128125 50.094687 \nL 335.128125 50.094687 \n\" style=\"fill:none;stroke:#17becf;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_17\">\n     <!-- val -->\n     <g transform=\"translate(343.128125 53.594687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p54593d48fa\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"40.603125\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyO4bGkDRv95"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPBnr16sSCJu"
      },
      "source": [
        "del model\n",
        "model = torch.load(config['model_path']).to(config['device'])"
      ],
      "execution_count": 1156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFTKkYtNejkV"
      },
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "for x in test_dataloader:\n",
        "    x = x.to(config['device'])\n",
        "    with torch.no_grad():\n",
        "        pred = model(x)\n",
        "    preds.append(pred.detach().cpu())\n",
        "preds = torch.cat(preds, dim=0).numpy()"
      ],
      "execution_count": 1157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovLu0xLufkno",
        "outputId": "2d613c8e-3bb5-47af-f126-2f1c3c137e55"
      },
      "source": [
        "print(f'Saving Result to {config[\"pred_file\"]}')\n",
        "\n",
        "with open(config['pred_file'], 'w') as fp:\n",
        "    fp.write('id,tested_positive\\n')\n",
        "    for id, pred in enumerate(preds):\n",
        "        fp.write(f'{id},{pred}\\n')"
      ],
      "execution_count": 1158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving Result to covid-19.pred.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbdXlJV7RwAI"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXA1vu8maep"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    }
  ]
}